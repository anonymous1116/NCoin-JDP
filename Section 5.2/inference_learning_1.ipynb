{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "456ad10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from DNN_module import Net\n",
    "\n",
    "%run ../NCoinDP_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af5984c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n",
      "True\n",
      "NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "if torch.cuda.is_available(): \n",
    "    dev = \"cuda:0\" \n",
    "else: \n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4bf06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.555986  [   64/250000]\n",
      "train_loss: 0.478531  [32064/250000]\n",
      "train_loss: 0.428812  [64064/250000]\n",
      "train_loss: 0.435352  [96064/250000]\n",
      "train_loss: 0.315381  [128064/250000]\n",
      "train_loss: 0.317572  [160064/250000]\n",
      "train_loss: 0.221515  [192064/250000]\n",
      "train_loss: 0.200542  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.279791 val_loss 0.282146\n",
      "learning rate:  1e-06 , sim:  3\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from DNN_module import Net\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Default : cuda\n",
    "torch.set_default_device('cuda')\n",
    "\n",
    "# Number of train and validation data\n",
    "L_train = 250000\n",
    "L_val   =  50000\n",
    "\n",
    "# Define the batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Number of Epochs\n",
    "N_EPOCHS = 300\n",
    "    \n",
    "# Number of Simulations\n",
    "sims = 20\n",
    "\n",
    "tmp = \"infer_sim_1.pt\"\n",
    "tmp = torch.load(tmp)\n",
    "\n",
    "# Data import\n",
    "[X, Y] = tmp\n",
    "X = X.to(device)\n",
    "Y = Y.to(device)\n",
    "\n",
    "# Weighted loss function\n",
    "torch.set_default_device('cuda')\n",
    "def weighted_mse_loss(input, target, weight):\n",
    "        return (weight * (input - target) ** 2).sum()\n",
    "out_range = [torch.quantile(Y, 0.01, 0).detach().cpu().numpy(), torch.quantile(Y, 0.99, 0).detach().cpu().numpy()]\n",
    "\n",
    "weight_1 = torch.tensor(1/(out_range[1] - out_range[0])**2)\n",
    "#for sim in range(0,4):\n",
    "for sim in [3, 19]:\n",
    "    \n",
    "    torch.manual_seed(1000 + sim)\n",
    "    indexes = torch.randperm(L_train + L_val)\n",
    "\n",
    "    # Divide Data\n",
    "    X_train = X[indexes[0:L_train]]\n",
    "    Y_train = Y[indexes[0:L_train]]\n",
    "\n",
    "    X_val = X[indexes[L_train:(L_train + L_val)]]\n",
    "    Y_val = Y[indexes[L_train:(L_train + L_val)]]\n",
    "\n",
    "    # Use torch.utils.data to create a DataLoader that will take care of creating batches\n",
    "    dataset = TensorDataset(X_train, Y_train)\n",
    "    dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle=True, generator=torch.Generator(device=device))\n",
    "\n",
    "    # Get the dataset size for printing (it is equal to N_SAMPLES)\n",
    "    dataset_size = len(dataloader.dataset)\n",
    "\n",
    "    # Define the input and output dimensions\n",
    "    D_in, D_out = X_train.size()[1], Y_train.size()[1]\n",
    "\n",
    "    # Create an instance of the Net class with specified dimensions\n",
    "    H, H2, H3 = 256, 256, 256\n",
    "    net = Net(D_in = D_in, D_out = D_out, H = H, H2 = H2, H3 = H3)\n",
    "\n",
    "    # Model name\n",
    "    model_save_name = 'infer_nets/net10/'+str(sim)+'.pt'\n",
    "    path = F\"./{model_save_name}\"\n",
    "\n",
    "    # The nn package also contains definitions of popular loss functions; in this case we will use Mean Squared Error (MSE) as our loss function.\n",
    "    #loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "    learning_rate = 1e-6\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "    train_error_plt = []\n",
    "    val_error_plt = []\n",
    "\n",
    "    torch.manual_seed(2000 + sim)\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        for id_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
    "            y_batch_pred = net(x_batch)\n",
    "            loss = weighted_mse_loss(y_batch, y_batch_pred, weight_1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % 30 ==0 and id_batch % 500 == 0:\n",
    "                loss, current = loss.item(), (id_batch + 1)* len(x_batch)\n",
    "                print(f\"train_loss: {loss/BATCH_SIZE:>7f}  [{current:>5d}/{dataset_size:>5d}]\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            theta_pred_train = net(X_train)\n",
    "            train_loss = weighted_mse_loss(Y_train, theta_pred_train, weight_1) / L_train\n",
    "           \n",
    "            train_error_plt = np.append(train_error_plt, train_loss.to(\"cpu\"))\n",
    "\n",
    "            theta_pred_val = net(X_val)\n",
    "            #val_loss = loss_fn(Y_val, theta_pred_val) / L_val\n",
    "            val_loss = weighted_mse_loss(Y_val, theta_pred_val, weight_1) / L_val\n",
    "         \n",
    "            val_error_plt = np.append(val_error_plt, val_loss.to(\"cpu\"))\n",
    "\n",
    "        if epoch % 10 ==0:\n",
    "            print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "            print(f\"train_loss {train_loss:>7f} val_loss {val_loss:>7f}\")\n",
    "            print(\"learning rate: \", learning_rate, \", sim: \", sim)\n",
    "\n",
    "        ## Choose Best Model\n",
    "        if val_error_plt[epoch] == np.min(val_error_plt):\n",
    "             best=epoch\n",
    "             torch.save(net.state_dict(), path)\n",
    "\n",
    "        if epoch % 100 ==99:\n",
    "            net.load_state_dict(torch.load(path))\n",
    "            learning_rate = max(learning_rate * 1e-1, 1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f1fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93730cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypackages2",
   "language": "python",
   "name": "mypackages2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
