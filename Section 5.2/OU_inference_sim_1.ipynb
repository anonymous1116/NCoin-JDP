{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456ad10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from DNN_module import Net\n",
    "\n",
    "%run ../NCoinDP_functions.ipynb\n",
    "torch.set_default_device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2dfb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2500000, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.load(\"infer_sim_1.pt\")\n",
    "a[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af5984c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1.0]\n",
      "train_loss: 0.202825  [   64/77000]\n",
      "train_loss: 0.193393  [ 6464/77000]\n",
      "train_loss: 0.201696  [12864/77000]\n",
      "train_loss: 0.191302  [19264/77000]\n",
      "train_loss: 0.198184  [25664/77000]\n",
      "train_loss: 0.193752  [32064/77000]\n",
      "train_loss: 0.174416  [38464/77000]\n",
      "train_loss: 0.193251  [44864/77000]\n",
      "train_loss: 0.181549  [51264/77000]\n",
      "train_loss: 0.179214  [57664/77000]\n",
      "train_loss: 0.189848  [64064/77000]\n",
      "train_loss: 0.187561  [70464/77000]\n",
      "train_loss: 0.184335  [76864/77000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.177986 val_loss 0.178510\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.020403 val_loss 0.020630\n",
      "train_loss: 0.022407  [   64/77000]\n",
      "train_loss: 0.019513  [ 6464/77000]\n",
      "train_loss: 0.023698  [12864/77000]\n",
      "train_loss: 0.014880  [19264/77000]\n",
      "train_loss: 0.018164  [25664/77000]\n",
      "train_loss: 0.018465  [32064/77000]\n",
      "train_loss: 0.021665  [38464/77000]\n",
      "train_loss: 0.021580  [44864/77000]\n",
      "train_loss: 0.017626  [51264/77000]\n",
      "train_loss: 0.028470  [57664/77000]\n",
      "train_loss: 0.017164  [64064/77000]\n",
      "train_loss: 0.027286  [70464/77000]\n",
      "train_loss: 0.021730  [76864/77000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.020353 val_loss 0.020596\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.020332 val_loss 0.020586\n",
      "0.020582462\n",
      "iter:  0 Val=  0.020582462\n",
      "train_loss: 0.190235  [   64/77000]\n",
      "train_loss: 0.206438  [ 6464/77000]\n",
      "train_loss: 0.190973  [12864/77000]\n",
      "train_loss: 0.222840  [19264/77000]\n",
      "train_loss: 0.180398  [25664/77000]\n",
      "train_loss: 0.197637  [32064/77000]\n",
      "train_loss: 0.207973  [38464/77000]\n",
      "train_loss: 0.191895  [44864/77000]\n",
      "train_loss: 0.181431  [51264/77000]\n",
      "train_loss: 0.169571  [57664/77000]\n",
      "train_loss: 0.175570  [64064/77000]\n",
      "train_loss: 0.169528  [70464/77000]\n",
      "train_loss: 0.166317  [76864/77000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.181855 val_loss 0.181199\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.021120 val_loss 0.021044\n",
      "train_loss: 0.020835  [   64/77000]\n",
      "train_loss: 0.023785  [ 6464/77000]\n",
      "train_loss: 0.022653  [12864/77000]\n",
      "train_loss: 0.021694  [19264/77000]\n",
      "train_loss: 0.023625  [25664/77000]\n",
      "train_loss: 0.020694  [32064/77000]\n",
      "train_loss: 0.025938  [38464/77000]\n",
      "train_loss: 0.022339  [44864/77000]\n",
      "train_loss: 0.016687  [51264/77000]\n",
      "train_loss: 0.021840  [57664/77000]\n",
      "train_loss: 0.017393  [64064/77000]\n",
      "train_loss: 0.020671  [70464/77000]\n",
      "train_loss: 0.021579  [76864/77000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.021073 val_loss 0.021024\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.021047 val_loss 0.021009\n",
      "0.020999726\n",
      "iter:  1 Val=  0.020582462\n",
      "train_loss: 0.190235  [   64/77000]\n",
      "train_loss: 0.206438  [ 6464/77000]\n",
      "train_loss: 0.190973  [12864/77000]\n",
      "train_loss: 0.222840  [19264/77000]\n",
      "train_loss: 0.180398  [25664/77000]\n",
      "train_loss: 0.197637  [32064/77000]\n",
      "train_loss: 0.207973  [38464/77000]\n",
      "train_loss: 0.191895  [44864/77000]\n",
      "train_loss: 0.181431  [51264/77000]\n",
      "train_loss: 0.169571  [57664/77000]\n",
      "train_loss: 0.175570  [64064/77000]\n",
      "train_loss: 0.169528  [70464/77000]\n",
      "train_loss: 0.166317  [76864/77000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.181855 val_loss 0.181199\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.021120 val_loss 0.021044\n",
      "train_loss: 0.020835  [   64/77000]\n",
      "train_loss: 0.023785  [ 6464/77000]\n",
      "train_loss: 0.022653  [12864/77000]\n",
      "train_loss: 0.021694  [19264/77000]\n",
      "train_loss: 0.023625  [25664/77000]\n",
      "train_loss: 0.020694  [32064/77000]\n",
      "train_loss: 0.025938  [38464/77000]\n",
      "train_loss: 0.022339  [44864/77000]\n",
      "train_loss: 0.016687  [51264/77000]\n",
      "train_loss: 0.021840  [57664/77000]\n",
      "train_loss: 0.017393  [64064/77000]\n",
      "train_loss: 0.020671  [70464/77000]\n",
      "train_loss: 0.021579  [76864/77000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.021073 val_loss 0.021024\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.021047 val_loss 0.021009\n",
      "0.020999726\n",
      "iter:  2 Val=  0.020582462\n",
      "train_loss: 0.190235  [   64/77000]\n",
      "train_loss: 0.189228  [ 6464/77000]\n",
      "train_loss: 0.159948  [12864/77000]\n",
      "train_loss: 0.179250  [19264/77000]\n",
      "train_loss: 0.131094  [25664/77000]\n",
      "train_loss: 0.138754  [32064/77000]\n",
      "train_loss: 0.138973  [38464/77000]\n",
      "train_loss: 0.120835  [44864/77000]\n",
      "train_loss: 0.105995  [51264/77000]\n",
      "train_loss: 0.089916  [57664/77000]\n",
      "train_loss: 0.089787  [64064/77000]\n",
      "train_loss: 0.079675  [70464/77000]\n",
      "train_loss: 0.074257  [76864/77000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.085936 val_loss 0.085509\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.021036 val_loss 0.021014\n",
      "train_loss: 0.020463  [   64/77000]\n",
      "train_loss: 0.024093  [ 6464/77000]\n",
      "train_loss: 0.022211  [12864/77000]\n",
      "train_loss: 0.021570  [19264/77000]\n",
      "train_loss: 0.023497  [25664/77000]\n",
      "train_loss: 0.020647  [32064/77000]\n",
      "train_loss: 0.025639  [38464/77000]\n",
      "train_loss: 0.022168  [44864/77000]\n",
      "train_loss: 0.016729  [51264/77000]\n",
      "train_loss: 0.021542  [57664/77000]\n",
      "train_loss: 0.017298  [64064/77000]\n",
      "train_loss: 0.020644  [70464/77000]\n",
      "train_loss: 0.021427  [76864/77000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.021040 val_loss 0.021045\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.020996 val_loss 0.021020\n",
      "0.020985194\n",
      "iter:  3 Val=  0.020582462\n",
      "train_loss: 0.190235  [   64/77000]\n",
      "train_loss: 0.101053  [ 6464/77000]\n",
      "train_loss: 0.046747  [12864/77000]\n",
      "train_loss: 0.044783  [19264/77000]\n",
      "train_loss: 0.020529  [25664/77000]\n",
      "train_loss: 0.024294  [32064/77000]\n",
      "train_loss: 0.024977  [38464/77000]\n",
      "train_loss: 0.021158  [44864/77000]\n",
      "train_loss: 0.021175  [51264/77000]\n",
      "train_loss: 0.016711  [57664/77000]\n",
      "train_loss: 0.018873  [64064/77000]\n",
      "train_loss: 0.016775  [70464/77000]\n",
      "train_loss: 0.019084  [76864/77000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.021477 val_loss 0.021333\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.021019 val_loss 0.020937\n",
      "train_loss: 0.020683  [   64/77000]\n",
      "train_loss: 0.024096  [ 6464/77000]\n",
      "train_loss: 0.022167  [12864/77000]\n",
      "train_loss: 0.021475  [19264/77000]\n",
      "train_loss: 0.023636  [25664/77000]\n",
      "train_loss: 0.020875  [32064/77000]\n",
      "train_loss: 0.025472  [38464/77000]\n",
      "train_loss: 0.022249  [44864/77000]\n",
      "train_loss: 0.016691  [51264/77000]\n",
      "train_loss: 0.021755  [57664/77000]\n",
      "train_loss: 0.017217  [64064/77000]\n",
      "train_loss: 0.021042  [70464/77000]\n",
      "train_loss: 0.021423  [76864/77000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.021075 val_loss 0.021003\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.021035 val_loss 0.020975\n",
      "0.020932728\n",
      "iter:  4 Val=  0.020582462\n",
      "train_loss: 0.190235  [   64/77000]\n",
      "train_loss: 0.101010  [ 6464/77000]\n",
      "train_loss: 0.046726  [12864/77000]\n",
      "train_loss: 0.044775  [19264/77000]\n",
      "train_loss: 0.020532  [25664/77000]\n",
      "train_loss: 0.024193  [32064/77000]\n",
      "train_loss: 0.024860  [38464/77000]\n",
      "train_loss: 0.021028  [44864/77000]\n",
      "train_loss: 0.020988  [51264/77000]\n",
      "train_loss: 0.016711  [57664/77000]\n",
      "train_loss: 0.019176  [64064/77000]\n",
      "train_loss: 0.016966  [70464/77000]\n",
      "train_loss: 0.018984  [76864/77000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.021461 val_loss 0.021327\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.020998 val_loss 0.020941\n",
      "train_loss: 0.020566  [   64/77000]\n",
      "train_loss: 0.024252  [ 6464/77000]\n",
      "train_loss: 0.022065  [12864/77000]\n",
      "train_loss: 0.021594  [19264/77000]\n",
      "train_loss: 0.023575  [25664/77000]\n",
      "train_loss: 0.020856  [32064/77000]\n",
      "train_loss: 0.025648  [38464/77000]\n",
      "train_loss: 0.022313  [44864/77000]\n",
      "train_loss: 0.016766  [51264/77000]\n",
      "train_loss: 0.021822  [57664/77000]\n",
      "train_loss: 0.017027  [64064/77000]\n",
      "train_loss: 0.020935  [70464/77000]\n",
      "train_loss: 0.021472  [76864/77000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.021070 val_loss 0.021032\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.020958 val_loss 0.020997\n",
      "0.020941116\n",
      "iter:  5 Val=  0.020582462\n",
      "train_loss: 0.190235  [   64/77000]\n",
      "train_loss: 0.206438  [ 6464/77000]\n",
      "train_loss: 0.190973  [12864/77000]\n",
      "train_loss: 0.222840  [19264/77000]\n",
      "train_loss: 0.180398  [25664/77000]\n",
      "train_loss: 0.197638  [32064/77000]\n",
      "train_loss: 0.207974  [38464/77000]\n",
      "train_loss: 0.191896  [44864/77000]\n",
      "train_loss: 0.181431  [51264/77000]\n",
      "train_loss: 0.169571  [57664/77000]\n",
      "train_loss: 0.175570  [64064/77000]\n",
      "train_loss: 0.169529  [70464/77000]\n",
      "train_loss: 0.166320  [76864/77000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.181858 val_loss 0.181201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.021120 val_loss 0.021044\n",
      "train_loss: 0.020833  [   64/77000]\n",
      "train_loss: 0.023791  [ 6464/77000]\n",
      "train_loss: 0.022642  [12864/77000]\n",
      "train_loss: 0.021709  [19264/77000]\n",
      "train_loss: 0.023629  [25664/77000]\n",
      "train_loss: 0.020698  [32064/77000]\n",
      "train_loss: 0.025929  [38464/77000]\n",
      "train_loss: 0.022345  [44864/77000]\n",
      "train_loss: 0.016671  [51264/77000]\n",
      "train_loss: 0.021829  [57664/77000]\n",
      "train_loss: 0.017406  [64064/77000]\n",
      "train_loss: 0.020672  [70464/77000]\n",
      "train_loss: 0.021584  [76864/77000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.021073 val_loss 0.021024\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.021047 val_loss 0.021009\n",
      "0.02100001\n",
      "iter:  6 Val=  0.020582462\n",
      "train_loss: 0.190235  [   64/77000]\n",
      "train_loss: 0.189228  [ 6464/77000]\n",
      "train_loss: 0.159948  [12864/77000]\n",
      "train_loss: 0.179250  [19264/77000]\n",
      "train_loss: 0.131094  [25664/77000]\n",
      "train_loss: 0.138754  [32064/77000]\n",
      "train_loss: 0.138973  [38464/77000]\n",
      "train_loss: 0.120835  [44864/77000]\n",
      "train_loss: 0.105995  [51264/77000]\n",
      "train_loss: 0.089916  [57664/77000]\n",
      "train_loss: 0.089787  [64064/77000]\n",
      "train_loss: 0.079675  [70464/77000]\n",
      "train_loss: 0.074257  [76864/77000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.085936 val_loss 0.085509\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.021036 val_loss 0.021014\n",
      "train_loss: 0.020463  [   64/77000]\n",
      "train_loss: 0.024093  [ 6464/77000]\n",
      "train_loss: 0.022211  [12864/77000]\n",
      "train_loss: 0.021570  [19264/77000]\n",
      "train_loss: 0.023497  [25664/77000]\n",
      "train_loss: 0.020647  [32064/77000]\n",
      "train_loss: 0.025639  [38464/77000]\n",
      "train_loss: 0.022168  [44864/77000]\n",
      "train_loss: 0.016729  [51264/77000]\n",
      "train_loss: 0.021542  [57664/77000]\n",
      "train_loss: 0.017298  [64064/77000]\n",
      "train_loss: 0.020644  [70464/77000]\n",
      "train_loss: 0.021427  [76864/77000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.021040 val_loss 0.021045\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.020996 val_loss 0.021020\n",
      "0.020985194\n",
      "iter:  7 Val=  0.020582462\n",
      "train_loss: 0.190235  [   64/77000]\n",
      "train_loss: 0.206438  [ 6464/77000]\n",
      "train_loss: 0.190973  [12864/77000]\n",
      "train_loss: 0.222840  [19264/77000]\n",
      "train_loss: 0.180398  [25664/77000]\n",
      "train_loss: 0.197637  [32064/77000]\n",
      "train_loss: 0.207973  [38464/77000]\n",
      "train_loss: 0.191895  [44864/77000]\n",
      "train_loss: 0.181431  [51264/77000]\n",
      "train_loss: 0.169571  [57664/77000]\n",
      "train_loss: 0.175570  [64064/77000]\n",
      "train_loss: 0.169528  [70464/77000]\n",
      "train_loss: 0.166317  [76864/77000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.181855 val_loss 0.181199\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.021120 val_loss 0.021044\n",
      "train_loss: 0.020835  [   64/77000]\n",
      "train_loss: 0.023785  [ 6464/77000]\n",
      "train_loss: 0.022653  [12864/77000]\n",
      "train_loss: 0.021694  [19264/77000]\n",
      "train_loss: 0.023625  [25664/77000]\n",
      "train_loss: 0.020694  [32064/77000]\n",
      "train_loss: 0.025938  [38464/77000]\n",
      "train_loss: 0.022339  [44864/77000]\n",
      "train_loss: 0.016687  [51264/77000]\n",
      "train_loss: 0.021840  [57664/77000]\n",
      "train_loss: 0.017393  [64064/77000]\n",
      "train_loss: 0.020671  [70464/77000]\n",
      "train_loss: 0.021579  [76864/77000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.021073 val_loss 0.021024\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.021047 val_loss 0.021009\n",
      "0.020999726\n",
      "iter:  8 Val=  0.020582462\n",
      "train_loss: 0.190235  [   64/77000]\n",
      "train_loss: 0.189228  [ 6464/77000]\n",
      "train_loss: 0.159948  [12864/77000]\n",
      "train_loss: 0.179251  [19264/77000]\n",
      "train_loss: 0.131095  [25664/77000]\n",
      "train_loss: 0.138760  [32064/77000]\n",
      "train_loss: 0.138963  [38464/77000]\n",
      "train_loss: 0.120832  [44864/77000]\n",
      "train_loss: 0.105993  [51264/77000]\n",
      "train_loss: 0.089935  [57664/77000]\n",
      "train_loss: 0.089797  [64064/77000]\n",
      "train_loss: 0.079683  [70464/77000]\n",
      "train_loss: 0.074266  [76864/77000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.085952 val_loss 0.085526\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.021033 val_loss 0.021012\n",
      "train_loss: 0.020505  [   64/77000]\n",
      "train_loss: 0.024063  [ 6464/77000]\n",
      "train_loss: 0.022165  [12864/77000]\n",
      "train_loss: 0.021637  [19264/77000]\n",
      "train_loss: 0.023496  [25664/77000]\n",
      "train_loss: 0.020737  [32064/77000]\n",
      "train_loss: 0.025709  [38464/77000]\n",
      "train_loss: 0.022152  [44864/77000]\n",
      "train_loss: 0.016664  [51264/77000]\n",
      "train_loss: 0.021585  [57664/77000]\n",
      "train_loss: 0.017259  [64064/77000]\n",
      "train_loss: 0.020632  [70464/77000]\n",
      "train_loss: 0.021426  [76864/77000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.021037 val_loss 0.021045\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.020994 val_loss 0.021022\n",
      "0.02099142\n",
      "iter:  9 Val=  0.020582462\n",
      "==================== sim:  0 =====================\n",
      "train_loss: 0.201579  [   64/77000]\n",
      "train_loss: 0.204175  [ 6464/77000]\n",
      "train_loss: 0.208071  [12864/77000]\n",
      "train_loss: 0.214744  [19264/77000]\n",
      "train_loss: 0.219879  [25664/77000]\n",
      "train_loss: 0.222435  [32064/77000]\n",
      "train_loss: 0.204235  [38464/77000]\n",
      "train_loss: 0.191757  [44864/77000]\n",
      "train_loss: 0.202068  [51264/77000]\n",
      "train_loss: 0.191419  [57664/77000]\n",
      "train_loss: 0.209259  [64064/77000]\n",
      "train_loss: 0.186077  [70464/77000]\n",
      "train_loss: 0.206888  [76864/77000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.185323 val_loss 0.185553\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.020345 val_loss 0.020404\n",
      "train_loss: 0.015410  [   64/77000]\n",
      "train_loss: 0.021049  [ 6464/77000]\n",
      "train_loss: 0.028687  [12864/77000]\n",
      "train_loss: 0.019202  [19264/77000]\n",
      "train_loss: 0.023848  [25664/77000]\n",
      "train_loss: 0.018531  [32064/77000]\n",
      "train_loss: 0.015486  [38464/77000]\n",
      "train_loss: 0.026891  [44864/77000]\n",
      "train_loss: 0.016639  [51264/77000]\n",
      "train_loss: 0.016367  [57664/77000]\n",
      "train_loss: 0.016738  [64064/77000]\n",
      "train_loss: 0.016882  [70464/77000]\n",
      "train_loss: 0.022517  [76864/77000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.020304 val_loss 0.020382\n"
     ]
    }
   ],
   "source": [
    "# Synthetic data for uncertainty\n",
    "tmp = \"infer_sim_1.pt\" # uniform prior\n",
    "tmp = torch.load(tmp)\n",
    "X = tmp[0]\n",
    "Y = tmp[1]\n",
    "\n",
    "# test data, but wanted to extract just a single (first) row\n",
    "n = 3000\n",
    "scenarios = [\"S1\", \"S2\", \"S3\"]\n",
    "test_save_name = '../test_data/OU_test_n'+ str(n) + '_' + scenarios[2] +'.pt'\n",
    "test = torch.load(test_save_name)\n",
    "torch.set_default_device(\"cpu\")\n",
    "\n",
    "# True parameter\n",
    "print(test[1][1])\n",
    "\n",
    "x0 = OU_summary(test[0][1])[0,:]\n",
    "x0 = torch.reshape(x0, (1,5))\n",
    "\n",
    "uncertainty_list = []\n",
    "r_list = [.05 ,.07, .10]\n",
    "for r in r_list:\n",
    "    for sim in range(3):\n",
    "        X = X.to(\"cpu\")\n",
    "        Y = Y.to(\"cpu\")\n",
    "        x0 = x0.to(\"cpu\")\n",
    "\n",
    "        L = X.size()[0]\n",
    "        L_train = 250000\n",
    "        L_val = 50000\n",
    "        L_cal = L - L_train - L_val\n",
    "\n",
    "        # Divide Data\n",
    "        X_cal = X[(L_train + L_val):].to(\"cpu\")\n",
    "        Y_cal = Y[(L_train + L_val):].to(\"cpu\")\n",
    "\n",
    "        model_save_name = str(sim) +'.pt'\n",
    "        path = F\"infer_nets/net1/{model_save_name}\"\n",
    "        torch.set_default_device(\"cpu\")\n",
    "\n",
    "        # load net\n",
    "        net = Net(D_in = 5, D_out = 3, H = 256, H2 = 256, H3 = 256)\n",
    "        net.load_state_dict(torch.load(path))\n",
    "        net.eval()\n",
    "\n",
    "        tmp = conf_inf_sd(x0, X_cal, Y_cal, net, r) # .05, .07, .10\n",
    "\n",
    "        uncertainty_list.append(tmp)\n",
    "        print(\"====================\", \"sim: \", sim, \"=====================\" )\n",
    "        torch.save(uncertainty_list, \"uncertainty_\" +str(r)+\"_1.pt\") # .05, .07, .10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb708ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      ".01\n",
      "coverage:  0.85 param:  kappa 0.819 mad:  0.006\n",
      "coverage:  0.9 param:  kappa 0.878 mad:  0.007\n",
      "coverage:  0.95 param:  kappa 0.926 mad:  0.004\n",
      "coverage:  0.85 param:  beta 0.845 mad:  0.012\n",
      "coverage:  0.9 param:  beta 0.893 mad:  0.01\n",
      "coverage:  0.95 param:  beta 0.948 mad:  0.006\n",
      "coverage:  0.85 param:  sigma2 0.786 mad:  0.055\n",
      "coverage:  0.9 param:  sigma2 0.855 mad:  0.049\n",
      "coverage:  0.95 param:  sigma2 0.923 mad:  0.027\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tmp = torch.load(\"uncertainty_10_1.pt\")\n",
    "print(len(tmp))\n",
    "print(\".10\")\n",
    "\n",
    "\n",
    "cvrg_results = np.zeros( (len(tmp),3,3 ))\n",
    "cvrg_results.shape\n",
    "\n",
    "# Read a CSV file into a DataFrame\n",
    "df = pd.read_csv('MCMC/MC_results_1.txt', sep=\"\\t\")\n",
    "MC_results = torch.tensor(df.values)\n",
    "\n",
    "param_name = [\"kappa\", \"beta\", \"sigma2\"]\n",
    "coverage = [0.85, 0.90, 0.95]\n",
    "\n",
    "for k in range(len(tmp)):\n",
    "    for i in range(3):\n",
    "        values = tmp[k][1][:,i].detach().cpu().numpy().tolist()\n",
    "        weights = tmp[k][0].numpy()\n",
    "        for j in range(3):\n",
    "            error_cvrg = 1-coverage[j]\n",
    "            interval = [error_cvrg/2, 1 - error_cvrg/2]\n",
    "            intvl = weighted_quantile(values, interval, weights)\n",
    "\n",
    "            cvrg = torch.sum((MC_results[:,i] < intvl[1]) & (intvl[0] < MC_results[:,i]))/MC_results.size()[0]\n",
    "            \n",
    "            cvrg_results[k,i,j] = cvrg.detach().cpu().numpy().tolist()\n",
    "            #print(\"coverage: \", coverage[j], param_name[i], \"inf_m: \", cov_m)\n",
    "            #print(\"coverage: \", coverage[j], param_name[i],\"inf_sd: \", cvrg)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        #print(\"coverage: \", coverage[j], \"param: \", param_name[i], round(np.mean(cvrg_results[:,i,j]),3), \"sd: \", round(np.std(cvrg_results[:,i,j]),3))\n",
    "        x = cvrg_results[:,i,j]\n",
    "        print(\"coverage: \", coverage[j], \"param: \", param_name[i], round(np.median(x),3), \"mad: \", round(np.median(np.absolute(x - np.median(x))),3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (My sbi_pack Kernel)",
   "language": "python",
   "name": "sbi_pack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
