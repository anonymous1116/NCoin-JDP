{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456ad10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from DNN_module import Net\n",
    "\n",
    "%run ../NCoinDP_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af5984c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n",
      "True\n",
      "NVIDIA A10\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "if torch.cuda.is_available(): \n",
    "    dev = \"cuda:0\" \n",
    "else: \n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc4bf06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 2.307885  [   64/250000]\n",
      "train_loss: 0.805660  [32064/250000]\n",
      "train_loss: 0.356383  [64064/250000]\n",
      "train_loss: 0.252312  [96064/250000]\n",
      "train_loss: 0.092206  [128064/250000]\n",
      "train_loss: 0.092058  [160064/250000]\n",
      "train_loss: 0.042132  [192064/250000]\n",
      "train_loss: 0.039139  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.021467 val_loss 0.021419\n",
      "learning rate:  1e-05 , sim:  0\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008743 val_loss 0.008766\n",
      "learning rate:  1e-05 , sim:  0\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.009294 val_loss 0.009324\n",
      "learning rate:  1e-05 , sim:  0\n",
      "train_loss: 0.007980  [   64/250000]\n",
      "train_loss: 0.009628  [32064/250000]\n",
      "train_loss: 0.008950  [64064/250000]\n",
      "train_loss: 0.010463  [96064/250000]\n",
      "train_loss: 0.009738  [128064/250000]\n",
      "train_loss: 0.010244  [160064/250000]\n",
      "train_loss: 0.008300  [192064/250000]\n",
      "train_loss: 0.008901  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008770 val_loss 0.008806\n",
      "learning rate:  1e-05 , sim:  0\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008694 val_loss 0.008714\n",
      "learning rate:  1e-05 , sim:  0\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008435 val_loss 0.008462\n",
      "learning rate:  1e-05 , sim:  0\n",
      "train_loss: 0.009069  [   64/250000]\n",
      "train_loss: 0.008352  [32064/250000]\n",
      "train_loss: 0.008441  [64064/250000]\n",
      "train_loss: 0.008042  [96064/250000]\n",
      "train_loss: 0.008163  [128064/250000]\n",
      "train_loss: 0.007392  [160064/250000]\n",
      "train_loss: 0.006861  [192064/250000]\n",
      "train_loss: 0.008847  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008734 val_loss 0.008765\n",
      "learning rate:  1e-05 , sim:  0\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008585 val_loss 0.008613\n",
      "learning rate:  1e-05 , sim:  0\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008585 val_loss 0.008622\n",
      "learning rate:  1e-05 , sim:  0\n",
      "train_loss: 0.010579  [   64/250000]\n",
      "train_loss: 0.006374  [32064/250000]\n",
      "train_loss: 0.009438  [64064/250000]\n",
      "train_loss: 0.008111  [96064/250000]\n",
      "train_loss: 0.007803  [128064/250000]\n",
      "train_loss: 0.009549  [160064/250000]\n",
      "train_loss: 0.009450  [192064/250000]\n",
      "train_loss: 0.007046  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008445 val_loss 0.008473\n",
      "learning rate:  1e-05 , sim:  0\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008928 val_loss 0.008964\n",
      "learning rate:  1.0000000000000002e-06 , sim:  0\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008595 val_loss 0.008630\n",
      "learning rate:  1.0000000000000002e-06 , sim:  0\n",
      "train_loss: 0.010369  [   64/250000]\n",
      "train_loss: 0.007560  [32064/250000]\n",
      "train_loss: 0.008526  [64064/250000]\n",
      "train_loss: 0.010569  [96064/250000]\n",
      "train_loss: 0.008291  [128064/250000]\n",
      "train_loss: 0.006629  [160064/250000]\n",
      "train_loss: 0.009311  [192064/250000]\n",
      "train_loss: 0.010451  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008544 val_loss 0.008574\n",
      "learning rate:  1.0000000000000002e-06 , sim:  0\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008512 val_loss 0.008521\n",
      "learning rate:  1.0000000000000002e-06 , sim:  0\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008406 val_loss 0.008432\n",
      "learning rate:  1.0000000000000002e-06 , sim:  0\n",
      "train_loss: 0.008626  [   64/250000]\n",
      "train_loss: 0.008512  [32064/250000]\n",
      "train_loss: 0.010551  [64064/250000]\n",
      "train_loss: 0.007872  [96064/250000]\n",
      "train_loss: 0.007289  [128064/250000]\n",
      "train_loss: 0.007156  [160064/250000]\n",
      "train_loss: 0.009329  [192064/250000]\n",
      "train_loss: 0.009089  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008723 val_loss 0.008747\n",
      "learning rate:  1.0000000000000002e-06 , sim:  0\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008383 val_loss 0.008409\n",
      "learning rate:  1.0000000000000002e-06 , sim:  0\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008305 val_loss 0.008342\n",
      "learning rate:  1.0000000000000002e-06 , sim:  0\n",
      "train_loss: 0.006984  [   64/250000]\n",
      "train_loss: 0.007619  [32064/250000]\n",
      "train_loss: 0.007432  [64064/250000]\n",
      "train_loss: 0.007651  [96064/250000]\n",
      "train_loss: 0.006494  [128064/250000]\n",
      "train_loss: 0.007945  [160064/250000]\n",
      "train_loss: 0.010587  [192064/250000]\n",
      "train_loss: 0.007310  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008281 val_loss 0.008312\n",
      "learning rate:  1.0000000000000002e-06 , sim:  0\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008922 val_loss 0.008960\n",
      "learning rate:  1.0000000000000002e-06 , sim:  0\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008460 val_loss 0.008486\n",
      "learning rate:  1.0000000000000002e-07 , sim:  0\n",
      "train_loss: 0.007701  [   64/250000]\n",
      "train_loss: 0.008243  [32064/250000]\n",
      "train_loss: 0.007488  [64064/250000]\n",
      "train_loss: 0.007476  [96064/250000]\n",
      "train_loss: 0.006322  [128064/250000]\n",
      "train_loss: 0.007228  [160064/250000]\n",
      "train_loss: 0.008279  [192064/250000]\n",
      "train_loss: 0.006781  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008317 val_loss 0.008359\n",
      "learning rate:  1.0000000000000002e-07 , sim:  0\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008722 val_loss 0.008754\n",
      "learning rate:  1.0000000000000002e-07 , sim:  0\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008668 val_loss 0.008697\n",
      "learning rate:  1.0000000000000002e-07 , sim:  0\n",
      "train_loss: 0.006842  [   64/250000]\n",
      "train_loss: 0.009344  [32064/250000]\n",
      "train_loss: 0.010152  [64064/250000]\n",
      "train_loss: 0.006085  [96064/250000]\n",
      "train_loss: 0.009436  [128064/250000]\n",
      "train_loss: 0.012630  [160064/250000]\n",
      "train_loss: 0.008017  [192064/250000]\n",
      "train_loss: 0.009655  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008301 val_loss 0.008326\n",
      "learning rate:  1.0000000000000002e-07 , sim:  0\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008589 val_loss 0.008622\n",
      "learning rate:  1.0000000000000002e-07 , sim:  0\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008260 val_loss 0.008307\n",
      "learning rate:  1.0000000000000002e-07 , sim:  0\n",
      "train_loss: 0.010325  [   64/250000]\n",
      "train_loss: 0.008749  [32064/250000]\n",
      "train_loss: 0.007388  [64064/250000]\n",
      "train_loss: 0.007506  [96064/250000]\n",
      "train_loss: 0.010058  [128064/250000]\n",
      "train_loss: 0.007559  [160064/250000]\n",
      "train_loss: 0.007194  [192064/250000]\n",
      "train_loss: 0.008296  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008394 val_loss 0.008434\n",
      "learning rate:  1.0000000000000002e-07 , sim:  0\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008259 val_loss 0.008311\n",
      "learning rate:  1.0000000000000002e-07 , sim:  0\n",
      "train_loss: 3.498030  [   64/250000]\n",
      "train_loss: 1.173016  [32064/250000]\n",
      "train_loss: 0.589630  [64064/250000]\n",
      "train_loss: 0.311780  [96064/250000]\n",
      "train_loss: 0.160823  [128064/250000]\n",
      "train_loss: 0.089446  [160064/250000]\n",
      "train_loss: 0.028648  [192064/250000]\n",
      "train_loss: 0.040586  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.026385 val_loss 0.026235\n",
      "learning rate:  1e-05 , sim:  1\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008972 val_loss 0.009032\n",
      "learning rate:  1e-05 , sim:  1\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008467 val_loss 0.008528\n",
      "learning rate:  1e-05 , sim:  1\n",
      "train_loss: 0.009586  [   64/250000]\n",
      "train_loss: 0.008602  [32064/250000]\n",
      "train_loss: 0.008906  [64064/250000]\n",
      "train_loss: 0.008665  [96064/250000]\n",
      "train_loss: 0.011316  [128064/250000]\n",
      "train_loss: 0.007154  [160064/250000]\n",
      "train_loss: 0.008149  [192064/250000]\n",
      "train_loss: 0.007160  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.009297 val_loss 0.009385\n",
      "learning rate:  1e-05 , sim:  1\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008739 val_loss 0.008821\n",
      "learning rate:  1e-05 , sim:  1\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008344 val_loss 0.008411\n",
      "learning rate:  1e-05 , sim:  1\n",
      "train_loss: 0.008390  [   64/250000]\n",
      "train_loss: 0.007349  [32064/250000]\n",
      "train_loss: 0.009077  [64064/250000]\n",
      "train_loss: 0.007061  [96064/250000]\n",
      "train_loss: 0.008789  [128064/250000]\n",
      "train_loss: 0.007075  [160064/250000]\n",
      "train_loss: 0.007839  [192064/250000]\n",
      "train_loss: 0.009299  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008365 val_loss 0.008446\n",
      "learning rate:  1e-05 , sim:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008356 val_loss 0.008442\n",
      "learning rate:  1e-05 , sim:  1\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008307 val_loss 0.008394\n",
      "learning rate:  1e-05 , sim:  1\n",
      "train_loss: 0.007863  [   64/250000]\n",
      "train_loss: 0.008050  [32064/250000]\n",
      "train_loss: 0.008211  [64064/250000]\n",
      "train_loss: 0.008258  [96064/250000]\n",
      "train_loss: 0.008226  [128064/250000]\n",
      "train_loss: 0.007793  [160064/250000]\n",
      "train_loss: 0.009242  [192064/250000]\n",
      "train_loss: 0.007698  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008331 val_loss 0.008409\n",
      "learning rate:  1e-05 , sim:  1\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008376 val_loss 0.008457\n",
      "learning rate:  1.0000000000000002e-06 , sim:  1\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008296 val_loss 0.008379\n",
      "learning rate:  1.0000000000000002e-06 , sim:  1\n",
      "train_loss: 0.008471  [   64/250000]\n",
      "train_loss: 0.008029  [32064/250000]\n",
      "train_loss: 0.008303  [64064/250000]\n",
      "train_loss: 0.005997  [96064/250000]\n",
      "train_loss: 0.009843  [128064/250000]\n",
      "train_loss: 0.011644  [160064/250000]\n",
      "train_loss: 0.009578  [192064/250000]\n",
      "train_loss: 0.009516  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008494 val_loss 0.008567\n",
      "learning rate:  1.0000000000000002e-06 , sim:  1\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008314 val_loss 0.008395\n",
      "learning rate:  1.0000000000000002e-06 , sim:  1\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008374 val_loss 0.008462\n",
      "learning rate:  1.0000000000000002e-06 , sim:  1\n",
      "train_loss: 0.009731  [   64/250000]\n",
      "train_loss: 0.008624  [32064/250000]\n",
      "train_loss: 0.008757  [64064/250000]\n",
      "train_loss: 0.008781  [96064/250000]\n",
      "train_loss: 0.006614  [128064/250000]\n",
      "train_loss: 0.008947  [160064/250000]\n",
      "train_loss: 0.010028  [192064/250000]\n",
      "train_loss: 0.007317  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008254 val_loss 0.008343\n",
      "learning rate:  1.0000000000000002e-06 , sim:  1\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008371 val_loss 0.008460\n",
      "learning rate:  1.0000000000000002e-06 , sim:  1\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008386 val_loss 0.008476\n",
      "learning rate:  1.0000000000000002e-06 , sim:  1\n",
      "train_loss: 0.009947  [   64/250000]\n",
      "train_loss: 0.006423  [32064/250000]\n",
      "train_loss: 0.007751  [64064/250000]\n",
      "train_loss: 0.009205  [96064/250000]\n",
      "train_loss: 0.008084  [128064/250000]\n",
      "train_loss: 0.008541  [160064/250000]\n",
      "train_loss: 0.007139  [192064/250000]\n",
      "train_loss: 0.007709  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008213 val_loss 0.008305\n",
      "learning rate:  1.0000000000000002e-06 , sim:  1\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008287 val_loss 0.008365\n",
      "learning rate:  1.0000000000000002e-06 , sim:  1\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008604 val_loss 0.008695\n",
      "learning rate:  1.0000000000000002e-07 , sim:  1\n",
      "train_loss: 0.008635  [   64/250000]\n",
      "train_loss: 0.008628  [32064/250000]\n",
      "train_loss: 0.007878  [64064/250000]\n",
      "train_loss: 0.008174  [96064/250000]\n",
      "train_loss: 0.007179  [128064/250000]\n",
      "train_loss: 0.006925  [160064/250000]\n",
      "train_loss: 0.008498  [192064/250000]\n",
      "train_loss: 0.007439  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008240 val_loss 0.008334\n",
      "learning rate:  1.0000000000000002e-07 , sim:  1\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008207 val_loss 0.008301\n",
      "learning rate:  1.0000000000000002e-07 , sim:  1\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008290 val_loss 0.008385\n",
      "learning rate:  1.0000000000000002e-07 , sim:  1\n",
      "train_loss: 0.008983  [   64/250000]\n",
      "train_loss: 0.007221  [32064/250000]\n",
      "train_loss: 0.009516  [64064/250000]\n",
      "train_loss: 0.007217  [96064/250000]\n",
      "train_loss: 0.008360  [128064/250000]\n",
      "train_loss: 0.007607  [160064/250000]\n",
      "train_loss: 0.008759  [192064/250000]\n",
      "train_loss: 0.008798  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008234 val_loss 0.008326\n",
      "learning rate:  1.0000000000000002e-07 , sim:  1\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008174 val_loss 0.008265\n",
      "learning rate:  1.0000000000000002e-07 , sim:  1\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008244 val_loss 0.008338\n",
      "learning rate:  1.0000000000000002e-07 , sim:  1\n",
      "train_loss: 0.007474  [   64/250000]\n",
      "train_loss: 0.008439  [32064/250000]\n",
      "train_loss: 0.009054  [64064/250000]\n",
      "train_loss: 0.006905  [96064/250000]\n",
      "train_loss: 0.007168  [128064/250000]\n",
      "train_loss: 0.007580  [160064/250000]\n",
      "train_loss: 0.012785  [192064/250000]\n",
      "train_loss: 0.008283  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008174 val_loss 0.008277\n",
      "learning rate:  1.0000000000000002e-07 , sim:  1\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008558 val_loss 0.008660\n",
      "learning rate:  1.0000000000000002e-07 , sim:  1\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008335 val_loss 0.008434\n",
      "learning rate:  1.0000000000000002e-07 , sim:  1\n",
      "train_loss: 4.244004  [   64/250000]\n",
      "train_loss: 1.608840  [32064/250000]\n",
      "train_loss: 0.787610  [64064/250000]\n",
      "train_loss: 0.435188  [96064/250000]\n",
      "train_loss: 0.223329  [128064/250000]\n",
      "train_loss: 0.090330  [160064/250000]\n",
      "train_loss: 0.047584  [192064/250000]\n",
      "train_loss: 0.034674  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.024594 val_loss 0.024492\n",
      "learning rate:  1e-05 , sim:  2\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008809 val_loss 0.008898\n",
      "learning rate:  1e-05 , sim:  2\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.009140 val_loss 0.009258\n",
      "learning rate:  1e-05 , sim:  2\n",
      "train_loss: 0.007509  [   64/250000]\n",
      "train_loss: 0.008942  [32064/250000]\n",
      "train_loss: 0.008473  [64064/250000]\n",
      "train_loss: 0.007805  [96064/250000]\n",
      "train_loss: 0.008809  [128064/250000]\n",
      "train_loss: 0.006646  [160064/250000]\n",
      "train_loss: 0.008741  [192064/250000]\n",
      "train_loss: 0.006658  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008801 val_loss 0.008909\n",
      "learning rate:  1e-05 , sim:  2\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008596 val_loss 0.008719\n",
      "learning rate:  1e-05 , sim:  2\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008456 val_loss 0.008585\n",
      "learning rate:  1e-05 , sim:  2\n",
      "train_loss: 0.009255  [   64/250000]\n",
      "train_loss: 0.009409  [32064/250000]\n",
      "train_loss: 0.008255  [64064/250000]\n",
      "train_loss: 0.008292  [96064/250000]\n",
      "train_loss: 0.008379  [128064/250000]\n",
      "train_loss: 0.007935  [160064/250000]\n",
      "train_loss: 0.009619  [192064/250000]\n",
      "train_loss: 0.008586  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008880 val_loss 0.009024\n",
      "learning rate:  1e-05 , sim:  2\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008655 val_loss 0.008791\n",
      "learning rate:  1e-05 , sim:  2\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008345 val_loss 0.008476\n",
      "learning rate:  1e-05 , sim:  2\n",
      "train_loss: 0.007350  [   64/250000]\n",
      "train_loss: 0.010058  [32064/250000]\n",
      "train_loss: 0.009736  [64064/250000]\n",
      "train_loss: 0.009159  [96064/250000]\n",
      "train_loss: 0.007228  [128064/250000]\n",
      "train_loss: 0.007599  [160064/250000]\n",
      "train_loss: 0.010639  [192064/250000]\n",
      "train_loss: 0.009899  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008429 val_loss 0.008562\n",
      "learning rate:  1e-05 , sim:  2\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008533 val_loss 0.008677\n",
      "learning rate:  1.0000000000000002e-06 , sim:  2\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008299 val_loss 0.008428\n",
      "learning rate:  1.0000000000000002e-06 , sim:  2\n",
      "train_loss: 0.008903  [   64/250000]\n",
      "train_loss: 0.009002  [32064/250000]\n",
      "train_loss: 0.007786  [64064/250000]\n",
      "train_loss: 0.008658  [96064/250000]\n",
      "train_loss: 0.007260  [128064/250000]\n",
      "train_loss: 0.008202  [160064/250000]\n",
      "train_loss: 0.008805  [192064/250000]\n",
      "train_loss: 0.007681  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008400 val_loss 0.008537\n",
      "learning rate:  1.0000000000000002e-06 , sim:  2\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008515 val_loss 0.008656\n",
      "learning rate:  1.0000000000000002e-06 , sim:  2\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008316 val_loss 0.008466\n",
      "learning rate:  1.0000000000000002e-06 , sim:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.006926  [   64/250000]\n",
      "train_loss: 0.009190  [32064/250000]\n",
      "train_loss: 0.007257  [64064/250000]\n",
      "train_loss: 0.009671  [96064/250000]\n",
      "train_loss: 0.009597  [128064/250000]\n",
      "train_loss: 0.007192  [160064/250000]\n",
      "train_loss: 0.008970  [192064/250000]\n",
      "train_loss: 0.008013  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008277 val_loss 0.008414\n",
      "learning rate:  1.0000000000000002e-06 , sim:  2\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008656 val_loss 0.008793\n",
      "learning rate:  1.0000000000000002e-06 , sim:  2\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008298 val_loss 0.008430\n",
      "learning rate:  1.0000000000000002e-06 , sim:  2\n",
      "train_loss: 0.008289  [   64/250000]\n",
      "train_loss: 0.008040  [32064/250000]\n",
      "train_loss: 0.007407  [64064/250000]\n",
      "train_loss: 0.008058  [96064/250000]\n",
      "train_loss: 0.008539  [128064/250000]\n",
      "train_loss: 0.008416  [160064/250000]\n",
      "train_loss: 0.007356  [192064/250000]\n",
      "train_loss: 0.008545  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008312 val_loss 0.008441\n",
      "learning rate:  1.0000000000000002e-06 , sim:  2\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008276 val_loss 0.008424\n",
      "learning rate:  1.0000000000000002e-06 , sim:  2\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008363 val_loss 0.008512\n",
      "learning rate:  1.0000000000000002e-07 , sim:  2\n",
      "train_loss: 0.009640  [   64/250000]\n",
      "train_loss: 0.010384  [32064/250000]\n",
      "train_loss: 0.009748  [64064/250000]\n",
      "train_loss: 0.007731  [96064/250000]\n",
      "train_loss: 0.008861  [128064/250000]\n",
      "train_loss: 0.007140  [160064/250000]\n",
      "train_loss: 0.009613  [192064/250000]\n",
      "train_loss: 0.007926  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008326 val_loss 0.008463\n",
      "learning rate:  1.0000000000000002e-07 , sim:  2\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008233 val_loss 0.008383\n",
      "learning rate:  1.0000000000000002e-07 , sim:  2\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008413 val_loss 0.008536\n",
      "learning rate:  1.0000000000000002e-07 , sim:  2\n",
      "train_loss: 0.007494  [   64/250000]\n",
      "train_loss: 0.008000  [32064/250000]\n",
      "train_loss: 0.009734  [64064/250000]\n",
      "train_loss: 0.008708  [96064/250000]\n",
      "train_loss: 0.011719  [128064/250000]\n",
      "train_loss: 0.006854  [160064/250000]\n",
      "train_loss: 0.009331  [192064/250000]\n",
      "train_loss: 0.006651  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008522 val_loss 0.008677\n",
      "learning rate:  1.0000000000000002e-07 , sim:  2\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008557 val_loss 0.008680\n",
      "learning rate:  1.0000000000000002e-07 , sim:  2\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008384 val_loss 0.008536\n",
      "learning rate:  1.0000000000000002e-07 , sim:  2\n",
      "train_loss: 0.006718  [   64/250000]\n",
      "train_loss: 0.008163  [32064/250000]\n",
      "train_loss: 0.009213  [64064/250000]\n",
      "train_loss: 0.008089  [96064/250000]\n",
      "train_loss: 0.008259  [128064/250000]\n",
      "train_loss: 0.008607  [160064/250000]\n",
      "train_loss: 0.008677  [192064/250000]\n",
      "train_loss: 0.007519  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008256 val_loss 0.008407\n",
      "learning rate:  1.0000000000000002e-07 , sim:  2\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008452 val_loss 0.008611\n",
      "learning rate:  1.0000000000000002e-07 , sim:  2\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008240 val_loss 0.008392\n",
      "learning rate:  1.0000000000000002e-07 , sim:  2\n",
      "train_loss: 3.270032  [   64/250000]\n",
      "train_loss: 1.155971  [32064/250000]\n",
      "train_loss: 0.570111  [64064/250000]\n",
      "train_loss: 0.322620  [96064/250000]\n",
      "train_loss: 0.147630  [128064/250000]\n",
      "train_loss: 0.069484  [160064/250000]\n",
      "train_loss: 0.046694  [192064/250000]\n",
      "train_loss: 0.058439  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.025006 val_loss 0.024870\n",
      "learning rate:  1e-05 , sim:  3\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008935 val_loss 0.009035\n",
      "learning rate:  1e-05 , sim:  3\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008592 val_loss 0.008695\n",
      "learning rate:  1e-05 , sim:  3\n",
      "train_loss: 0.010076  [   64/250000]\n",
      "train_loss: 0.008685  [32064/250000]\n",
      "train_loss: 0.010379  [64064/250000]\n",
      "train_loss: 0.009911  [96064/250000]\n",
      "train_loss: 0.007701  [128064/250000]\n",
      "train_loss: 0.006992  [160064/250000]\n",
      "train_loss: 0.009370  [192064/250000]\n",
      "train_loss: 0.008746  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008575 val_loss 0.008688\n",
      "learning rate:  1e-05 , sim:  3\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008552 val_loss 0.008661\n",
      "learning rate:  1e-05 , sim:  3\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008548 val_loss 0.008674\n",
      "learning rate:  1e-05 , sim:  3\n",
      "train_loss: 0.007106  [   64/250000]\n",
      "train_loss: 0.007067  [32064/250000]\n",
      "train_loss: 0.008817  [64064/250000]\n",
      "train_loss: 0.008268  [96064/250000]\n",
      "train_loss: 0.007376  [128064/250000]\n",
      "train_loss: 0.006621  [160064/250000]\n",
      "train_loss: 0.011548  [192064/250000]\n",
      "train_loss: 0.010749  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008509 val_loss 0.008624\n",
      "learning rate:  1e-05 , sim:  3\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008787 val_loss 0.008893\n",
      "learning rate:  1e-05 , sim:  3\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008631 val_loss 0.008752\n",
      "learning rate:  1e-05 , sim:  3\n",
      "train_loss: 0.008421  [   64/250000]\n",
      "train_loss: 0.006141  [32064/250000]\n",
      "train_loss: 0.006622  [64064/250000]\n",
      "train_loss: 0.012456  [96064/250000]\n",
      "train_loss: 0.007169  [128064/250000]\n",
      "train_loss: 0.009390  [160064/250000]\n",
      "train_loss: 0.011990  [192064/250000]\n",
      "train_loss: 0.008528  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008412 val_loss 0.008508\n",
      "learning rate:  1e-05 , sim:  3\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008725 val_loss 0.008849\n",
      "learning rate:  1.0000000000000002e-06 , sim:  3\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008454 val_loss 0.008556\n",
      "learning rate:  1.0000000000000002e-06 , sim:  3\n",
      "train_loss: 0.007661  [   64/250000]\n",
      "train_loss: 0.011513  [32064/250000]\n",
      "train_loss: 0.007552  [64064/250000]\n",
      "train_loss: 0.010807  [96064/250000]\n",
      "train_loss: 0.008618  [128064/250000]\n",
      "train_loss: 0.009158  [160064/250000]\n",
      "train_loss: 0.006058  [192064/250000]\n",
      "train_loss: 0.009281  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008521 val_loss 0.008635\n",
      "learning rate:  1.0000000000000002e-06 , sim:  3\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008793 val_loss 0.008924\n",
      "learning rate:  1.0000000000000002e-06 , sim:  3\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008330 val_loss 0.008442\n",
      "learning rate:  1.0000000000000002e-06 , sim:  3\n",
      "train_loss: 0.007713  [   64/250000]\n",
      "train_loss: 0.006705  [32064/250000]\n",
      "train_loss: 0.007100  [64064/250000]\n",
      "train_loss: 0.008696  [96064/250000]\n",
      "train_loss: 0.007504  [128064/250000]\n",
      "train_loss: 0.008070  [160064/250000]\n",
      "train_loss: 0.009321  [192064/250000]\n",
      "train_loss: 0.008392  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008402 val_loss 0.008516\n",
      "learning rate:  1.0000000000000002e-06 , sim:  3\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008334 val_loss 0.008461\n",
      "learning rate:  1.0000000000000002e-06 , sim:  3\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008405 val_loss 0.008525\n",
      "learning rate:  1.0000000000000002e-06 , sim:  3\n",
      "train_loss: 0.009659  [   64/250000]\n",
      "train_loss: 0.009552  [32064/250000]\n",
      "train_loss: 0.006787  [64064/250000]\n",
      "train_loss: 0.008344  [96064/250000]\n",
      "train_loss: 0.011708  [128064/250000]\n",
      "train_loss: 0.009097  [160064/250000]\n",
      "train_loss: 0.008772  [192064/250000]\n",
      "train_loss: 0.008701  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008355 val_loss 0.008479\n",
      "learning rate:  1.0000000000000002e-06 , sim:  3\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008346 val_loss 0.008458\n",
      "learning rate:  1.0000000000000002e-06 , sim:  3\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008359 val_loss 0.008474\n",
      "learning rate:  1.0000000000000002e-07 , sim:  3\n",
      "train_loss: 0.008420  [   64/250000]\n",
      "train_loss: 0.005619  [32064/250000]\n",
      "train_loss: 0.006661  [64064/250000]\n",
      "train_loss: 0.009197  [96064/250000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.010081  [128064/250000]\n",
      "train_loss: 0.008583  [160064/250000]\n",
      "train_loss: 0.006872  [192064/250000]\n",
      "train_loss: 0.006878  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008730 val_loss 0.008861\n",
      "learning rate:  1.0000000000000002e-07 , sim:  3\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.009138 val_loss 0.009281\n",
      "learning rate:  1.0000000000000002e-07 , sim:  3\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008376 val_loss 0.008495\n",
      "learning rate:  1.0000000000000002e-07 , sim:  3\n",
      "train_loss: 0.008098  [   64/250000]\n",
      "train_loss: 0.006379  [32064/250000]\n",
      "train_loss: 0.008225  [64064/250000]\n",
      "train_loss: 0.008993  [96064/250000]\n",
      "train_loss: 0.006837  [128064/250000]\n",
      "train_loss: 0.009353  [160064/250000]\n",
      "train_loss: 0.009722  [192064/250000]\n",
      "train_loss: 0.008918  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008348 val_loss 0.008454\n",
      "learning rate:  1.0000000000000002e-07 , sim:  3\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008435 val_loss 0.008558\n",
      "learning rate:  1.0000000000000002e-07 , sim:  3\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008484 val_loss 0.008591\n",
      "learning rate:  1.0000000000000002e-07 , sim:  3\n",
      "train_loss: 0.008594  [   64/250000]\n",
      "train_loss: 0.007792  [32064/250000]\n",
      "train_loss: 0.008437  [64064/250000]\n",
      "train_loss: 0.009016  [96064/250000]\n",
      "train_loss: 0.008631  [128064/250000]\n",
      "train_loss: 0.007379  [160064/250000]\n",
      "train_loss: 0.009090  [192064/250000]\n",
      "train_loss: 0.009123  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008426 val_loss 0.008546\n",
      "learning rate:  1.0000000000000002e-07 , sim:  3\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008248 val_loss 0.008380\n",
      "learning rate:  1.0000000000000002e-07 , sim:  3\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008298 val_loss 0.008426\n",
      "learning rate:  1.0000000000000002e-07 , sim:  3\n",
      "train_loss: 3.510737  [   64/250000]\n",
      "train_loss: 1.176612  [32064/250000]\n",
      "train_loss: 0.581175  [64064/250000]\n",
      "train_loss: 0.251520  [96064/250000]\n",
      "train_loss: 0.187845  [128064/250000]\n",
      "train_loss: 0.086227  [160064/250000]\n",
      "train_loss: 0.032621  [192064/250000]\n",
      "train_loss: 0.035401  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.020644 val_loss 0.020614\n",
      "learning rate:  1e-05 , sim:  4\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008786 val_loss 0.008836\n",
      "learning rate:  1e-05 , sim:  4\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008830 val_loss 0.008891\n",
      "learning rate:  1e-05 , sim:  4\n",
      "train_loss: 0.006658  [   64/250000]\n",
      "train_loss: 0.008767  [32064/250000]\n",
      "train_loss: 0.008566  [64064/250000]\n",
      "train_loss: 0.008503  [96064/250000]\n",
      "train_loss: 0.007744  [128064/250000]\n",
      "train_loss: 0.007307  [160064/250000]\n",
      "train_loss: 0.009254  [192064/250000]\n",
      "train_loss: 0.008472  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008453 val_loss 0.008519\n",
      "learning rate:  1e-05 , sim:  4\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008816 val_loss 0.008885\n",
      "learning rate:  1e-05 , sim:  4\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008751 val_loss 0.008819\n",
      "learning rate:  1e-05 , sim:  4\n",
      "train_loss: 0.008979  [   64/250000]\n",
      "train_loss: 0.007464  [32064/250000]\n",
      "train_loss: 0.008407  [64064/250000]\n",
      "train_loss: 0.010558  [96064/250000]\n",
      "train_loss: 0.010395  [128064/250000]\n",
      "train_loss: 0.008607  [160064/250000]\n",
      "train_loss: 0.006948  [192064/250000]\n",
      "train_loss: 0.008321  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008472 val_loss 0.008523\n",
      "learning rate:  1e-05 , sim:  4\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008481 val_loss 0.008589\n",
      "learning rate:  1e-05 , sim:  4\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008510 val_loss 0.008584\n",
      "learning rate:  1e-05 , sim:  4\n",
      "train_loss: 0.008336  [   64/250000]\n",
      "train_loss: 0.008013  [32064/250000]\n",
      "train_loss: 0.009067  [64064/250000]\n",
      "train_loss: 0.007325  [96064/250000]\n",
      "train_loss: 0.007543  [128064/250000]\n",
      "train_loss: 0.008063  [160064/250000]\n",
      "train_loss: 0.007395  [192064/250000]\n",
      "train_loss: 0.009560  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008594 val_loss 0.008668\n",
      "learning rate:  1e-05 , sim:  4\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008814 val_loss 0.008895\n",
      "learning rate:  1.0000000000000002e-06 , sim:  4\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008360 val_loss 0.008458\n",
      "learning rate:  1.0000000000000002e-06 , sim:  4\n",
      "train_loss: 0.008124  [   64/250000]\n",
      "train_loss: 0.008644  [32064/250000]\n",
      "train_loss: 0.008252  [64064/250000]\n",
      "train_loss: 0.008122  [96064/250000]\n",
      "train_loss: 0.008079  [128064/250000]\n",
      "train_loss: 0.007173  [160064/250000]\n",
      "train_loss: 0.008250  [192064/250000]\n",
      "train_loss: 0.007671  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008378 val_loss 0.008478\n",
      "learning rate:  1.0000000000000002e-06 , sim:  4\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008619 val_loss 0.008691\n",
      "learning rate:  1.0000000000000002e-06 , sim:  4\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008297 val_loss 0.008398\n",
      "learning rate:  1.0000000000000002e-06 , sim:  4\n",
      "train_loss: 0.009372  [   64/250000]\n",
      "train_loss: 0.008563  [32064/250000]\n",
      "train_loss: 0.009206  [64064/250000]\n",
      "train_loss: 0.007509  [96064/250000]\n",
      "train_loss: 0.010761  [128064/250000]\n",
      "train_loss: 0.008683  [160064/250000]\n",
      "train_loss: 0.008439  [192064/250000]\n",
      "train_loss: 0.009318  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008392 val_loss 0.008463\n",
      "learning rate:  1.0000000000000002e-06 , sim:  4\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008512 val_loss 0.008636\n",
      "learning rate:  1.0000000000000002e-06 , sim:  4\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008315 val_loss 0.008390\n",
      "learning rate:  1.0000000000000002e-06 , sim:  4\n",
      "train_loss: 0.007407  [   64/250000]\n",
      "train_loss: 0.007270  [32064/250000]\n",
      "train_loss: 0.009078  [64064/250000]\n",
      "train_loss: 0.009994  [96064/250000]\n",
      "train_loss: 0.010420  [128064/250000]\n",
      "train_loss: 0.007840  [160064/250000]\n",
      "train_loss: 0.007006  [192064/250000]\n",
      "train_loss: 0.007712  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008350 val_loss 0.008460\n",
      "learning rate:  1.0000000000000002e-06 , sim:  4\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008359 val_loss 0.008446\n",
      "learning rate:  1.0000000000000002e-06 , sim:  4\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008282 val_loss 0.008385\n",
      "learning rate:  1.0000000000000002e-07 , sim:  4\n",
      "train_loss: 0.008884  [   64/250000]\n",
      "train_loss: 0.008095  [32064/250000]\n",
      "train_loss: 0.008199  [64064/250000]\n",
      "train_loss: 0.007183  [96064/250000]\n",
      "train_loss: 0.007717  [128064/250000]\n",
      "train_loss: 0.008682  [160064/250000]\n",
      "train_loss: 0.008561  [192064/250000]\n",
      "train_loss: 0.010461  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008419 val_loss 0.008525\n",
      "learning rate:  1.0000000000000002e-07 , sim:  4\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008412 val_loss 0.008533\n",
      "learning rate:  1.0000000000000002e-07 , sim:  4\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008315 val_loss 0.008403\n",
      "learning rate:  1.0000000000000002e-07 , sim:  4\n",
      "train_loss: 0.007709  [   64/250000]\n",
      "train_loss: 0.007908  [32064/250000]\n",
      "train_loss: 0.007710  [64064/250000]\n",
      "train_loss: 0.008758  [96064/250000]\n",
      "train_loss: 0.008926  [128064/250000]\n",
      "train_loss: 0.008668  [160064/250000]\n",
      "train_loss: 0.008034  [192064/250000]\n",
      "train_loss: 0.008360  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008519 val_loss 0.008631\n",
      "learning rate:  1.0000000000000002e-07 , sim:  4\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008431 val_loss 0.008549\n",
      "learning rate:  1.0000000000000002e-07 , sim:  4\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008310 val_loss 0.008402\n",
      "learning rate:  1.0000000000000002e-07 , sim:  4\n",
      "train_loss: 0.008872  [   64/250000]\n",
      "train_loss: 0.007328  [32064/250000]\n",
      "train_loss: 0.009787  [64064/250000]\n",
      "train_loss: 0.007517  [96064/250000]\n",
      "train_loss: 0.012083  [128064/250000]\n",
      "train_loss: 0.008577  [160064/250000]\n",
      "train_loss: 0.008319  [192064/250000]\n",
      "train_loss: 0.006224  [224064/250000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008368 val_loss 0.008454\n",
      "learning rate:  1.0000000000000002e-07 , sim:  4\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008229 val_loss 0.008353\n",
      "learning rate:  1.0000000000000002e-07 , sim:  4\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008377 val_loss 0.008482\n",
      "learning rate:  1.0000000000000002e-07 , sim:  4\n",
      "train_loss: 3.195873  [   64/250000]\n",
      "train_loss: 1.273975  [32064/250000]\n",
      "train_loss: 0.648411  [64064/250000]\n",
      "train_loss: 0.237705  [96064/250000]\n",
      "train_loss: 0.170905  [128064/250000]\n",
      "train_loss: 0.066676  [160064/250000]\n",
      "train_loss: 0.038077  [192064/250000]\n",
      "train_loss: 0.025357  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.018783 val_loss 0.018740\n",
      "learning rate:  1e-05 , sim:  5\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.009116 val_loss 0.009129\n",
      "learning rate:  1e-05 , sim:  5\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008984 val_loss 0.009015\n",
      "learning rate:  1e-05 , sim:  5\n",
      "train_loss: 0.009401  [   64/250000]\n",
      "train_loss: 0.008782  [32064/250000]\n",
      "train_loss: 0.010358  [64064/250000]\n",
      "train_loss: 0.009442  [96064/250000]\n",
      "train_loss: 0.008148  [128064/250000]\n",
      "train_loss: 0.009588  [160064/250000]\n",
      "train_loss: 0.007569  [192064/250000]\n",
      "train_loss: 0.009036  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008912 val_loss 0.008935\n",
      "learning rate:  1e-05 , sim:  5\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008957 val_loss 0.008980\n",
      "learning rate:  1e-05 , sim:  5\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008890 val_loss 0.008894\n",
      "learning rate:  1e-05 , sim:  5\n",
      "train_loss: 0.009126  [   64/250000]\n",
      "train_loss: 0.008950  [32064/250000]\n",
      "train_loss: 0.010071  [64064/250000]\n",
      "train_loss: 0.011472  [96064/250000]\n",
      "train_loss: 0.008760  [128064/250000]\n",
      "train_loss: 0.008192  [160064/250000]\n",
      "train_loss: 0.007808  [192064/250000]\n",
      "train_loss: 0.007050  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008653 val_loss 0.008685\n",
      "learning rate:  1e-05 , sim:  5\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008376 val_loss 0.008422\n",
      "learning rate:  1e-05 , sim:  5\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008560 val_loss 0.008615\n",
      "learning rate:  1e-05 , sim:  5\n",
      "train_loss: 0.009029  [   64/250000]\n",
      "train_loss: 0.011710  [32064/250000]\n",
      "train_loss: 0.006644  [64064/250000]\n",
      "train_loss: 0.007912  [96064/250000]\n",
      "train_loss: 0.007390  [128064/250000]\n",
      "train_loss: 0.008353  [160064/250000]\n",
      "train_loss: 0.008260  [192064/250000]\n",
      "train_loss: 0.006765  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008404 val_loss 0.008442\n",
      "learning rate:  1e-05 , sim:  5\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.009470 val_loss 0.009512\n",
      "learning rate:  1.0000000000000002e-06 , sim:  5\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008940 val_loss 0.008975\n",
      "learning rate:  1.0000000000000002e-06 , sim:  5\n",
      "train_loss: 0.009980  [   64/250000]\n",
      "train_loss: 0.007543  [32064/250000]\n",
      "train_loss: 0.008344  [64064/250000]\n",
      "train_loss: 0.010515  [96064/250000]\n",
      "train_loss: 0.008885  [128064/250000]\n",
      "train_loss: 0.009391  [160064/250000]\n",
      "train_loss: 0.010095  [192064/250000]\n",
      "train_loss: 0.009587  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.009312 val_loss 0.009347\n",
      "learning rate:  1.0000000000000002e-06 , sim:  5\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008508 val_loss 0.008566\n",
      "learning rate:  1.0000000000000002e-06 , sim:  5\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008460 val_loss 0.008494\n",
      "learning rate:  1.0000000000000002e-06 , sim:  5\n",
      "train_loss: 0.008686  [   64/250000]\n",
      "train_loss: 0.008725  [32064/250000]\n",
      "train_loss: 0.009413  [64064/250000]\n",
      "train_loss: 0.007678  [96064/250000]\n",
      "train_loss: 0.006720  [128064/250000]\n",
      "train_loss: 0.009022  [160064/250000]\n",
      "train_loss: 0.007651  [192064/250000]\n",
      "train_loss: 0.009914  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008325 val_loss 0.008404\n",
      "learning rate:  1.0000000000000002e-06 , sim:  5\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008383 val_loss 0.008432\n",
      "learning rate:  1.0000000000000002e-06 , sim:  5\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008506 val_loss 0.008569\n",
      "learning rate:  1.0000000000000002e-06 , sim:  5\n",
      "train_loss: 0.005997  [   64/250000]\n",
      "train_loss: 0.009878  [32064/250000]\n",
      "train_loss: 0.009038  [64064/250000]\n",
      "train_loss: 0.010053  [96064/250000]\n",
      "train_loss: 0.007896  [128064/250000]\n",
      "train_loss: 0.010322  [160064/250000]\n",
      "train_loss: 0.008498  [192064/250000]\n",
      "train_loss: 0.007478  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008234 val_loss 0.008297\n",
      "learning rate:  1.0000000000000002e-06 , sim:  5\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008355 val_loss 0.008412\n",
      "learning rate:  1.0000000000000002e-06 , sim:  5\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008535 val_loss 0.008589\n",
      "learning rate:  1.0000000000000002e-07 , sim:  5\n",
      "train_loss: 0.007474  [   64/250000]\n",
      "train_loss: 0.007862  [32064/250000]\n",
      "train_loss: 0.008263  [64064/250000]\n",
      "train_loss: 0.007841  [96064/250000]\n",
      "train_loss: 0.007616  [128064/250000]\n",
      "train_loss: 0.007728  [160064/250000]\n",
      "train_loss: 0.012195  [192064/250000]\n",
      "train_loss: 0.007572  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008588 val_loss 0.008633\n",
      "learning rate:  1.0000000000000002e-07 , sim:  5\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008459 val_loss 0.008516\n",
      "learning rate:  1.0000000000000002e-07 , sim:  5\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.009178 val_loss 0.009225\n",
      "learning rate:  1.0000000000000002e-07 , sim:  5\n",
      "train_loss: 0.009369  [   64/250000]\n",
      "train_loss: 0.007535  [32064/250000]\n",
      "train_loss: 0.008877  [64064/250000]\n",
      "train_loss: 0.010664  [96064/250000]\n",
      "train_loss: 0.008350  [128064/250000]\n",
      "train_loss: 0.008804  [160064/250000]\n",
      "train_loss: 0.005599  [192064/250000]\n",
      "train_loss: 0.008828  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008561 val_loss 0.008619\n",
      "learning rate:  1.0000000000000002e-07 , sim:  5\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008326 val_loss 0.008361\n",
      "learning rate:  1.0000000000000002e-07 , sim:  5\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008416 val_loss 0.008456\n",
      "learning rate:  1.0000000000000002e-07 , sim:  5\n",
      "train_loss: 0.007778  [   64/250000]\n",
      "train_loss: 0.008484  [32064/250000]\n",
      "train_loss: 0.008304  [64064/250000]\n",
      "train_loss: 0.009406  [96064/250000]\n",
      "train_loss: 0.009121  [128064/250000]\n",
      "train_loss: 0.006910  [160064/250000]\n",
      "train_loss: 0.007895  [192064/250000]\n",
      "train_loss: 0.009041  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008301 val_loss 0.008357\n",
      "learning rate:  1.0000000000000002e-07 , sim:  5\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008324 val_loss 0.008395\n",
      "learning rate:  1.0000000000000002e-07 , sim:  5\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008290 val_loss 0.008338\n",
      "learning rate:  1.0000000000000002e-07 , sim:  5\n",
      "train_loss: 3.491805  [   64/250000]\n",
      "train_loss: 1.225080  [32064/250000]\n",
      "train_loss: 0.673074  [64064/250000]\n",
      "train_loss: 0.318569  [96064/250000]\n",
      "train_loss: 0.132580  [128064/250000]\n",
      "train_loss: 0.063393  [160064/250000]\n",
      "train_loss: 0.057625  [192064/250000]\n",
      "train_loss: 0.029080  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.020421 val_loss 0.020489\n",
      "learning rate:  1e-05 , sim:  6\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008787 val_loss 0.008858\n",
      "learning rate:  1e-05 , sim:  6\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008709 val_loss 0.008791\n",
      "learning rate:  1e-05 , sim:  6\n",
      "train_loss: 0.011177  [   64/250000]\n",
      "train_loss: 0.007288  [32064/250000]\n",
      "train_loss: 0.007537  [64064/250000]\n",
      "train_loss: 0.007341  [96064/250000]\n",
      "train_loss: 0.010930  [128064/250000]\n",
      "train_loss: 0.008111  [160064/250000]\n",
      "train_loss: 0.007368  [192064/250000]\n",
      "train_loss: 0.008009  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008513 val_loss 0.008599\n",
      "learning rate:  1e-05 , sim:  6\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008681 val_loss 0.008752\n",
      "learning rate:  1e-05 , sim:  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.009610 val_loss 0.009714\n",
      "learning rate:  1e-05 , sim:  6\n",
      "train_loss: 0.010243  [   64/250000]\n",
      "train_loss: 0.007580  [32064/250000]\n",
      "train_loss: 0.008021  [64064/250000]\n",
      "train_loss: 0.008856  [96064/250000]\n",
      "train_loss: 0.009412  [128064/250000]\n",
      "train_loss: 0.009291  [160064/250000]\n",
      "train_loss: 0.007491  [192064/250000]\n",
      "train_loss: 0.008218  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008686 val_loss 0.008749\n",
      "learning rate:  1e-05 , sim:  6\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.009002 val_loss 0.009089\n",
      "learning rate:  1e-05 , sim:  6\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008446 val_loss 0.008534\n",
      "learning rate:  1e-05 , sim:  6\n",
      "train_loss: 0.007581  [   64/250000]\n",
      "train_loss: 0.009254  [32064/250000]\n",
      "train_loss: 0.010057  [64064/250000]\n",
      "train_loss: 0.009433  [96064/250000]\n",
      "train_loss: 0.007777  [128064/250000]\n",
      "train_loss: 0.007484  [160064/250000]\n",
      "train_loss: 0.009357  [192064/250000]\n",
      "train_loss: 0.009406  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008420 val_loss 0.008520\n",
      "learning rate:  1e-05 , sim:  6\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008402 val_loss 0.008493\n",
      "learning rate:  1.0000000000000002e-06 , sim:  6\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008360 val_loss 0.008440\n",
      "learning rate:  1.0000000000000002e-06 , sim:  6\n",
      "train_loss: 0.009664  [   64/250000]\n",
      "train_loss: 0.005845  [32064/250000]\n",
      "train_loss: 0.005986  [64064/250000]\n",
      "train_loss: 0.008407  [96064/250000]\n",
      "train_loss: 0.009326  [128064/250000]\n",
      "train_loss: 0.008663  [160064/250000]\n",
      "train_loss: 0.008752  [192064/250000]\n",
      "train_loss: 0.008529  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008359 val_loss 0.008460\n",
      "learning rate:  1.0000000000000002e-06 , sim:  6\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008367 val_loss 0.008456\n",
      "learning rate:  1.0000000000000002e-06 , sim:  6\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008404 val_loss 0.008516\n",
      "learning rate:  1.0000000000000002e-06 , sim:  6\n",
      "train_loss: 0.008402  [   64/250000]\n",
      "train_loss: 0.008182  [32064/250000]\n",
      "train_loss: 0.008705  [64064/250000]\n",
      "train_loss: 0.008315  [96064/250000]\n",
      "train_loss: 0.009663  [128064/250000]\n",
      "train_loss: 0.008218  [160064/250000]\n",
      "train_loss: 0.007177  [192064/250000]\n",
      "train_loss: 0.010403  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008474 val_loss 0.008572\n",
      "learning rate:  1.0000000000000002e-06 , sim:  6\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008312 val_loss 0.008406\n",
      "learning rate:  1.0000000000000002e-06 , sim:  6\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008637 val_loss 0.008731\n",
      "learning rate:  1.0000000000000002e-06 , sim:  6\n",
      "train_loss: 0.008703  [   64/250000]\n",
      "train_loss: 0.007424  [32064/250000]\n",
      "train_loss: 0.009295  [64064/250000]\n",
      "train_loss: 0.007789  [96064/250000]\n",
      "train_loss: 0.009756  [128064/250000]\n",
      "train_loss: 0.009945  [160064/250000]\n",
      "train_loss: 0.008753  [192064/250000]\n",
      "train_loss: 0.006617  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008288 val_loss 0.008391\n",
      "learning rate:  1.0000000000000002e-06 , sim:  6\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008587 val_loss 0.008690\n",
      "learning rate:  1.0000000000000002e-06 , sim:  6\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008316 val_loss 0.008429\n",
      "learning rate:  1.0000000000000002e-07 , sim:  6\n",
      "train_loss: 0.008102  [   64/250000]\n",
      "train_loss: 0.009972  [32064/250000]\n",
      "train_loss: 0.006321  [64064/250000]\n",
      "train_loss: 0.008558  [96064/250000]\n",
      "train_loss: 0.008842  [128064/250000]\n",
      "train_loss: 0.008153  [160064/250000]\n",
      "train_loss: 0.007757  [192064/250000]\n",
      "train_loss: 0.008812  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.009174 val_loss 0.009298\n",
      "learning rate:  1.0000000000000002e-07 , sim:  6\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008329 val_loss 0.008441\n",
      "learning rate:  1.0000000000000002e-07 , sim:  6\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008532 val_loss 0.008635\n",
      "learning rate:  1.0000000000000002e-07 , sim:  6\n",
      "train_loss: 0.009007  [   64/250000]\n",
      "train_loss: 0.007918  [32064/250000]\n",
      "train_loss: 0.009526  [64064/250000]\n",
      "train_loss: 0.007891  [96064/250000]\n",
      "train_loss: 0.008886  [128064/250000]\n",
      "train_loss: 0.005553  [160064/250000]\n",
      "train_loss: 0.007372  [192064/250000]\n",
      "train_loss: 0.006607  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008425 val_loss 0.008526\n",
      "learning rate:  1.0000000000000002e-07 , sim:  6\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008566 val_loss 0.008662\n",
      "learning rate:  1.0000000000000002e-07 , sim:  6\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008284 val_loss 0.008416\n",
      "learning rate:  1.0000000000000002e-07 , sim:  6\n",
      "train_loss: 0.011099  [   64/250000]\n",
      "train_loss: 0.005246  [32064/250000]\n",
      "train_loss: 0.009676  [64064/250000]\n",
      "train_loss: 0.009442  [96064/250000]\n",
      "train_loss: 0.006058  [128064/250000]\n",
      "train_loss: 0.008765  [160064/250000]\n",
      "train_loss: 0.008264  [192064/250000]\n",
      "train_loss: 0.010224  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008239 val_loss 0.008373\n",
      "learning rate:  1.0000000000000002e-07 , sim:  6\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008482 val_loss 0.008600\n",
      "learning rate:  1.0000000000000002e-07 , sim:  6\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008269 val_loss 0.008391\n",
      "learning rate:  1.0000000000000002e-07 , sim:  6\n",
      "train_loss: 2.578070  [   64/250000]\n",
      "train_loss: 0.956119  [32064/250000]\n",
      "train_loss: 0.488657  [64064/250000]\n",
      "train_loss: 0.250454  [96064/250000]\n",
      "train_loss: 0.140328  [128064/250000]\n",
      "train_loss: 0.060540  [160064/250000]\n",
      "train_loss: 0.049546  [192064/250000]\n",
      "train_loss: 0.029722  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.019808 val_loss 0.019833\n",
      "learning rate:  1e-05 , sim:  7\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008891 val_loss 0.008979\n",
      "learning rate:  1e-05 , sim:  7\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008721 val_loss 0.008838\n",
      "learning rate:  1e-05 , sim:  7\n",
      "train_loss: 0.009962  [   64/250000]\n",
      "train_loss: 0.009000  [32064/250000]\n",
      "train_loss: 0.008816  [64064/250000]\n",
      "train_loss: 0.009950  [96064/250000]\n",
      "train_loss: 0.009206  [128064/250000]\n",
      "train_loss: 0.008013  [160064/250000]\n",
      "train_loss: 0.011514  [192064/250000]\n",
      "train_loss: 0.008993  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008582 val_loss 0.008699\n",
      "learning rate:  1e-05 , sim:  7\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008371 val_loss 0.008475\n",
      "learning rate:  1e-05 , sim:  7\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008487 val_loss 0.008596\n",
      "learning rate:  1e-05 , sim:  7\n",
      "train_loss: 0.007373  [   64/250000]\n",
      "train_loss: 0.009087  [32064/250000]\n",
      "train_loss: 0.007232  [64064/250000]\n",
      "train_loss: 0.008619  [96064/250000]\n",
      "train_loss: 0.009594  [128064/250000]\n",
      "train_loss: 0.007568  [160064/250000]\n",
      "train_loss: 0.008490  [192064/250000]\n",
      "train_loss: 0.011209  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008466 val_loss 0.008564\n",
      "learning rate:  1e-05 , sim:  7\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008398 val_loss 0.008508\n",
      "learning rate:  1e-05 , sim:  7\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008392 val_loss 0.008513\n",
      "learning rate:  1e-05 , sim:  7\n",
      "train_loss: 0.006722  [   64/250000]\n",
      "train_loss: 0.008043  [32064/250000]\n",
      "train_loss: 0.007412  [64064/250000]\n",
      "train_loss: 0.009191  [96064/250000]\n",
      "train_loss: 0.008635  [128064/250000]\n",
      "train_loss: 0.007483  [160064/250000]\n",
      "train_loss: 0.009166  [192064/250000]\n",
      "train_loss: 0.008236  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008332 val_loss 0.008460\n",
      "learning rate:  1e-05 , sim:  7\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008532 val_loss 0.008660\n",
      "learning rate:  1.0000000000000002e-06 , sim:  7\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008567 val_loss 0.008703\n",
      "learning rate:  1.0000000000000002e-06 , sim:  7\n",
      "train_loss: 0.009454  [   64/250000]\n",
      "train_loss: 0.007430  [32064/250000]\n",
      "train_loss: 0.008000  [64064/250000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.011687  [96064/250000]\n",
      "train_loss: 0.009090  [128064/250000]\n",
      "train_loss: 0.006880  [160064/250000]\n",
      "train_loss: 0.007545  [192064/250000]\n",
      "train_loss: 0.007361  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008877 val_loss 0.009008\n",
      "learning rate:  1.0000000000000002e-06 , sim:  7\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008287 val_loss 0.008413\n",
      "learning rate:  1.0000000000000002e-06 , sim:  7\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008299 val_loss 0.008437\n",
      "learning rate:  1.0000000000000002e-06 , sim:  7\n",
      "train_loss: 0.006815  [   64/250000]\n",
      "train_loss: 0.007945  [32064/250000]\n",
      "train_loss: 0.007272  [64064/250000]\n",
      "train_loss: 0.006680  [96064/250000]\n",
      "train_loss: 0.008380  [128064/250000]\n",
      "train_loss: 0.009333  [160064/250000]\n",
      "train_loss: 0.008530  [192064/250000]\n",
      "train_loss: 0.007478  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008463 val_loss 0.008607\n",
      "learning rate:  1.0000000000000002e-06 , sim:  7\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008369 val_loss 0.008506\n",
      "learning rate:  1.0000000000000002e-06 , sim:  7\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008279 val_loss 0.008408\n",
      "learning rate:  1.0000000000000002e-06 , sim:  7\n",
      "train_loss: 0.006432  [   64/250000]\n",
      "train_loss: 0.008314  [32064/250000]\n",
      "train_loss: 0.006863  [64064/250000]\n",
      "train_loss: 0.007833  [96064/250000]\n",
      "train_loss: 0.009261  [128064/250000]\n",
      "train_loss: 0.006532  [160064/250000]\n",
      "train_loss: 0.006484  [192064/250000]\n",
      "train_loss: 0.009844  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008297 val_loss 0.008431\n",
      "learning rate:  1.0000000000000002e-06 , sim:  7\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008288 val_loss 0.008417\n",
      "learning rate:  1.0000000000000002e-06 , sim:  7\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008278 val_loss 0.008410\n",
      "learning rate:  1.0000000000000002e-07 , sim:  7\n",
      "train_loss: 0.005580  [   64/250000]\n",
      "train_loss: 0.008627  [32064/250000]\n",
      "train_loss: 0.007936  [64064/250000]\n",
      "train_loss: 0.011318  [96064/250000]\n",
      "train_loss: 0.012909  [128064/250000]\n",
      "train_loss: 0.008786  [160064/250000]\n",
      "train_loss: 0.010067  [192064/250000]\n",
      "train_loss: 0.008101  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008206 val_loss 0.008323\n",
      "learning rate:  1.0000000000000002e-07 , sim:  7\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008257 val_loss 0.008382\n",
      "learning rate:  1.0000000000000002e-07 , sim:  7\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008257 val_loss 0.008403\n",
      "learning rate:  1.0000000000000002e-07 , sim:  7\n",
      "train_loss: 0.007665  [   64/250000]\n",
      "train_loss: 0.008213  [32064/250000]\n",
      "train_loss: 0.008336  [64064/250000]\n",
      "train_loss: 0.010471  [96064/250000]\n",
      "train_loss: 0.008257  [128064/250000]\n",
      "train_loss: 0.008799  [160064/250000]\n",
      "train_loss: 0.006047  [192064/250000]\n",
      "train_loss: 0.007629  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008252 val_loss 0.008387\n",
      "learning rate:  1.0000000000000002e-07 , sim:  7\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008309 val_loss 0.008452\n",
      "learning rate:  1.0000000000000002e-07 , sim:  7\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008192 val_loss 0.008330\n",
      "learning rate:  1.0000000000000002e-07 , sim:  7\n",
      "train_loss: 0.009785  [   64/250000]\n",
      "train_loss: 0.007995  [32064/250000]\n",
      "train_loss: 0.010488  [64064/250000]\n",
      "train_loss: 0.008013  [96064/250000]\n",
      "train_loss: 0.007188  [128064/250000]\n",
      "train_loss: 0.007893  [160064/250000]\n",
      "train_loss: 0.009806  [192064/250000]\n",
      "train_loss: 0.009612  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008391 val_loss 0.008529\n",
      "learning rate:  1.0000000000000002e-07 , sim:  7\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008358 val_loss 0.008484\n",
      "learning rate:  1.0000000000000002e-07 , sim:  7\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008317 val_loss 0.008453\n",
      "learning rate:  1.0000000000000002e-07 , sim:  7\n",
      "train_loss: 2.514433  [   64/250000]\n",
      "train_loss: 0.833625  [32064/250000]\n",
      "train_loss: 0.366169  [64064/250000]\n",
      "train_loss: 0.223146  [96064/250000]\n",
      "train_loss: 0.122467  [128064/250000]\n",
      "train_loss: 0.091990  [160064/250000]\n",
      "train_loss: 0.038055  [192064/250000]\n",
      "train_loss: 0.037116  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.023451 val_loss 0.023653\n",
      "learning rate:  1e-05 , sim:  8\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.010052 val_loss 0.010072\n",
      "learning rate:  1e-05 , sim:  8\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.009163 val_loss 0.009180\n",
      "learning rate:  1e-05 , sim:  8\n",
      "train_loss: 0.006977  [   64/250000]\n",
      "train_loss: 0.006812  [32064/250000]\n",
      "train_loss: 0.008780  [64064/250000]\n",
      "train_loss: 0.009123  [96064/250000]\n",
      "train_loss: 0.011565  [128064/250000]\n",
      "train_loss: 0.010374  [160064/250000]\n",
      "train_loss: 0.008898  [192064/250000]\n",
      "train_loss: 0.008572  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008758 val_loss 0.008778\n",
      "learning rate:  1e-05 , sim:  8\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008691 val_loss 0.008733\n",
      "learning rate:  1e-05 , sim:  8\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008776 val_loss 0.008810\n",
      "learning rate:  1e-05 , sim:  8\n",
      "train_loss: 0.009584  [   64/250000]\n",
      "train_loss: 0.009483  [32064/250000]\n",
      "train_loss: 0.009406  [64064/250000]\n",
      "train_loss: 0.009067  [96064/250000]\n",
      "train_loss: 0.007963  [128064/250000]\n",
      "train_loss: 0.008329  [160064/250000]\n",
      "train_loss: 0.008083  [192064/250000]\n",
      "train_loss: 0.010077  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008634 val_loss 0.008667\n",
      "learning rate:  1e-05 , sim:  8\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008745 val_loss 0.008785\n",
      "learning rate:  1e-05 , sim:  8\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.009307 val_loss 0.009369\n",
      "learning rate:  1e-05 , sim:  8\n",
      "train_loss: 0.009549  [   64/250000]\n",
      "train_loss: 0.008206  [32064/250000]\n",
      "train_loss: 0.010675  [64064/250000]\n",
      "train_loss: 0.007937  [96064/250000]\n",
      "train_loss: 0.007927  [128064/250000]\n",
      "train_loss: 0.006601  [160064/250000]\n",
      "train_loss: 0.010395  [192064/250000]\n",
      "train_loss: 0.009680  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008334 val_loss 0.008378\n",
      "learning rate:  1e-05 , sim:  8\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008394 val_loss 0.008438\n",
      "learning rate:  1.0000000000000002e-06 , sim:  8\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008357 val_loss 0.008407\n",
      "learning rate:  1.0000000000000002e-06 , sim:  8\n",
      "train_loss: 0.006802  [   64/250000]\n",
      "train_loss: 0.011058  [32064/250000]\n",
      "train_loss: 0.007481  [64064/250000]\n",
      "train_loss: 0.009613  [96064/250000]\n",
      "train_loss: 0.008961  [128064/250000]\n",
      "train_loss: 0.007377  [160064/250000]\n",
      "train_loss: 0.009184  [192064/250000]\n",
      "train_loss: 0.008493  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008485 val_loss 0.008536\n",
      "learning rate:  1.0000000000000002e-06 , sim:  8\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008405 val_loss 0.008451\n",
      "learning rate:  1.0000000000000002e-06 , sim:  8\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008261 val_loss 0.008316\n",
      "learning rate:  1.0000000000000002e-06 , sim:  8\n",
      "train_loss: 0.012684  [   64/250000]\n",
      "train_loss: 0.008448  [32064/250000]\n",
      "train_loss: 0.010912  [64064/250000]\n",
      "train_loss: 0.010985  [96064/250000]\n",
      "train_loss: 0.009533  [128064/250000]\n",
      "train_loss: 0.008740  [160064/250000]\n",
      "train_loss: 0.009312  [192064/250000]\n",
      "train_loss: 0.007114  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008551 val_loss 0.008614\n",
      "learning rate:  1.0000000000000002e-06 , sim:  8\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008398 val_loss 0.008445\n",
      "learning rate:  1.0000000000000002e-06 , sim:  8\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008264 val_loss 0.008316\n",
      "learning rate:  1.0000000000000002e-06 , sim:  8\n",
      "train_loss: 0.011448  [   64/250000]\n",
      "train_loss: 0.007427  [32064/250000]\n",
      "train_loss: 0.007431  [64064/250000]\n",
      "train_loss: 0.009413  [96064/250000]\n",
      "train_loss: 0.007133  [128064/250000]\n",
      "train_loss: 0.008192  [160064/250000]\n",
      "train_loss: 0.006364  [192064/250000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.007176  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008406 val_loss 0.008459\n",
      "learning rate:  1.0000000000000002e-06 , sim:  8\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008238 val_loss 0.008295\n",
      "learning rate:  1.0000000000000002e-06 , sim:  8\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008374 val_loss 0.008438\n",
      "learning rate:  1.0000000000000002e-07 , sim:  8\n",
      "train_loss: 0.009477  [   64/250000]\n",
      "train_loss: 0.007538  [32064/250000]\n",
      "train_loss: 0.010475  [64064/250000]\n",
      "train_loss: 0.007333  [96064/250000]\n",
      "train_loss: 0.007165  [128064/250000]\n",
      "train_loss: 0.009386  [160064/250000]\n",
      "train_loss: 0.011826  [192064/250000]\n",
      "train_loss: 0.008506  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008443 val_loss 0.008509\n",
      "learning rate:  1.0000000000000002e-07 , sim:  8\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008598 val_loss 0.008645\n",
      "learning rate:  1.0000000000000002e-07 , sim:  8\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008358 val_loss 0.008422\n",
      "learning rate:  1.0000000000000002e-07 , sim:  8\n",
      "train_loss: 0.006594  [   64/250000]\n",
      "train_loss: 0.008904  [32064/250000]\n",
      "train_loss: 0.008142  [64064/250000]\n",
      "train_loss: 0.006741  [96064/250000]\n",
      "train_loss: 0.008305  [128064/250000]\n",
      "train_loss: 0.007474  [160064/250000]\n",
      "train_loss: 0.011990  [192064/250000]\n",
      "train_loss: 0.007187  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008476 val_loss 0.008542\n",
      "learning rate:  1.0000000000000002e-07 , sim:  8\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008260 val_loss 0.008328\n",
      "learning rate:  1.0000000000000002e-07 , sim:  8\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008348 val_loss 0.008408\n",
      "learning rate:  1.0000000000000002e-07 , sim:  8\n",
      "train_loss: 0.007190  [   64/250000]\n",
      "train_loss: 0.010114  [32064/250000]\n",
      "train_loss: 0.007923  [64064/250000]\n",
      "train_loss: 0.007510  [96064/250000]\n",
      "train_loss: 0.007246  [128064/250000]\n",
      "train_loss: 0.008535  [160064/250000]\n",
      "train_loss: 0.005784  [192064/250000]\n",
      "train_loss: 0.009437  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008659 val_loss 0.008699\n",
      "learning rate:  1.0000000000000002e-07 , sim:  8\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008289 val_loss 0.008345\n",
      "learning rate:  1.0000000000000002e-07 , sim:  8\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008442 val_loss 0.008501\n",
      "learning rate:  1.0000000000000002e-07 , sim:  8\n",
      "train_loss: 2.047994  [   64/250000]\n",
      "train_loss: 0.680086  [32064/250000]\n",
      "train_loss: 0.352208  [64064/250000]\n",
      "train_loss: 0.126525  [96064/250000]\n",
      "train_loss: 0.118914  [128064/250000]\n",
      "train_loss: 0.036130  [160064/250000]\n",
      "train_loss: 0.026728  [192064/250000]\n",
      "train_loss: 0.047677  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.018393 val_loss 0.018426\n",
      "learning rate:  1e-05 , sim:  9\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008752 val_loss 0.008891\n",
      "learning rate:  1e-05 , sim:  9\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008765 val_loss 0.008909\n",
      "learning rate:  1e-05 , sim:  9\n",
      "train_loss: 0.008070  [   64/250000]\n",
      "train_loss: 0.009525  [32064/250000]\n",
      "train_loss: 0.008007  [64064/250000]\n",
      "train_loss: 0.008553  [96064/250000]\n",
      "train_loss: 0.007883  [128064/250000]\n",
      "train_loss: 0.009317  [160064/250000]\n",
      "train_loss: 0.010330  [192064/250000]\n",
      "train_loss: 0.008022  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.010838 val_loss 0.011079\n",
      "learning rate:  1e-05 , sim:  9\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008604 val_loss 0.008791\n",
      "learning rate:  1e-05 , sim:  9\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008881 val_loss 0.009059\n",
      "learning rate:  1e-05 , sim:  9\n",
      "train_loss: 0.009697  [   64/250000]\n",
      "train_loss: 0.013088  [32064/250000]\n",
      "train_loss: 0.009898  [64064/250000]\n",
      "train_loss: 0.008237  [96064/250000]\n",
      "train_loss: 0.007911  [128064/250000]\n",
      "train_loss: 0.009708  [160064/250000]\n",
      "train_loss: 0.008736  [192064/250000]\n",
      "train_loss: 0.007221  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008722 val_loss 0.008911\n",
      "learning rate:  1e-05 , sim:  9\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008511 val_loss 0.008697\n",
      "learning rate:  1e-05 , sim:  9\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008533 val_loss 0.008706\n",
      "learning rate:  1e-05 , sim:  9\n",
      "train_loss: 0.006997  [   64/250000]\n",
      "train_loss: 0.007295  [32064/250000]\n",
      "train_loss: 0.007571  [64064/250000]\n",
      "train_loss: 0.008443  [96064/250000]\n",
      "train_loss: 0.008480  [128064/250000]\n",
      "train_loss: 0.010478  [160064/250000]\n",
      "train_loss: 0.009375  [192064/250000]\n",
      "train_loss: 0.008518  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008631 val_loss 0.008796\n",
      "learning rate:  1e-05 , sim:  9\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008640 val_loss 0.008797\n",
      "learning rate:  1.0000000000000002e-06 , sim:  9\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008690 val_loss 0.008836\n",
      "learning rate:  1.0000000000000002e-06 , sim:  9\n",
      "train_loss: 0.007942  [   64/250000]\n",
      "train_loss: 0.008216  [32064/250000]\n",
      "train_loss: 0.011305  [64064/250000]\n",
      "train_loss: 0.009169  [96064/250000]\n",
      "train_loss: 0.010183  [128064/250000]\n",
      "train_loss: 0.009360  [160064/250000]\n",
      "train_loss: 0.009701  [192064/250000]\n",
      "train_loss: 0.009115  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008724 val_loss 0.008881\n",
      "learning rate:  1.0000000000000002e-06 , sim:  9\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008450 val_loss 0.008640\n",
      "learning rate:  1.0000000000000002e-06 , sim:  9\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008780 val_loss 0.008918\n",
      "learning rate:  1.0000000000000002e-06 , sim:  9\n",
      "train_loss: 0.008082  [   64/250000]\n",
      "train_loss: 0.008060  [32064/250000]\n",
      "train_loss: 0.009111  [64064/250000]\n",
      "train_loss: 0.007356  [96064/250000]\n",
      "train_loss: 0.007388  [128064/250000]\n",
      "train_loss: 0.006711  [160064/250000]\n",
      "train_loss: 0.009909  [192064/250000]\n",
      "train_loss: 0.009431  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008641 val_loss 0.008833\n",
      "learning rate:  1.0000000000000002e-06 , sim:  9\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008223 val_loss 0.008408\n",
      "learning rate:  1.0000000000000002e-06 , sim:  9\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008579 val_loss 0.008743\n",
      "learning rate:  1.0000000000000002e-06 , sim:  9\n",
      "train_loss: 0.008930  [   64/250000]\n",
      "train_loss: 0.009298  [32064/250000]\n",
      "train_loss: 0.007172  [64064/250000]\n",
      "train_loss: 0.011564  [96064/250000]\n",
      "train_loss: 0.006278  [128064/250000]\n",
      "train_loss: 0.006446  [160064/250000]\n",
      "train_loss: 0.009001  [192064/250000]\n",
      "train_loss: 0.010573  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008854 val_loss 0.009062\n",
      "learning rate:  1.0000000000000002e-06 , sim:  9\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008503 val_loss 0.008664\n",
      "learning rate:  1.0000000000000002e-06 , sim:  9\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008584 val_loss 0.008777\n",
      "learning rate:  1.0000000000000002e-07 , sim:  9\n",
      "train_loss: 0.010257  [   64/250000]\n",
      "train_loss: 0.008046  [32064/250000]\n",
      "train_loss: 0.007653  [64064/250000]\n",
      "train_loss: 0.009318  [96064/250000]\n",
      "train_loss: 0.007015  [128064/250000]\n",
      "train_loss: 0.006981  [160064/250000]\n",
      "train_loss: 0.007558  [192064/250000]\n",
      "train_loss: 0.007512  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008321 val_loss 0.008506\n",
      "learning rate:  1.0000000000000002e-07 , sim:  9\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008429 val_loss 0.008618\n",
      "learning rate:  1.0000000000000002e-07 , sim:  9\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008538 val_loss 0.008710\n",
      "learning rate:  1.0000000000000002e-07 , sim:  9\n",
      "train_loss: 0.009431  [   64/250000]\n",
      "train_loss: 0.009479  [32064/250000]\n",
      "train_loss: 0.008117  [64064/250000]\n",
      "train_loss: 0.006998  [96064/250000]\n",
      "train_loss: 0.009277  [128064/250000]\n",
      "train_loss: 0.010341  [160064/250000]\n",
      "train_loss: 0.009893  [192064/250000]\n",
      "train_loss: 0.009232  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008342 val_loss 0.008529\n",
      "learning rate:  1.0000000000000002e-07 , sim:  9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008230 val_loss 0.008414\n",
      "learning rate:  1.0000000000000002e-07 , sim:  9\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008393 val_loss 0.008561\n",
      "learning rate:  1.0000000000000002e-07 , sim:  9\n",
      "train_loss: 0.007876  [   64/250000]\n",
      "train_loss: 0.009696  [32064/250000]\n",
      "train_loss: 0.009651  [64064/250000]\n",
      "train_loss: 0.011456  [96064/250000]\n",
      "train_loss: 0.008668  [128064/250000]\n",
      "train_loss: 0.006967  [160064/250000]\n",
      "train_loss: 0.008949  [192064/250000]\n",
      "train_loss: 0.009541  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008553 val_loss 0.008738\n",
      "learning rate:  1.0000000000000002e-07 , sim:  9\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008304 val_loss 0.008481\n",
      "learning rate:  1.0000000000000002e-07 , sim:  9\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008601 val_loss 0.008788\n",
      "learning rate:  1.0000000000000002e-07 , sim:  9\n",
      "train_loss: 3.459327  [   64/250000]\n",
      "train_loss: 1.291861  [32064/250000]\n",
      "train_loss: 0.687950  [64064/250000]\n",
      "train_loss: 0.312315  [96064/250000]\n",
      "train_loss: 0.158305  [128064/250000]\n",
      "train_loss: 0.083252  [160064/250000]\n",
      "train_loss: 0.060531  [192064/250000]\n",
      "train_loss: 0.046429  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.023022 val_loss 0.023182\n",
      "learning rate:  1e-05 , sim:  10\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008942 val_loss 0.008953\n",
      "learning rate:  1e-05 , sim:  10\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008679 val_loss 0.008679\n",
      "learning rate:  1e-05 , sim:  10\n",
      "train_loss: 0.009428  [   64/250000]\n",
      "train_loss: 0.006421  [32064/250000]\n",
      "train_loss: 0.009036  [64064/250000]\n",
      "train_loss: 0.007518  [96064/250000]\n",
      "train_loss: 0.008630  [128064/250000]\n",
      "train_loss: 0.007668  [160064/250000]\n",
      "train_loss: 0.009222  [192064/250000]\n",
      "train_loss: 0.009009  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008806 val_loss 0.008819\n",
      "learning rate:  1e-05 , sim:  10\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008678 val_loss 0.008708\n",
      "learning rate:  1e-05 , sim:  10\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008685 val_loss 0.008701\n",
      "learning rate:  1e-05 , sim:  10\n",
      "train_loss: 0.006624  [   64/250000]\n",
      "train_loss: 0.008568  [32064/250000]\n",
      "train_loss: 0.009716  [64064/250000]\n",
      "train_loss: 0.006870  [96064/250000]\n",
      "train_loss: 0.008598  [128064/250000]\n",
      "train_loss: 0.008850  [160064/250000]\n",
      "train_loss: 0.008425  [192064/250000]\n",
      "train_loss: 0.007729  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008613 val_loss 0.008637\n",
      "learning rate:  1e-05 , sim:  10\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008449 val_loss 0.008485\n",
      "learning rate:  1e-05 , sim:  10\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008626 val_loss 0.008675\n",
      "learning rate:  1e-05 , sim:  10\n",
      "train_loss: 0.008807  [   64/250000]\n",
      "train_loss: 0.007541  [32064/250000]\n",
      "train_loss: 0.008537  [64064/250000]\n",
      "train_loss: 0.010130  [96064/250000]\n",
      "train_loss: 0.010174  [128064/250000]\n",
      "train_loss: 0.009739  [160064/250000]\n",
      "train_loss: 0.008747  [192064/250000]\n",
      "train_loss: 0.008773  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008514 val_loss 0.008546\n",
      "learning rate:  1e-05 , sim:  10\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008467 val_loss 0.008508\n",
      "learning rate:  1.0000000000000002e-06 , sim:  10\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008596 val_loss 0.008654\n",
      "learning rate:  1.0000000000000002e-06 , sim:  10\n",
      "train_loss: 0.008455  [   64/250000]\n",
      "train_loss: 0.008842  [32064/250000]\n",
      "train_loss: 0.007966  [64064/250000]\n",
      "train_loss: 0.007990  [96064/250000]\n",
      "train_loss: 0.006020  [128064/250000]\n",
      "train_loss: 0.008657  [160064/250000]\n",
      "train_loss: 0.010908  [192064/250000]\n",
      "train_loss: 0.009035  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008547 val_loss 0.008581\n",
      "learning rate:  1.0000000000000002e-06 , sim:  10\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008492 val_loss 0.008511\n",
      "learning rate:  1.0000000000000002e-06 , sim:  10\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008622 val_loss 0.008661\n",
      "learning rate:  1.0000000000000002e-06 , sim:  10\n",
      "train_loss: 0.007493  [   64/250000]\n",
      "train_loss: 0.008177  [32064/250000]\n",
      "train_loss: 0.008905  [64064/250000]\n",
      "train_loss: 0.006631  [96064/250000]\n",
      "train_loss: 0.008851  [128064/250000]\n",
      "train_loss: 0.008425  [160064/250000]\n",
      "train_loss: 0.007416  [192064/250000]\n",
      "train_loss: 0.008227  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008433 val_loss 0.008476\n",
      "learning rate:  1.0000000000000002e-06 , sim:  10\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008513 val_loss 0.008557\n",
      "learning rate:  1.0000000000000002e-06 , sim:  10\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008754 val_loss 0.008794\n",
      "learning rate:  1.0000000000000002e-06 , sim:  10\n",
      "train_loss: 0.008056  [   64/250000]\n",
      "train_loss: 0.011011  [32064/250000]\n",
      "train_loss: 0.009211  [64064/250000]\n",
      "train_loss: 0.006425  [96064/250000]\n",
      "train_loss: 0.008170  [128064/250000]\n",
      "train_loss: 0.007178  [160064/250000]\n",
      "train_loss: 0.007439  [192064/250000]\n",
      "train_loss: 0.009419  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008571 val_loss 0.008635\n",
      "learning rate:  1.0000000000000002e-06 , sim:  10\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008806 val_loss 0.008860\n",
      "learning rate:  1.0000000000000002e-06 , sim:  10\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008499 val_loss 0.008541\n",
      "learning rate:  1.0000000000000002e-07 , sim:  10\n",
      "train_loss: 0.008129  [   64/250000]\n",
      "train_loss: 0.008740  [32064/250000]\n",
      "train_loss: 0.011022  [64064/250000]\n",
      "train_loss: 0.009025  [96064/250000]\n",
      "train_loss: 0.007083  [128064/250000]\n",
      "train_loss: 0.008244  [160064/250000]\n",
      "train_loss: 0.007638  [192064/250000]\n",
      "train_loss: 0.006982  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008441 val_loss 0.008496\n",
      "learning rate:  1.0000000000000002e-07 , sim:  10\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008686 val_loss 0.008724\n",
      "learning rate:  1.0000000000000002e-07 , sim:  10\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008932 val_loss 0.008980\n",
      "learning rate:  1.0000000000000002e-07 , sim:  10\n",
      "train_loss: 0.009478  [   64/250000]\n",
      "train_loss: 0.008839  [32064/250000]\n",
      "train_loss: 0.009019  [64064/250000]\n",
      "train_loss: 0.007647  [96064/250000]\n",
      "train_loss: 0.008485  [128064/250000]\n",
      "train_loss: 0.008041  [160064/250000]\n",
      "train_loss: 0.010336  [192064/250000]\n",
      "train_loss: 0.005876  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008274 val_loss 0.008323\n",
      "learning rate:  1.0000000000000002e-07 , sim:  10\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.009039 val_loss 0.009077\n",
      "learning rate:  1.0000000000000002e-07 , sim:  10\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008284 val_loss 0.008328\n",
      "learning rate:  1.0000000000000002e-07 , sim:  10\n",
      "train_loss: 0.009271  [   64/250000]\n",
      "train_loss: 0.007557  [32064/250000]\n",
      "train_loss: 0.007869  [64064/250000]\n",
      "train_loss: 0.009447  [96064/250000]\n",
      "train_loss: 0.010171  [128064/250000]\n",
      "train_loss: 0.010214  [160064/250000]\n",
      "train_loss: 0.009815  [192064/250000]\n",
      "train_loss: 0.007884  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008419 val_loss 0.008456\n",
      "learning rate:  1.0000000000000002e-07 , sim:  10\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008335 val_loss 0.008397\n",
      "learning rate:  1.0000000000000002e-07 , sim:  10\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008250 val_loss 0.008299\n",
      "learning rate:  1.0000000000000002e-07 , sim:  10\n",
      "train_loss: 3.547998  [   64/250000]\n",
      "train_loss: 1.145239  [32064/250000]\n",
      "train_loss: 0.616515  [64064/250000]\n",
      "train_loss: 0.244464  [96064/250000]\n",
      "train_loss: 0.136259  [128064/250000]\n",
      "train_loss: 0.099440  [160064/250000]\n",
      "train_loss: 0.058784  [192064/250000]\n",
      "train_loss: 0.038252  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.021601 val_loss 0.021476\n",
      "learning rate:  1e-05 , sim:  11\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.009176 val_loss 0.009215\n",
      "learning rate:  1e-05 , sim:  11\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008877 val_loss 0.008971\n",
      "learning rate:  1e-05 , sim:  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.008118  [   64/250000]\n",
      "train_loss: 0.008579  [32064/250000]\n",
      "train_loss: 0.006422  [64064/250000]\n",
      "train_loss: 0.010719  [96064/250000]\n",
      "train_loss: 0.010123  [128064/250000]\n",
      "train_loss: 0.011732  [160064/250000]\n",
      "train_loss: 0.005934  [192064/250000]\n",
      "train_loss: 0.007593  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008699 val_loss 0.008770\n",
      "learning rate:  1e-05 , sim:  11\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.010041 val_loss 0.010101\n",
      "learning rate:  1e-05 , sim:  11\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008889 val_loss 0.008951\n",
      "learning rate:  1e-05 , sim:  11\n",
      "train_loss: 0.009087  [   64/250000]\n",
      "train_loss: 0.009589  [32064/250000]\n",
      "train_loss: 0.009586  [64064/250000]\n",
      "train_loss: 0.009503  [96064/250000]\n",
      "train_loss: 0.007257  [128064/250000]\n",
      "train_loss: 0.007289  [160064/250000]\n",
      "train_loss: 0.010663  [192064/250000]\n",
      "train_loss: 0.007434  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.009521 val_loss 0.009579\n",
      "learning rate:  1e-05 , sim:  11\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.009155 val_loss 0.009253\n",
      "learning rate:  1e-05 , sim:  11\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008352 val_loss 0.008436\n",
      "learning rate:  1e-05 , sim:  11\n",
      "train_loss: 0.008528  [   64/250000]\n",
      "train_loss: 0.009790  [32064/250000]\n",
      "train_loss: 0.008981  [64064/250000]\n",
      "train_loss: 0.008108  [96064/250000]\n",
      "train_loss: 0.008298  [128064/250000]\n",
      "train_loss: 0.008047  [160064/250000]\n",
      "train_loss: 0.008152  [192064/250000]\n",
      "train_loss: 0.010037  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008399 val_loss 0.008462\n",
      "learning rate:  1e-05 , sim:  11\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008586 val_loss 0.008658\n",
      "learning rate:  1.0000000000000002e-06 , sim:  11\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008605 val_loss 0.008669\n",
      "learning rate:  1.0000000000000002e-06 , sim:  11\n",
      "train_loss: 0.010096  [   64/250000]\n",
      "train_loss: 0.009510  [32064/250000]\n",
      "train_loss: 0.010135  [64064/250000]\n",
      "train_loss: 0.007679  [96064/250000]\n",
      "train_loss: 0.009212  [128064/250000]\n",
      "train_loss: 0.009093  [160064/250000]\n",
      "train_loss: 0.008323  [192064/250000]\n",
      "train_loss: 0.008977  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008431 val_loss 0.008500\n",
      "learning rate:  1.0000000000000002e-06 , sim:  11\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008544 val_loss 0.008624\n",
      "learning rate:  1.0000000000000002e-06 , sim:  11\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.009167 val_loss 0.009237\n",
      "learning rate:  1.0000000000000002e-06 , sim:  11\n",
      "train_loss: 0.010035  [   64/250000]\n",
      "train_loss: 0.008041  [32064/250000]\n",
      "train_loss: 0.007171  [64064/250000]\n",
      "train_loss: 0.010164  [96064/250000]\n",
      "train_loss: 0.006501  [128064/250000]\n",
      "train_loss: 0.007813  [160064/250000]\n",
      "train_loss: 0.010447  [192064/250000]\n",
      "train_loss: 0.010138  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008719 val_loss 0.008814\n",
      "learning rate:  1.0000000000000002e-06 , sim:  11\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008521 val_loss 0.008595\n",
      "learning rate:  1.0000000000000002e-06 , sim:  11\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008365 val_loss 0.008456\n",
      "learning rate:  1.0000000000000002e-06 , sim:  11\n",
      "train_loss: 0.008904  [   64/250000]\n",
      "train_loss: 0.009276  [32064/250000]\n",
      "train_loss: 0.009868  [64064/250000]\n",
      "train_loss: 0.008115  [96064/250000]\n",
      "train_loss: 0.010461  [128064/250000]\n",
      "train_loss: 0.007554  [160064/250000]\n",
      "train_loss: 0.009202  [192064/250000]\n",
      "train_loss: 0.007670  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008469 val_loss 0.008536\n",
      "learning rate:  1.0000000000000002e-06 , sim:  11\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008364 val_loss 0.008445\n",
      "learning rate:  1.0000000000000002e-06 , sim:  11\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008417 val_loss 0.008483\n",
      "learning rate:  1.0000000000000002e-07 , sim:  11\n",
      "train_loss: 0.007807  [   64/250000]\n",
      "train_loss: 0.009393  [32064/250000]\n",
      "train_loss: 0.008796  [64064/250000]\n",
      "train_loss: 0.009434  [96064/250000]\n",
      "train_loss: 0.007007  [128064/250000]\n",
      "train_loss: 0.008880  [160064/250000]\n",
      "train_loss: 0.007065  [192064/250000]\n",
      "train_loss: 0.007653  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008600 val_loss 0.008681\n",
      "learning rate:  1.0000000000000002e-07 , sim:  11\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008459 val_loss 0.008543\n",
      "learning rate:  1.0000000000000002e-07 , sim:  11\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008927 val_loss 0.009031\n",
      "learning rate:  1.0000000000000002e-07 , sim:  11\n",
      "train_loss: 0.008950  [   64/250000]\n",
      "train_loss: 0.010558  [32064/250000]\n",
      "train_loss: 0.008923  [64064/250000]\n",
      "train_loss: 0.010383  [96064/250000]\n",
      "train_loss: 0.006609  [128064/250000]\n",
      "train_loss: 0.008692  [160064/250000]\n",
      "train_loss: 0.009031  [192064/250000]\n",
      "train_loss: 0.008149  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008697 val_loss 0.008802\n",
      "learning rate:  1.0000000000000002e-07 , sim:  11\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008345 val_loss 0.008428\n",
      "learning rate:  1.0000000000000002e-07 , sim:  11\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008298 val_loss 0.008379\n",
      "learning rate:  1.0000000000000002e-07 , sim:  11\n",
      "train_loss: 0.006609  [   64/250000]\n",
      "train_loss: 0.008037  [32064/250000]\n",
      "train_loss: 0.008358  [64064/250000]\n",
      "train_loss: 0.008135  [96064/250000]\n",
      "train_loss: 0.007250  [128064/250000]\n",
      "train_loss: 0.009296  [160064/250000]\n",
      "train_loss: 0.008307  [192064/250000]\n",
      "train_loss: 0.008868  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008295 val_loss 0.008384\n",
      "learning rate:  1.0000000000000002e-07 , sim:  11\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008427 val_loss 0.008532\n",
      "learning rate:  1.0000000000000002e-07 , sim:  11\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008667 val_loss 0.008750\n",
      "learning rate:  1.0000000000000002e-07 , sim:  11\n",
      "train_loss: 2.916269  [   64/250000]\n",
      "train_loss: 1.212533  [32064/250000]\n",
      "train_loss: 0.545704  [64064/250000]\n",
      "train_loss: 0.292866  [96064/250000]\n",
      "train_loss: 0.126809  [128064/250000]\n",
      "train_loss: 0.079195  [160064/250000]\n",
      "train_loss: 0.034201  [192064/250000]\n",
      "train_loss: 0.057550  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.022748 val_loss 0.022663\n",
      "learning rate:  1e-05 , sim:  12\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008867 val_loss 0.008861\n",
      "learning rate:  1e-05 , sim:  12\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008665 val_loss 0.008669\n",
      "learning rate:  1e-05 , sim:  12\n",
      "train_loss: 0.008033  [   64/250000]\n",
      "train_loss: 0.011197  [32064/250000]\n",
      "train_loss: 0.008735  [64064/250000]\n",
      "train_loss: 0.006801  [96064/250000]\n",
      "train_loss: 0.009099  [128064/250000]\n",
      "train_loss: 0.010336  [160064/250000]\n",
      "train_loss: 0.007768  [192064/250000]\n",
      "train_loss: 0.009129  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008601 val_loss 0.008594\n",
      "learning rate:  1e-05 , sim:  12\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008986 val_loss 0.009008\n",
      "learning rate:  1e-05 , sim:  12\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008461 val_loss 0.008473\n",
      "learning rate:  1e-05 , sim:  12\n",
      "train_loss: 0.007088  [   64/250000]\n",
      "train_loss: 0.010302  [32064/250000]\n",
      "train_loss: 0.010032  [64064/250000]\n",
      "train_loss: 0.008394  [96064/250000]\n",
      "train_loss: 0.006757  [128064/250000]\n",
      "train_loss: 0.007858  [160064/250000]\n",
      "train_loss: 0.009065  [192064/250000]\n",
      "train_loss: 0.007538  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008359 val_loss 0.008359\n",
      "learning rate:  1e-05 , sim:  12\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008375 val_loss 0.008382\n",
      "learning rate:  1e-05 , sim:  12\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008329 val_loss 0.008334\n",
      "learning rate:  1e-05 , sim:  12\n",
      "train_loss: 0.010308  [   64/250000]\n",
      "train_loss: 0.007175  [32064/250000]\n",
      "train_loss: 0.009444  [64064/250000]\n",
      "train_loss: 0.006070  [96064/250000]\n",
      "train_loss: 0.007631  [128064/250000]\n",
      "train_loss: 0.008353  [160064/250000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.008741  [192064/250000]\n",
      "train_loss: 0.008124  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008379 val_loss 0.008394\n",
      "learning rate:  1e-05 , sim:  12\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008361 val_loss 0.008374\n",
      "learning rate:  1.0000000000000002e-06 , sim:  12\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008351 val_loss 0.008371\n",
      "learning rate:  1.0000000000000002e-06 , sim:  12\n",
      "train_loss: 0.008619  [   64/250000]\n",
      "train_loss: 0.009220  [32064/250000]\n",
      "train_loss: 0.006790  [64064/250000]\n",
      "train_loss: 0.009550  [96064/250000]\n",
      "train_loss: 0.008803  [128064/250000]\n",
      "train_loss: 0.010520  [160064/250000]\n",
      "train_loss: 0.006646  [192064/250000]\n",
      "train_loss: 0.007974  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008454 val_loss 0.008467\n",
      "learning rate:  1.0000000000000002e-06 , sim:  12\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008421 val_loss 0.008435\n",
      "learning rate:  1.0000000000000002e-06 , sim:  12\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008293 val_loss 0.008305\n",
      "learning rate:  1.0000000000000002e-06 , sim:  12\n",
      "train_loss: 0.007020  [   64/250000]\n",
      "train_loss: 0.009951  [32064/250000]\n",
      "train_loss: 0.006662  [64064/250000]\n",
      "train_loss: 0.006661  [96064/250000]\n",
      "train_loss: 0.008313  [128064/250000]\n",
      "train_loss: 0.008604  [160064/250000]\n",
      "train_loss: 0.008080  [192064/250000]\n",
      "train_loss: 0.009665  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008357 val_loss 0.008377\n",
      "learning rate:  1.0000000000000002e-06 , sim:  12\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008317 val_loss 0.008331\n",
      "learning rate:  1.0000000000000002e-06 , sim:  12\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008705 val_loss 0.008722\n",
      "learning rate:  1.0000000000000002e-06 , sim:  12\n",
      "train_loss: 0.007634  [   64/250000]\n",
      "train_loss: 0.008811  [32064/250000]\n",
      "train_loss: 0.008944  [64064/250000]\n",
      "train_loss: 0.008953  [96064/250000]\n",
      "train_loss: 0.007976  [128064/250000]\n",
      "train_loss: 0.006103  [160064/250000]\n",
      "train_loss: 0.009980  [192064/250000]\n",
      "train_loss: 0.006859  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008335 val_loss 0.008359\n",
      "learning rate:  1.0000000000000002e-06 , sim:  12\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008355 val_loss 0.008371\n",
      "learning rate:  1.0000000000000002e-06 , sim:  12\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008213 val_loss 0.008229\n",
      "learning rate:  1.0000000000000002e-07 , sim:  12\n",
      "train_loss: 0.006479  [   64/250000]\n",
      "train_loss: 0.008770  [32064/250000]\n",
      "train_loss: 0.009128  [64064/250000]\n",
      "train_loss: 0.007560  [96064/250000]\n",
      "train_loss: 0.009046  [128064/250000]\n",
      "train_loss: 0.008291  [160064/250000]\n",
      "train_loss: 0.007322  [192064/250000]\n",
      "train_loss: 0.008995  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008648 val_loss 0.008663\n",
      "learning rate:  1.0000000000000002e-07 , sim:  12\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008252 val_loss 0.008283\n",
      "learning rate:  1.0000000000000002e-07 , sim:  12\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008199 val_loss 0.008229\n",
      "learning rate:  1.0000000000000002e-07 , sim:  12\n",
      "train_loss: 0.009170  [   64/250000]\n",
      "train_loss: 0.006237  [32064/250000]\n",
      "train_loss: 0.006719  [64064/250000]\n",
      "train_loss: 0.008659  [96064/250000]\n",
      "train_loss: 0.008170  [128064/250000]\n",
      "train_loss: 0.007625  [160064/250000]\n",
      "train_loss: 0.007981  [192064/250000]\n",
      "train_loss: 0.008963  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008175 val_loss 0.008208\n",
      "learning rate:  1.0000000000000002e-07 , sim:  12\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008326 val_loss 0.008353\n",
      "learning rate:  1.0000000000000002e-07 , sim:  12\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008177 val_loss 0.008210\n",
      "learning rate:  1.0000000000000002e-07 , sim:  12\n",
      "train_loss: 0.008991  [   64/250000]\n",
      "train_loss: 0.007376  [32064/250000]\n",
      "train_loss: 0.009771  [64064/250000]\n",
      "train_loss: 0.007820  [96064/250000]\n",
      "train_loss: 0.007399  [128064/250000]\n",
      "train_loss: 0.008220  [160064/250000]\n",
      "train_loss: 0.008004  [192064/250000]\n",
      "train_loss: 0.007370  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008224 val_loss 0.008256\n",
      "learning rate:  1.0000000000000002e-07 , sim:  12\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008169 val_loss 0.008197\n",
      "learning rate:  1.0000000000000002e-07 , sim:  12\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008219 val_loss 0.008248\n",
      "learning rate:  1.0000000000000002e-07 , sim:  12\n",
      "train_loss: 2.471719  [   64/250000]\n",
      "train_loss: 0.763378  [32064/250000]\n",
      "train_loss: 0.356722  [64064/250000]\n",
      "train_loss: 0.132245  [96064/250000]\n",
      "train_loss: 0.082854  [128064/250000]\n",
      "train_loss: 0.036207  [160064/250000]\n",
      "train_loss: 0.025622  [192064/250000]\n",
      "train_loss: 0.021948  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.017977 val_loss 0.018128\n",
      "learning rate:  1e-05 , sim:  13\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.009088 val_loss 0.009183\n",
      "learning rate:  1e-05 , sim:  13\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008623 val_loss 0.008735\n",
      "learning rate:  1e-05 , sim:  13\n",
      "train_loss: 0.009037  [   64/250000]\n",
      "train_loss: 0.008469  [32064/250000]\n",
      "train_loss: 0.008096  [64064/250000]\n",
      "train_loss: 0.008284  [96064/250000]\n",
      "train_loss: 0.009377  [128064/250000]\n",
      "train_loss: 0.010022  [160064/250000]\n",
      "train_loss: 0.010435  [192064/250000]\n",
      "train_loss: 0.007512  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008770 val_loss 0.008876\n",
      "learning rate:  1e-05 , sim:  13\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.009055 val_loss 0.009186\n",
      "learning rate:  1e-05 , sim:  13\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008687 val_loss 0.008796\n",
      "learning rate:  1e-05 , sim:  13\n",
      "train_loss: 0.011118  [   64/250000]\n",
      "train_loss: 0.007300  [32064/250000]\n",
      "train_loss: 0.007187  [64064/250000]\n",
      "train_loss: 0.007469  [96064/250000]\n",
      "train_loss: 0.009161  [128064/250000]\n",
      "train_loss: 0.007474  [160064/250000]\n",
      "train_loss: 0.007415  [192064/250000]\n",
      "train_loss: 0.008510  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008468 val_loss 0.008589\n",
      "learning rate:  1e-05 , sim:  13\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008533 val_loss 0.008664\n",
      "learning rate:  1e-05 , sim:  13\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008351 val_loss 0.008470\n",
      "learning rate:  1e-05 , sim:  13\n",
      "train_loss: 0.007666  [   64/250000]\n",
      "train_loss: 0.009968  [32064/250000]\n",
      "train_loss: 0.007633  [64064/250000]\n",
      "train_loss: 0.009847  [96064/250000]\n",
      "train_loss: 0.008274  [128064/250000]\n",
      "train_loss: 0.007312  [160064/250000]\n",
      "train_loss: 0.007098  [192064/250000]\n",
      "train_loss: 0.007725  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008539 val_loss 0.008669\n",
      "learning rate:  1e-05 , sim:  13\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008418 val_loss 0.008525\n",
      "learning rate:  1.0000000000000002e-06 , sim:  13\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008376 val_loss 0.008504\n",
      "learning rate:  1.0000000000000002e-06 , sim:  13\n",
      "train_loss: 0.007963  [   64/250000]\n",
      "train_loss: 0.008778  [32064/250000]\n",
      "train_loss: 0.008706  [64064/250000]\n",
      "train_loss: 0.009343  [96064/250000]\n",
      "train_loss: 0.007141  [128064/250000]\n",
      "train_loss: 0.010147  [160064/250000]\n",
      "train_loss: 0.008168  [192064/250000]\n",
      "train_loss: 0.008227  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008419 val_loss 0.008536\n",
      "learning rate:  1.0000000000000002e-06 , sim:  13\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008309 val_loss 0.008422\n",
      "learning rate:  1.0000000000000002e-06 , sim:  13\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008727 val_loss 0.008852\n",
      "learning rate:  1.0000000000000002e-06 , sim:  13\n",
      "train_loss: 0.007855  [   64/250000]\n",
      "train_loss: 0.008175  [32064/250000]\n",
      "train_loss: 0.008478  [64064/250000]\n",
      "train_loss: 0.009487  [96064/250000]\n",
      "train_loss: 0.008072  [128064/250000]\n",
      "train_loss: 0.009844  [160064/250000]\n",
      "train_loss: 0.008619  [192064/250000]\n",
      "train_loss: 0.010082  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008390 val_loss 0.008517\n",
      "learning rate:  1.0000000000000002e-06 , sim:  13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008429 val_loss 0.008570\n",
      "learning rate:  1.0000000000000002e-06 , sim:  13\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008349 val_loss 0.008476\n",
      "learning rate:  1.0000000000000002e-06 , sim:  13\n",
      "train_loss: 0.006380  [   64/250000]\n",
      "train_loss: 0.009820  [32064/250000]\n",
      "train_loss: 0.009482  [64064/250000]\n",
      "train_loss: 0.008711  [96064/250000]\n",
      "train_loss: 0.007304  [128064/250000]\n",
      "train_loss: 0.011951  [160064/250000]\n",
      "train_loss: 0.006979  [192064/250000]\n",
      "train_loss: 0.009060  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008502 val_loss 0.008630\n",
      "learning rate:  1.0000000000000002e-06 , sim:  13\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008455 val_loss 0.008580\n",
      "learning rate:  1.0000000000000002e-06 , sim:  13\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008325 val_loss 0.008449\n",
      "learning rate:  1.0000000000000002e-07 , sim:  13\n",
      "train_loss: 0.008317  [   64/250000]\n",
      "train_loss: 0.008193  [32064/250000]\n",
      "train_loss: 0.010940  [64064/250000]\n",
      "train_loss: 0.008860  [96064/250000]\n",
      "train_loss: 0.007359  [128064/250000]\n",
      "train_loss: 0.005057  [160064/250000]\n",
      "train_loss: 0.007780  [192064/250000]\n",
      "train_loss: 0.008826  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008784 val_loss 0.008897\n",
      "learning rate:  1.0000000000000002e-07 , sim:  13\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008358 val_loss 0.008476\n",
      "learning rate:  1.0000000000000002e-07 , sim:  13\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008620 val_loss 0.008734\n",
      "learning rate:  1.0000000000000002e-07 , sim:  13\n",
      "train_loss: 0.007983  [   64/250000]\n",
      "train_loss: 0.009742  [32064/250000]\n",
      "train_loss: 0.008873  [64064/250000]\n",
      "train_loss: 0.007515  [96064/250000]\n",
      "train_loss: 0.008820  [128064/250000]\n",
      "train_loss: 0.007762  [160064/250000]\n",
      "train_loss: 0.009558  [192064/250000]\n",
      "train_loss: 0.008628  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.009108 val_loss 0.009211\n",
      "learning rate:  1.0000000000000002e-07 , sim:  13\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008345 val_loss 0.008460\n",
      "learning rate:  1.0000000000000002e-07 , sim:  13\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008398 val_loss 0.008519\n",
      "learning rate:  1.0000000000000002e-07 , sim:  13\n",
      "train_loss: 0.007479  [   64/250000]\n",
      "train_loss: 0.010371  [32064/250000]\n",
      "train_loss: 0.008973  [64064/250000]\n",
      "train_loss: 0.007206  [96064/250000]\n",
      "train_loss: 0.007227  [128064/250000]\n",
      "train_loss: 0.007653  [160064/250000]\n",
      "train_loss: 0.008396  [192064/250000]\n",
      "train_loss: 0.008390  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008358 val_loss 0.008492\n",
      "learning rate:  1.0000000000000002e-07 , sim:  13\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008586 val_loss 0.008711\n",
      "learning rate:  1.0000000000000002e-07 , sim:  13\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008354 val_loss 0.008493\n",
      "learning rate:  1.0000000000000002e-07 , sim:  13\n",
      "train_loss: 3.568541  [   64/250000]\n",
      "train_loss: 1.193328  [32064/250000]\n",
      "train_loss: 0.533716  [64064/250000]\n",
      "train_loss: 0.260158  [96064/250000]\n",
      "train_loss: 0.140563  [128064/250000]\n",
      "train_loss: 0.074149  [160064/250000]\n",
      "train_loss: 0.039118  [192064/250000]\n",
      "train_loss: 0.032295  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.019952 val_loss 0.019895\n",
      "learning rate:  1e-05 , sim:  14\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008805 val_loss 0.008844\n",
      "learning rate:  1e-05 , sim:  14\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008610 val_loss 0.008655\n",
      "learning rate:  1e-05 , sim:  14\n",
      "train_loss: 0.008193  [   64/250000]\n",
      "train_loss: 0.007003  [32064/250000]\n",
      "train_loss: 0.010350  [64064/250000]\n",
      "train_loss: 0.010192  [96064/250000]\n",
      "train_loss: 0.010046  [128064/250000]\n",
      "train_loss: 0.008117  [160064/250000]\n",
      "train_loss: 0.008716  [192064/250000]\n",
      "train_loss: 0.009305  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008522 val_loss 0.008560\n",
      "learning rate:  1e-05 , sim:  14\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008451 val_loss 0.008496\n",
      "learning rate:  1e-05 , sim:  14\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008854 val_loss 0.008908\n",
      "learning rate:  1e-05 , sim:  14\n",
      "train_loss: 0.008985  [   64/250000]\n",
      "train_loss: 0.007230  [32064/250000]\n",
      "train_loss: 0.007404  [64064/250000]\n",
      "train_loss: 0.010492  [96064/250000]\n",
      "train_loss: 0.009103  [128064/250000]\n",
      "train_loss: 0.009394  [160064/250000]\n",
      "train_loss: 0.007336  [192064/250000]\n",
      "train_loss: 0.006854  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008312 val_loss 0.008351\n",
      "learning rate:  1e-05 , sim:  14\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008349 val_loss 0.008404\n",
      "learning rate:  1e-05 , sim:  14\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008425 val_loss 0.008475\n",
      "learning rate:  1e-05 , sim:  14\n",
      "train_loss: 0.011986  [   64/250000]\n",
      "train_loss: 0.007943  [32064/250000]\n",
      "train_loss: 0.007861  [64064/250000]\n",
      "train_loss: 0.008769  [96064/250000]\n",
      "train_loss: 0.007549  [128064/250000]\n",
      "train_loss: 0.008272  [160064/250000]\n",
      "train_loss: 0.007022  [192064/250000]\n",
      "train_loss: 0.008259  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008295 val_loss 0.008357\n",
      "learning rate:  1e-05 , sim:  14\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008404 val_loss 0.008464\n",
      "learning rate:  1.0000000000000002e-06 , sim:  14\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008403 val_loss 0.008448\n",
      "learning rate:  1.0000000000000002e-06 , sim:  14\n",
      "train_loss: 0.008601  [   64/250000]\n",
      "train_loss: 0.008932  [32064/250000]\n",
      "train_loss: 0.008783  [64064/250000]\n",
      "train_loss: 0.008808  [96064/250000]\n",
      "train_loss: 0.009153  [128064/250000]\n",
      "train_loss: 0.008191  [160064/250000]\n",
      "train_loss: 0.007703  [192064/250000]\n",
      "train_loss: 0.009132  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008347 val_loss 0.008398\n",
      "learning rate:  1.0000000000000002e-06 , sim:  14\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008491 val_loss 0.008537\n",
      "learning rate:  1.0000000000000002e-06 , sim:  14\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008414 val_loss 0.008451\n",
      "learning rate:  1.0000000000000002e-06 , sim:  14\n",
      "train_loss: 0.007363  [   64/250000]\n",
      "train_loss: 0.008642  [32064/250000]\n",
      "train_loss: 0.010306  [64064/250000]\n",
      "train_loss: 0.005665  [96064/250000]\n",
      "train_loss: 0.008669  [128064/250000]\n",
      "train_loss: 0.007752  [160064/250000]\n",
      "train_loss: 0.006673  [192064/250000]\n",
      "train_loss: 0.007952  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008263 val_loss 0.008315\n",
      "learning rate:  1.0000000000000002e-06 , sim:  14\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008284 val_loss 0.008349\n",
      "learning rate:  1.0000000000000002e-06 , sim:  14\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008439 val_loss 0.008491\n",
      "learning rate:  1.0000000000000002e-06 , sim:  14\n",
      "train_loss: 0.008760  [   64/250000]\n",
      "train_loss: 0.009967  [32064/250000]\n",
      "train_loss: 0.007447  [64064/250000]\n",
      "train_loss: 0.009379  [96064/250000]\n",
      "train_loss: 0.007803  [128064/250000]\n",
      "train_loss: 0.008652  [160064/250000]\n",
      "train_loss: 0.009000  [192064/250000]\n",
      "train_loss: 0.008825  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008505 val_loss 0.008565\n",
      "learning rate:  1.0000000000000002e-06 , sim:  14\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008563 val_loss 0.008628\n",
      "learning rate:  1.0000000000000002e-06 , sim:  14\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008405 val_loss 0.008467\n",
      "learning rate:  1.0000000000000002e-07 , sim:  14\n",
      "train_loss: 0.008839  [   64/250000]\n",
      "train_loss: 0.008137  [32064/250000]\n",
      "train_loss: 0.008765  [64064/250000]\n",
      "train_loss: 0.007974  [96064/250000]\n",
      "train_loss: 0.006935  [128064/250000]\n",
      "train_loss: 0.011242  [160064/250000]\n",
      "train_loss: 0.007781  [192064/250000]\n",
      "train_loss: 0.006304  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008298 val_loss 0.008366\n",
      "learning rate:  1.0000000000000002e-07 , sim:  14\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008253 val_loss 0.008318\n",
      "learning rate:  1.0000000000000002e-07 , sim:  14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008306 val_loss 0.008372\n",
      "learning rate:  1.0000000000000002e-07 , sim:  14\n",
      "train_loss: 0.010523  [   64/250000]\n",
      "train_loss: 0.008404  [32064/250000]\n",
      "train_loss: 0.008692  [64064/250000]\n",
      "train_loss: 0.008709  [96064/250000]\n",
      "train_loss: 0.008012  [128064/250000]\n",
      "train_loss: 0.009073  [160064/250000]\n",
      "train_loss: 0.008785  [192064/250000]\n",
      "train_loss: 0.007773  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008228 val_loss 0.008291\n",
      "learning rate:  1.0000000000000002e-07 , sim:  14\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008560 val_loss 0.008639\n",
      "learning rate:  1.0000000000000002e-07 , sim:  14\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008409 val_loss 0.008475\n",
      "learning rate:  1.0000000000000002e-07 , sim:  14\n",
      "train_loss: 0.011457  [   64/250000]\n",
      "train_loss: 0.008437  [32064/250000]\n",
      "train_loss: 0.008356  [64064/250000]\n",
      "train_loss: 0.008027  [96064/250000]\n",
      "train_loss: 0.008752  [128064/250000]\n",
      "train_loss: 0.006823  [160064/250000]\n",
      "train_loss: 0.007983  [192064/250000]\n",
      "train_loss: 0.006941  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008317 val_loss 0.008387\n",
      "learning rate:  1.0000000000000002e-07 , sim:  14\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008285 val_loss 0.008360\n",
      "learning rate:  1.0000000000000002e-07 , sim:  14\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008526 val_loss 0.008599\n",
      "learning rate:  1.0000000000000002e-07 , sim:  14\n",
      "train_loss: 3.389047  [   64/250000]\n",
      "train_loss: 1.043574  [32064/250000]\n",
      "train_loss: 0.589676  [64064/250000]\n",
      "train_loss: 0.258313  [96064/250000]\n",
      "train_loss: 0.127122  [128064/250000]\n",
      "train_loss: 0.084134  [160064/250000]\n",
      "train_loss: 0.036064  [192064/250000]\n",
      "train_loss: 0.027565  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.018127 val_loss 0.017958\n",
      "learning rate:  1e-05 , sim:  15\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.009082 val_loss 0.009190\n",
      "learning rate:  1e-05 , sim:  15\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008899 val_loss 0.009015\n",
      "learning rate:  1e-05 , sim:  15\n",
      "train_loss: 0.008169  [   64/250000]\n",
      "train_loss: 0.009551  [32064/250000]\n",
      "train_loss: 0.008485  [64064/250000]\n",
      "train_loss: 0.007486  [96064/250000]\n",
      "train_loss: 0.009872  [128064/250000]\n",
      "train_loss: 0.009413  [160064/250000]\n",
      "train_loss: 0.011470  [192064/250000]\n",
      "train_loss: 0.009101  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008700 val_loss 0.008824\n",
      "learning rate:  1e-05 , sim:  15\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008753 val_loss 0.008875\n",
      "learning rate:  1e-05 , sim:  15\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008490 val_loss 0.008614\n",
      "learning rate:  1e-05 , sim:  15\n",
      "train_loss: 0.007213  [   64/250000]\n",
      "train_loss: 0.007761  [32064/250000]\n",
      "train_loss: 0.009298  [64064/250000]\n",
      "train_loss: 0.008483  [96064/250000]\n",
      "train_loss: 0.006542  [128064/250000]\n",
      "train_loss: 0.010634  [160064/250000]\n",
      "train_loss: 0.007412  [192064/250000]\n",
      "train_loss: 0.008536  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008677 val_loss 0.008811\n",
      "learning rate:  1e-05 , sim:  15\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008389 val_loss 0.008542\n",
      "learning rate:  1e-05 , sim:  15\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008459 val_loss 0.008589\n",
      "learning rate:  1e-05 , sim:  15\n",
      "train_loss: 0.009406  [   64/250000]\n",
      "train_loss: 0.008450  [32064/250000]\n",
      "train_loss: 0.011617  [64064/250000]\n",
      "train_loss: 0.009474  [96064/250000]\n",
      "train_loss: 0.008149  [128064/250000]\n",
      "train_loss: 0.007932  [160064/250000]\n",
      "train_loss: 0.007568  [192064/250000]\n",
      "train_loss: 0.010516  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008335 val_loss 0.008479\n",
      "learning rate:  1e-05 , sim:  15\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008465 val_loss 0.008607\n",
      "learning rate:  1.0000000000000002e-06 , sim:  15\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008985 val_loss 0.009129\n",
      "learning rate:  1.0000000000000002e-06 , sim:  15\n",
      "train_loss: 0.009513  [   64/250000]\n",
      "train_loss: 0.008031  [32064/250000]\n",
      "train_loss: 0.007862  [64064/250000]\n",
      "train_loss: 0.006617  [96064/250000]\n",
      "train_loss: 0.006988  [128064/250000]\n",
      "train_loss: 0.007676  [160064/250000]\n",
      "train_loss: 0.008946  [192064/250000]\n",
      "train_loss: 0.008347  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008382 val_loss 0.008526\n",
      "learning rate:  1.0000000000000002e-06 , sim:  15\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008510 val_loss 0.008655\n",
      "learning rate:  1.0000000000000002e-06 , sim:  15\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008651 val_loss 0.008814\n",
      "learning rate:  1.0000000000000002e-06 , sim:  15\n",
      "train_loss: 0.008472  [   64/250000]\n",
      "train_loss: 0.008239  [32064/250000]\n",
      "train_loss: 0.011267  [64064/250000]\n",
      "train_loss: 0.005888  [96064/250000]\n",
      "train_loss: 0.010859  [128064/250000]\n",
      "train_loss: 0.007992  [160064/250000]\n",
      "train_loss: 0.010675  [192064/250000]\n",
      "train_loss: 0.008284  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008404 val_loss 0.008555\n",
      "learning rate:  1.0000000000000002e-06 , sim:  15\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008481 val_loss 0.008624\n",
      "learning rate:  1.0000000000000002e-06 , sim:  15\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008577 val_loss 0.008722\n",
      "learning rate:  1.0000000000000002e-06 , sim:  15\n",
      "train_loss: 0.009034  [   64/250000]\n",
      "train_loss: 0.008624  [32064/250000]\n",
      "train_loss: 0.007424  [64064/250000]\n",
      "train_loss: 0.008259  [96064/250000]\n",
      "train_loss: 0.006984  [128064/250000]\n",
      "train_loss: 0.008817  [160064/250000]\n",
      "train_loss: 0.009491  [192064/250000]\n",
      "train_loss: 0.008165  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008624 val_loss 0.008785\n",
      "learning rate:  1.0000000000000002e-06 , sim:  15\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008443 val_loss 0.008604\n",
      "learning rate:  1.0000000000000002e-06 , sim:  15\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008292 val_loss 0.008452\n",
      "learning rate:  1.0000000000000002e-07 , sim:  15\n",
      "train_loss: 0.006376  [   64/250000]\n",
      "train_loss: 0.007813  [32064/250000]\n",
      "train_loss: 0.007256  [64064/250000]\n",
      "train_loss: 0.008164  [96064/250000]\n",
      "train_loss: 0.010474  [128064/250000]\n",
      "train_loss: 0.010710  [160064/250000]\n",
      "train_loss: 0.010100  [192064/250000]\n",
      "train_loss: 0.012445  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008297 val_loss 0.008456\n",
      "learning rate:  1.0000000000000002e-07 , sim:  15\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008519 val_loss 0.008673\n",
      "learning rate:  1.0000000000000002e-07 , sim:  15\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008853 val_loss 0.009021\n",
      "learning rate:  1.0000000000000002e-07 , sim:  15\n",
      "train_loss: 0.008890  [   64/250000]\n",
      "train_loss: 0.011164  [32064/250000]\n",
      "train_loss: 0.007699  [64064/250000]\n",
      "train_loss: 0.008387  [96064/250000]\n",
      "train_loss: 0.005644  [128064/250000]\n",
      "train_loss: 0.006676  [160064/250000]\n",
      "train_loss: 0.008821  [192064/250000]\n",
      "train_loss: 0.007790  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008284 val_loss 0.008438\n",
      "learning rate:  1.0000000000000002e-07 , sim:  15\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008345 val_loss 0.008505\n",
      "learning rate:  1.0000000000000002e-07 , sim:  15\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008373 val_loss 0.008525\n",
      "learning rate:  1.0000000000000002e-07 , sim:  15\n",
      "train_loss: 0.007099  [   64/250000]\n",
      "train_loss: 0.008711  [32064/250000]\n",
      "train_loss: 0.008748  [64064/250000]\n",
      "train_loss: 0.006718  [96064/250000]\n",
      "train_loss: 0.008115  [128064/250000]\n",
      "train_loss: 0.007922  [160064/250000]\n",
      "train_loss: 0.009358  [192064/250000]\n",
      "train_loss: 0.006895  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008526 val_loss 0.008686\n",
      "learning rate:  1.0000000000000002e-07 , sim:  15\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008632 val_loss 0.008788\n",
      "learning rate:  1.0000000000000002e-07 , sim:  15\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008304 val_loss 0.008453\n",
      "learning rate:  1.0000000000000002e-07 , sim:  15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 3.118960  [   64/250000]\n",
      "train_loss: 1.090748  [32064/250000]\n",
      "train_loss: 0.504350  [64064/250000]\n",
      "train_loss: 0.347767  [96064/250000]\n",
      "train_loss: 0.176564  [128064/250000]\n",
      "train_loss: 0.096174  [160064/250000]\n",
      "train_loss: 0.063333  [192064/250000]\n",
      "train_loss: 0.033401  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.023181 val_loss 0.023217\n",
      "learning rate:  1e-05 , sim:  16\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008613 val_loss 0.008704\n",
      "learning rate:  1e-05 , sim:  16\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008486 val_loss 0.008586\n",
      "learning rate:  1e-05 , sim:  16\n",
      "train_loss: 0.006105  [   64/250000]\n",
      "train_loss: 0.007063  [32064/250000]\n",
      "train_loss: 0.006667  [64064/250000]\n",
      "train_loss: 0.007943  [96064/250000]\n",
      "train_loss: 0.008297  [128064/250000]\n",
      "train_loss: 0.009186  [160064/250000]\n",
      "train_loss: 0.008878  [192064/250000]\n",
      "train_loss: 0.007905  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008519 val_loss 0.008625\n",
      "learning rate:  1e-05 , sim:  16\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008679 val_loss 0.008773\n",
      "learning rate:  1e-05 , sim:  16\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008446 val_loss 0.008547\n",
      "learning rate:  1e-05 , sim:  16\n",
      "train_loss: 0.008518  [   64/250000]\n",
      "train_loss: 0.008508  [32064/250000]\n",
      "train_loss: 0.008019  [64064/250000]\n",
      "train_loss: 0.008152  [96064/250000]\n",
      "train_loss: 0.008305  [128064/250000]\n",
      "train_loss: 0.007644  [160064/250000]\n",
      "train_loss: 0.007501  [192064/250000]\n",
      "train_loss: 0.007918  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008628 val_loss 0.008743\n",
      "learning rate:  1e-05 , sim:  16\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008437 val_loss 0.008553\n",
      "learning rate:  1e-05 , sim:  16\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008336 val_loss 0.008453\n",
      "learning rate:  1e-05 , sim:  16\n",
      "train_loss: 0.007330  [   64/250000]\n",
      "train_loss: 0.006243  [32064/250000]\n",
      "train_loss: 0.008946  [64064/250000]\n",
      "train_loss: 0.007348  [96064/250000]\n",
      "train_loss: 0.009105  [128064/250000]\n",
      "train_loss: 0.009271  [160064/250000]\n",
      "train_loss: 0.008538  [192064/250000]\n",
      "train_loss: 0.007714  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008487 val_loss 0.008595\n",
      "learning rate:  1e-05 , sim:  16\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008537 val_loss 0.008617\n",
      "learning rate:  1.0000000000000002e-06 , sim:  16\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008540 val_loss 0.008632\n",
      "learning rate:  1.0000000000000002e-06 , sim:  16\n",
      "train_loss: 0.009171  [   64/250000]\n",
      "train_loss: 0.008262  [32064/250000]\n",
      "train_loss: 0.006604  [64064/250000]\n",
      "train_loss: 0.010382  [96064/250000]\n",
      "train_loss: 0.007720  [128064/250000]\n",
      "train_loss: 0.008885  [160064/250000]\n",
      "train_loss: 0.009865  [192064/250000]\n",
      "train_loss: 0.006881  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008346 val_loss 0.008449\n",
      "learning rate:  1.0000000000000002e-06 , sim:  16\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.009112 val_loss 0.009227\n",
      "learning rate:  1.0000000000000002e-06 , sim:  16\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008330 val_loss 0.008447\n",
      "learning rate:  1.0000000000000002e-06 , sim:  16\n",
      "train_loss: 0.007567  [   64/250000]\n",
      "train_loss: 0.006464  [32064/250000]\n",
      "train_loss: 0.007074  [64064/250000]\n",
      "train_loss: 0.008517  [96064/250000]\n",
      "train_loss: 0.006018  [128064/250000]\n",
      "train_loss: 0.008996  [160064/250000]\n",
      "train_loss: 0.010868  [192064/250000]\n",
      "train_loss: 0.008521  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008600 val_loss 0.008708\n",
      "learning rate:  1.0000000000000002e-06 , sim:  16\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008259 val_loss 0.008355\n",
      "learning rate:  1.0000000000000002e-06 , sim:  16\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008465 val_loss 0.008582\n",
      "learning rate:  1.0000000000000002e-06 , sim:  16\n",
      "train_loss: 0.007560  [   64/250000]\n",
      "train_loss: 0.007606  [32064/250000]\n",
      "train_loss: 0.009355  [64064/250000]\n",
      "train_loss: 0.008061  [96064/250000]\n",
      "train_loss: 0.008077  [128064/250000]\n",
      "train_loss: 0.008217  [160064/250000]\n",
      "train_loss: 0.008161  [192064/250000]\n",
      "train_loss: 0.006930  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008486 val_loss 0.008617\n",
      "learning rate:  1.0000000000000002e-06 , sim:  16\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008350 val_loss 0.008455\n",
      "learning rate:  1.0000000000000002e-06 , sim:  16\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008287 val_loss 0.008403\n",
      "learning rate:  1.0000000000000002e-07 , sim:  16\n",
      "train_loss: 0.009067  [   64/250000]\n",
      "train_loss: 0.009712  [32064/250000]\n",
      "train_loss: 0.007512  [64064/250000]\n",
      "train_loss: 0.008744  [96064/250000]\n",
      "train_loss: 0.008866  [128064/250000]\n",
      "train_loss: 0.009573  [160064/250000]\n",
      "train_loss: 0.007179  [192064/250000]\n",
      "train_loss: 0.008206  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008437 val_loss 0.008542\n",
      "learning rate:  1.0000000000000002e-07 , sim:  16\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008297 val_loss 0.008397\n",
      "learning rate:  1.0000000000000002e-07 , sim:  16\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008218 val_loss 0.008335\n",
      "learning rate:  1.0000000000000002e-07 , sim:  16\n",
      "train_loss: 0.007226  [   64/250000]\n",
      "train_loss: 0.006553  [32064/250000]\n",
      "train_loss: 0.010643  [64064/250000]\n",
      "train_loss: 0.007202  [96064/250000]\n",
      "train_loss: 0.008278  [128064/250000]\n",
      "train_loss: 0.008168  [160064/250000]\n",
      "train_loss: 0.009929  [192064/250000]\n",
      "train_loss: 0.008567  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008216 val_loss 0.008346\n",
      "learning rate:  1.0000000000000002e-07 , sim:  16\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008315 val_loss 0.008436\n",
      "learning rate:  1.0000000000000002e-07 , sim:  16\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008193 val_loss 0.008308\n",
      "learning rate:  1.0000000000000002e-07 , sim:  16\n",
      "train_loss: 0.006350  [   64/250000]\n",
      "train_loss: 0.008677  [32064/250000]\n",
      "train_loss: 0.010841  [64064/250000]\n",
      "train_loss: 0.007108  [96064/250000]\n",
      "train_loss: 0.008796  [128064/250000]\n",
      "train_loss: 0.009270  [160064/250000]\n",
      "train_loss: 0.007669  [192064/250000]\n",
      "train_loss: 0.009434  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008330 val_loss 0.008447\n",
      "learning rate:  1.0000000000000002e-07 , sim:  16\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008280 val_loss 0.008398\n",
      "learning rate:  1.0000000000000002e-07 , sim:  16\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008229 val_loss 0.008354\n",
      "learning rate:  1.0000000000000002e-07 , sim:  16\n",
      "train_loss: 3.356115  [   64/250000]\n",
      "train_loss: 1.391933  [32064/250000]\n",
      "train_loss: 0.592919  [64064/250000]\n",
      "train_loss: 0.290432  [96064/250000]\n",
      "train_loss: 0.248934  [128064/250000]\n",
      "train_loss: 0.078987  [160064/250000]\n",
      "train_loss: 0.042808  [192064/250000]\n",
      "train_loss: 0.025229  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.020046 val_loss 0.020076\n",
      "learning rate:  1e-05 , sim:  17\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.009080 val_loss 0.009123\n",
      "learning rate:  1e-05 , sim:  17\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008892 val_loss 0.008946\n",
      "learning rate:  1e-05 , sim:  17\n",
      "train_loss: 0.009660  [   64/250000]\n",
      "train_loss: 0.008092  [32064/250000]\n",
      "train_loss: 0.011087  [64064/250000]\n",
      "train_loss: 0.008409  [96064/250000]\n",
      "train_loss: 0.009526  [128064/250000]\n",
      "train_loss: 0.005931  [160064/250000]\n",
      "train_loss: 0.008703  [192064/250000]\n",
      "train_loss: 0.006208  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008824 val_loss 0.008892\n",
      "learning rate:  1e-05 , sim:  17\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008547 val_loss 0.008635\n",
      "learning rate:  1e-05 , sim:  17\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008408 val_loss 0.008496\n",
      "learning rate:  1e-05 , sim:  17\n",
      "train_loss: 0.008947  [   64/250000]\n",
      "train_loss: 0.009239  [32064/250000]\n",
      "train_loss: 0.011900  [64064/250000]\n",
      "train_loss: 0.009560  [96064/250000]\n",
      "train_loss: 0.008415  [128064/250000]\n",
      "train_loss: 0.007778  [160064/250000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.009352  [192064/250000]\n",
      "train_loss: 0.007915  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008642 val_loss 0.008730\n",
      "learning rate:  1e-05 , sim:  17\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008427 val_loss 0.008528\n",
      "learning rate:  1e-05 , sim:  17\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008566 val_loss 0.008652\n",
      "learning rate:  1e-05 , sim:  17\n",
      "train_loss: 0.008354  [   64/250000]\n",
      "train_loss: 0.008299  [32064/250000]\n",
      "train_loss: 0.007927  [64064/250000]\n",
      "train_loss: 0.008327  [96064/250000]\n",
      "train_loss: 0.007840  [128064/250000]\n",
      "train_loss: 0.009679  [160064/250000]\n",
      "train_loss: 0.009861  [192064/250000]\n",
      "train_loss: 0.007818  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008498 val_loss 0.008607\n",
      "learning rate:  1e-05 , sim:  17\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008292 val_loss 0.008402\n",
      "learning rate:  1.0000000000000002e-06 , sim:  17\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008423 val_loss 0.008536\n",
      "learning rate:  1.0000000000000002e-06 , sim:  17\n",
      "train_loss: 0.006839  [   64/250000]\n",
      "train_loss: 0.006408  [32064/250000]\n",
      "train_loss: 0.011415  [64064/250000]\n",
      "train_loss: 0.006937  [96064/250000]\n",
      "train_loss: 0.009833  [128064/250000]\n",
      "train_loss: 0.008603  [160064/250000]\n",
      "train_loss: 0.008244  [192064/250000]\n",
      "train_loss: 0.007239  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008406 val_loss 0.008516\n",
      "learning rate:  1.0000000000000002e-06 , sim:  17\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008697 val_loss 0.008807\n",
      "learning rate:  1.0000000000000002e-06 , sim:  17\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008591 val_loss 0.008717\n",
      "learning rate:  1.0000000000000002e-06 , sim:  17\n",
      "train_loss: 0.009072  [   64/250000]\n",
      "train_loss: 0.007234  [32064/250000]\n",
      "train_loss: 0.008488  [64064/250000]\n",
      "train_loss: 0.009424  [96064/250000]\n",
      "train_loss: 0.007046  [128064/250000]\n",
      "train_loss: 0.008890  [160064/250000]\n",
      "train_loss: 0.006693  [192064/250000]\n",
      "train_loss: 0.008007  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008303 val_loss 0.008427\n",
      "learning rate:  1.0000000000000002e-06 , sim:  17\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008479 val_loss 0.008599\n",
      "learning rate:  1.0000000000000002e-06 , sim:  17\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008454 val_loss 0.008578\n",
      "learning rate:  1.0000000000000002e-06 , sim:  17\n",
      "train_loss: 0.010465  [   64/250000]\n",
      "train_loss: 0.008824  [32064/250000]\n",
      "train_loss: 0.010057  [64064/250000]\n",
      "train_loss: 0.007897  [96064/250000]\n",
      "train_loss: 0.007867  [128064/250000]\n",
      "train_loss: 0.008769  [160064/250000]\n",
      "train_loss: 0.007210  [192064/250000]\n",
      "train_loss: 0.009178  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008312 val_loss 0.008426\n",
      "learning rate:  1.0000000000000002e-06 , sim:  17\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008477 val_loss 0.008587\n",
      "learning rate:  1.0000000000000002e-06 , sim:  17\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008651 val_loss 0.008778\n",
      "learning rate:  1.0000000000000002e-07 , sim:  17\n",
      "train_loss: 0.008442  [   64/250000]\n",
      "train_loss: 0.006663  [32064/250000]\n",
      "train_loss: 0.007526  [64064/250000]\n",
      "train_loss: 0.007636  [96064/250000]\n",
      "train_loss: 0.009090  [128064/250000]\n",
      "train_loss: 0.007775  [160064/250000]\n",
      "train_loss: 0.007868  [192064/250000]\n",
      "train_loss: 0.007915  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008350 val_loss 0.008472\n",
      "learning rate:  1.0000000000000002e-07 , sim:  17\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008327 val_loss 0.008450\n",
      "learning rate:  1.0000000000000002e-07 , sim:  17\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008713 val_loss 0.008827\n",
      "learning rate:  1.0000000000000002e-07 , sim:  17\n",
      "train_loss: 0.008579  [   64/250000]\n",
      "train_loss: 0.008827  [32064/250000]\n",
      "train_loss: 0.007215  [64064/250000]\n",
      "train_loss: 0.008903  [96064/250000]\n",
      "train_loss: 0.006062  [128064/250000]\n",
      "train_loss: 0.008344  [160064/250000]\n",
      "train_loss: 0.007770  [192064/250000]\n",
      "train_loss: 0.008123  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008539 val_loss 0.008671\n",
      "learning rate:  1.0000000000000002e-07 , sim:  17\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008290 val_loss 0.008417\n",
      "learning rate:  1.0000000000000002e-07 , sim:  17\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008744 val_loss 0.008870\n",
      "learning rate:  1.0000000000000002e-07 , sim:  17\n",
      "train_loss: 0.008332  [   64/250000]\n",
      "train_loss: 0.009022  [32064/250000]\n",
      "train_loss: 0.009586  [64064/250000]\n",
      "train_loss: 0.008566  [96064/250000]\n",
      "train_loss: 0.007462  [128064/250000]\n",
      "train_loss: 0.008562  [160064/250000]\n",
      "train_loss: 0.007868  [192064/250000]\n",
      "train_loss: 0.007121  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008426 val_loss 0.008556\n",
      "learning rate:  1.0000000000000002e-07 , sim:  17\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008228 val_loss 0.008364\n",
      "learning rate:  1.0000000000000002e-07 , sim:  17\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008343 val_loss 0.008469\n",
      "learning rate:  1.0000000000000002e-07 , sim:  17\n",
      "train_loss: 2.884256  [   64/250000]\n",
      "train_loss: 0.907843  [32064/250000]\n",
      "train_loss: 0.438657  [64064/250000]\n",
      "train_loss: 0.244277  [96064/250000]\n",
      "train_loss: 0.119005  [128064/250000]\n",
      "train_loss: 0.105715  [160064/250000]\n",
      "train_loss: 0.045198  [192064/250000]\n",
      "train_loss: 0.020463  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.018077 val_loss 0.018097\n",
      "learning rate:  1e-05 , sim:  18\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.008942 val_loss 0.009024\n",
      "learning rate:  1e-05 , sim:  18\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008751 val_loss 0.008831\n",
      "learning rate:  1e-05 , sim:  18\n",
      "train_loss: 0.007709  [   64/250000]\n",
      "train_loss: 0.007795  [32064/250000]\n",
      "train_loss: 0.007066  [64064/250000]\n",
      "train_loss: 0.008866  [96064/250000]\n",
      "train_loss: 0.007426  [128064/250000]\n",
      "train_loss: 0.009759  [160064/250000]\n",
      "train_loss: 0.010478  [192064/250000]\n",
      "train_loss: 0.009847  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008548 val_loss 0.008671\n",
      "learning rate:  1e-05 , sim:  18\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008550 val_loss 0.008651\n",
      "learning rate:  1e-05 , sim:  18\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008339 val_loss 0.008464\n",
      "learning rate:  1e-05 , sim:  18\n",
      "train_loss: 0.008851  [   64/250000]\n",
      "train_loss: 0.006375  [32064/250000]\n",
      "train_loss: 0.009112  [64064/250000]\n",
      "train_loss: 0.008567  [96064/250000]\n",
      "train_loss: 0.006389  [128064/250000]\n",
      "train_loss: 0.006684  [160064/250000]\n",
      "train_loss: 0.007666  [192064/250000]\n",
      "train_loss: 0.008533  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008546 val_loss 0.008630\n",
      "learning rate:  1e-05 , sim:  18\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008444 val_loss 0.008551\n",
      "learning rate:  1e-05 , sim:  18\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008400 val_loss 0.008489\n",
      "learning rate:  1e-05 , sim:  18\n",
      "train_loss: 0.007535  [   64/250000]\n",
      "train_loss: 0.009634  [32064/250000]\n",
      "train_loss: 0.006675  [64064/250000]\n",
      "train_loss: 0.005942  [96064/250000]\n",
      "train_loss: 0.008320  [128064/250000]\n",
      "train_loss: 0.008415  [160064/250000]\n",
      "train_loss: 0.009027  [192064/250000]\n",
      "train_loss: 0.007798  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008438 val_loss 0.008540\n",
      "learning rate:  1e-05 , sim:  18\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008396 val_loss 0.008487\n",
      "learning rate:  1.0000000000000002e-06 , sim:  18\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008352 val_loss 0.008464\n",
      "learning rate:  1.0000000000000002e-06 , sim:  18\n",
      "train_loss: 0.007820  [   64/250000]\n",
      "train_loss: 0.009506  [32064/250000]\n",
      "train_loss: 0.007872  [64064/250000]\n",
      "train_loss: 0.008392  [96064/250000]\n",
      "train_loss: 0.011151  [128064/250000]\n",
      "train_loss: 0.009864  [160064/250000]\n",
      "train_loss: 0.008350  [192064/250000]\n",
      "train_loss: 0.008688  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008821 val_loss 0.008903\n",
      "learning rate:  1.0000000000000002e-06 , sim:  18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008709 val_loss 0.008829\n",
      "learning rate:  1.0000000000000002e-06 , sim:  18\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008512 val_loss 0.008610\n",
      "learning rate:  1.0000000000000002e-06 , sim:  18\n",
      "train_loss: 0.007520  [   64/250000]\n",
      "train_loss: 0.008327  [32064/250000]\n",
      "train_loss: 0.006632  [64064/250000]\n",
      "train_loss: 0.008086  [96064/250000]\n",
      "train_loss: 0.008639  [128064/250000]\n",
      "train_loss: 0.007410  [160064/250000]\n",
      "train_loss: 0.008538  [192064/250000]\n",
      "train_loss: 0.010730  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008306 val_loss 0.008415\n",
      "learning rate:  1.0000000000000002e-06 , sim:  18\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008398 val_loss 0.008517\n",
      "learning rate:  1.0000000000000002e-06 , sim:  18\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008472 val_loss 0.008608\n",
      "learning rate:  1.0000000000000002e-06 , sim:  18\n",
      "train_loss: 0.007560  [   64/250000]\n",
      "train_loss: 0.008391  [32064/250000]\n",
      "train_loss: 0.011472  [64064/250000]\n",
      "train_loss: 0.007079  [96064/250000]\n",
      "train_loss: 0.007480  [128064/250000]\n",
      "train_loss: 0.007909  [160064/250000]\n",
      "train_loss: 0.008551  [192064/250000]\n",
      "train_loss: 0.007498  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008444 val_loss 0.008560\n",
      "learning rate:  1.0000000000000002e-06 , sim:  18\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008301 val_loss 0.008417\n",
      "learning rate:  1.0000000000000002e-06 , sim:  18\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008287 val_loss 0.008413\n",
      "learning rate:  1.0000000000000002e-07 , sim:  18\n",
      "train_loss: 0.008771  [   64/250000]\n",
      "train_loss: 0.007933  [32064/250000]\n",
      "train_loss: 0.007918  [64064/250000]\n",
      "train_loss: 0.009926  [96064/250000]\n",
      "train_loss: 0.010331  [128064/250000]\n",
      "train_loss: 0.006789  [160064/250000]\n",
      "train_loss: 0.008251  [192064/250000]\n",
      "train_loss: 0.008663  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008546 val_loss 0.008679\n",
      "learning rate:  1.0000000000000002e-07 , sim:  18\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008303 val_loss 0.008417\n",
      "learning rate:  1.0000000000000002e-07 , sim:  18\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008489 val_loss 0.008631\n",
      "learning rate:  1.0000000000000002e-07 , sim:  18\n",
      "train_loss: 0.006641  [   64/250000]\n",
      "train_loss: 0.007317  [32064/250000]\n",
      "train_loss: 0.010143  [64064/250000]\n",
      "train_loss: 0.006747  [96064/250000]\n",
      "train_loss: 0.007371  [128064/250000]\n",
      "train_loss: 0.009061  [160064/250000]\n",
      "train_loss: 0.011310  [192064/250000]\n",
      "train_loss: 0.009439  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008366 val_loss 0.008463\n",
      "learning rate:  1.0000000000000002e-07 , sim:  18\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008734 val_loss 0.008815\n",
      "learning rate:  1.0000000000000002e-07 , sim:  18\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008514 val_loss 0.008651\n",
      "learning rate:  1.0000000000000002e-07 , sim:  18\n",
      "train_loss: 0.006736  [   64/250000]\n",
      "train_loss: 0.007282  [32064/250000]\n",
      "train_loss: 0.006902  [64064/250000]\n",
      "train_loss: 0.008726  [96064/250000]\n",
      "train_loss: 0.010245  [128064/250000]\n",
      "train_loss: 0.008391  [160064/250000]\n",
      "train_loss: 0.006963  [192064/250000]\n",
      "train_loss: 0.006274  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008330 val_loss 0.008434\n",
      "learning rate:  1.0000000000000002e-07 , sim:  18\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008292 val_loss 0.008430\n",
      "learning rate:  1.0000000000000002e-07 , sim:  18\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008238 val_loss 0.008362\n",
      "learning rate:  1.0000000000000002e-07 , sim:  18\n",
      "train_loss: 2.898669  [   64/250000]\n",
      "train_loss: 1.007567  [32064/250000]\n",
      "train_loss: 0.464343  [64064/250000]\n",
      "train_loss: 0.175311  [96064/250000]\n",
      "train_loss: 0.084218  [128064/250000]\n",
      "train_loss: 0.050427  [160064/250000]\n",
      "train_loss: 0.039742  [192064/250000]\n",
      "train_loss: 0.018190  [224064/250000]\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train_loss 0.018085 val_loss 0.018065\n",
      "learning rate:  1e-05 , sim:  19\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "train_loss 0.009220 val_loss 0.009292\n",
      "learning rate:  1e-05 , sim:  19\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "train_loss 0.008533 val_loss 0.008636\n",
      "learning rate:  1e-05 , sim:  19\n",
      "train_loss: 0.006614  [   64/250000]\n",
      "train_loss: 0.006801  [32064/250000]\n",
      "train_loss: 0.009513  [64064/250000]\n",
      "train_loss: 0.011430  [96064/250000]\n",
      "train_loss: 0.009639  [128064/250000]\n",
      "train_loss: 0.007138  [160064/250000]\n",
      "train_loss: 0.007199  [192064/250000]\n",
      "train_loss: 0.009201  [224064/250000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "train_loss 0.008550 val_loss 0.008643\n",
      "learning rate:  1e-05 , sim:  19\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "train_loss 0.008490 val_loss 0.008593\n",
      "learning rate:  1e-05 , sim:  19\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "train_loss 0.008569 val_loss 0.008667\n",
      "learning rate:  1e-05 , sim:  19\n",
      "train_loss: 0.010161  [   64/250000]\n",
      "train_loss: 0.007493  [32064/250000]\n",
      "train_loss: 0.008372  [64064/250000]\n",
      "train_loss: 0.011072  [96064/250000]\n",
      "train_loss: 0.008955  [128064/250000]\n",
      "train_loss: 0.006753  [160064/250000]\n",
      "train_loss: 0.007244  [192064/250000]\n",
      "train_loss: 0.007201  [224064/250000]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "train_loss 0.008272 val_loss 0.008383\n",
      "learning rate:  1e-05 , sim:  19\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "train_loss 0.008306 val_loss 0.008415\n",
      "learning rate:  1e-05 , sim:  19\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "train_loss 0.008293 val_loss 0.008406\n",
      "learning rate:  1e-05 , sim:  19\n",
      "train_loss: 0.007345  [   64/250000]\n",
      "train_loss: 0.010275  [32064/250000]\n",
      "train_loss: 0.006885  [64064/250000]\n",
      "train_loss: 0.007730  [96064/250000]\n",
      "train_loss: 0.008428  [128064/250000]\n",
      "train_loss: 0.005445  [160064/250000]\n",
      "train_loss: 0.008302  [192064/250000]\n",
      "train_loss: 0.006966  [224064/250000]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "train_loss 0.008324 val_loss 0.008417\n",
      "learning rate:  1e-05 , sim:  19\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "train_loss 0.008241 val_loss 0.008364\n",
      "learning rate:  1.0000000000000002e-06 , sim:  19\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "train_loss 0.008221 val_loss 0.008348\n",
      "learning rate:  1.0000000000000002e-06 , sim:  19\n",
      "train_loss: 0.008339  [   64/250000]\n",
      "train_loss: 0.010130  [32064/250000]\n",
      "train_loss: 0.008450  [64064/250000]\n",
      "train_loss: 0.007832  [96064/250000]\n",
      "train_loss: 0.007455  [128064/250000]\n",
      "train_loss: 0.007916  [160064/250000]\n",
      "train_loss: 0.007100  [192064/250000]\n",
      "train_loss: 0.010378  [224064/250000]\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "train_loss 0.008306 val_loss 0.008420\n",
      "learning rate:  1.0000000000000002e-06 , sim:  19\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "train_loss 0.008219 val_loss 0.008329\n",
      "learning rate:  1.0000000000000002e-06 , sim:  19\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "train_loss 0.008231 val_loss 0.008353\n",
      "learning rate:  1.0000000000000002e-06 , sim:  19\n",
      "train_loss: 0.009604  [   64/250000]\n",
      "train_loss: 0.009103  [32064/250000]\n",
      "train_loss: 0.008319  [64064/250000]\n",
      "train_loss: 0.006363  [96064/250000]\n",
      "train_loss: 0.008657  [128064/250000]\n",
      "train_loss: 0.009362  [160064/250000]\n",
      "train_loss: 0.006885  [192064/250000]\n",
      "train_loss: 0.008653  [224064/250000]\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "train_loss 0.008182 val_loss 0.008294\n",
      "learning rate:  1.0000000000000002e-06 , sim:  19\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "train_loss 0.008149 val_loss 0.008269\n",
      "learning rate:  1.0000000000000002e-06 , sim:  19\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "train_loss 0.008263 val_loss 0.008398\n",
      "learning rate:  1.0000000000000002e-06 , sim:  19\n",
      "train_loss: 0.009595  [   64/250000]\n",
      "train_loss: 0.007139  [32064/250000]\n",
      "train_loss: 0.007477  [64064/250000]\n",
      "train_loss: 0.006588  [96064/250000]\n",
      "train_loss: 0.007961  [128064/250000]\n",
      "train_loss: 0.007083  [160064/250000]\n",
      "train_loss: 0.008303  [192064/250000]\n",
      "train_loss: 0.006775  [224064/250000]\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "train_loss 0.008291 val_loss 0.008405\n",
      "learning rate:  1.0000000000000002e-06 , sim:  19\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "train_loss 0.008194 val_loss 0.008319\n",
      "learning rate:  1.0000000000000002e-06 , sim:  19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201\n",
      "-------------------------------\n",
      "train_loss 0.008337 val_loss 0.008468\n",
      "learning rate:  1.0000000000000002e-07 , sim:  19\n",
      "train_loss: 0.010715  [   64/250000]\n",
      "train_loss: 0.009177  [32064/250000]\n",
      "train_loss: 0.008848  [64064/250000]\n",
      "train_loss: 0.006735  [96064/250000]\n",
      "train_loss: 0.008389  [128064/250000]\n",
      "train_loss: 0.009490  [160064/250000]\n",
      "train_loss: 0.010074  [192064/250000]\n",
      "train_loss: 0.009412  [224064/250000]\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "train_loss 0.008117 val_loss 0.008238\n",
      "learning rate:  1.0000000000000002e-07 , sim:  19\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "train_loss 0.008152 val_loss 0.008286\n",
      "learning rate:  1.0000000000000002e-07 , sim:  19\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "train_loss 0.008400 val_loss 0.008536\n",
      "learning rate:  1.0000000000000002e-07 , sim:  19\n",
      "train_loss: 0.007620  [   64/250000]\n",
      "train_loss: 0.008293  [32064/250000]\n",
      "train_loss: 0.007463  [64064/250000]\n",
      "train_loss: 0.007960  [96064/250000]\n",
      "train_loss: 0.006750  [128064/250000]\n",
      "train_loss: 0.006634  [160064/250000]\n",
      "train_loss: 0.008665  [192064/250000]\n",
      "train_loss: 0.005017  [224064/250000]\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "train_loss 0.008403 val_loss 0.008520\n",
      "learning rate:  1.0000000000000002e-07 , sim:  19\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "train_loss 0.008128 val_loss 0.008247\n",
      "learning rate:  1.0000000000000002e-07 , sim:  19\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "train_loss 0.008140 val_loss 0.008275\n",
      "learning rate:  1.0000000000000002e-07 , sim:  19\n",
      "train_loss: 0.008577  [   64/250000]\n",
      "train_loss: 0.007575  [32064/250000]\n",
      "train_loss: 0.008467  [64064/250000]\n",
      "train_loss: 0.008206  [96064/250000]\n",
      "train_loss: 0.008383  [128064/250000]\n",
      "train_loss: 0.008588  [160064/250000]\n",
      "train_loss: 0.008962  [192064/250000]\n",
      "train_loss: 0.009001  [224064/250000]\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "train_loss 0.008162 val_loss 0.008303\n",
      "learning rate:  1.0000000000000002e-07 , sim:  19\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "train_loss 0.008157 val_loss 0.008307\n",
      "learning rate:  1.0000000000000002e-07 , sim:  19\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "train_loss 0.008249 val_loss 0.008371\n",
      "learning rate:  1.0000000000000002e-07 , sim:  19\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from DNN_module import Net\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Default : cuda\n",
    "torch.set_default_device('cuda')\n",
    "\n",
    "# Number of train and validation data\n",
    "L_train = 250000\n",
    "L_val   =  50000\n",
    "\n",
    "# Define the batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Number of Epochs\n",
    "N_EPOCHS = 300\n",
    "    \n",
    "# Number of Simulations\n",
    "sims = 20\n",
    "\n",
    "tmp = \"infer_sim_0.pt\"\n",
    "tmp = torch.load(tmp)\n",
    "\n",
    "# Data import\n",
    "[X, Y] = tmp\n",
    "X = X.to(device)\n",
    "Y = Y.to(device)\n",
    "\n",
    "# Weighted loss function\n",
    "torch.set_default_device('cuda')\n",
    "def weighted_mse_loss(input, target, weight):\n",
    "        return (weight * (input - target) ** 2).sum()\n",
    "out_range = [torch.min(Y,0).values.detach().cpu().numpy(), torch.max(Y,0).values.detach().cpu().numpy()]\n",
    "\n",
    "weight_1 = torch.tensor(1/(out_range[1] - out_range[0])**2)\n",
    "\n",
    "for sim in range(sims):\n",
    "    \n",
    "    torch.manual_seed(1000 + sim)\n",
    "    indexes = torch.randperm(L_train + L_val)\n",
    "\n",
    "    # Divide Data\n",
    "    X_train = X[indexes[0:L_train]]\n",
    "    Y_train = Y[indexes[0:L_train]]\n",
    "\n",
    "    X_val = X[indexes[L_train:(L_train + L_val)]]\n",
    "    Y_val = Y[indexes[L_train:(L_train + L_val)]]\n",
    "\n",
    "    # Use torch.utils.data to create a DataLoader that will take care of creating batches\n",
    "    dataset = TensorDataset(X_train, Y_train)\n",
    "    dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle=True, generator=torch.Generator(device=device))\n",
    "\n",
    "    # Get the dataset size for printing (it is equal to N_SAMPLES)\n",
    "    dataset_size = len(dataloader.dataset)\n",
    "\n",
    "    # Define the input and output dimensions\n",
    "    D_in, D_out = X_train.size()[1], Y_train.size()[1]\n",
    "\n",
    "    # Create an instance of the Net class with specified dimensions\n",
    "    H, H2, H3 = 256, 256, 256\n",
    "    net = Net(D_in = D_in, D_out = D_out, H = H, H2 = H2, H3 = H3)\n",
    "\n",
    "    # Model name\n",
    "    model_save_name = 'infer_nets/net0/'+str(sim)+'.pt'\n",
    "    path = F\"./{model_save_name}\"\n",
    "\n",
    "    # The nn package also contains definitions of popular loss functions; in this case we will use Mean Squared Error (MSE) as our loss function.\n",
    "    #loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "    learning_rate = 1e-5\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "    train_error_plt = []\n",
    "    val_error_plt = []\n",
    "\n",
    "    torch.manual_seed(2000 + sim)\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        for id_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
    "            y_batch_pred = net(x_batch)\n",
    "            loss = weighted_mse_loss(y_batch, y_batch_pred, weight_1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % 30 ==0 and id_batch % 500 == 0:\n",
    "                loss, current = loss.item(), (id_batch + 1)* len(x_batch)\n",
    "                print(f\"train_loss: {loss/BATCH_SIZE:>7f}  [{current:>5d}/{dataset_size:>5d}]\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            theta_pred_train = net(X_train)\n",
    "            train_loss = weighted_mse_loss(Y_train, theta_pred_train, weight_1) / L_train\n",
    "           \n",
    "            train_error_plt = np.append(train_error_plt, train_loss.to(\"cpu\"))\n",
    "\n",
    "            theta_pred_val = net(X_val)\n",
    "            #val_loss = loss_fn(Y_val, theta_pred_val) / L_val\n",
    "            val_loss = weighted_mse_loss(Y_val, theta_pred_val, weight_1) / L_val\n",
    "         \n",
    "            val_error_plt = np.append(val_error_plt, val_loss.to(\"cpu\"))\n",
    "\n",
    "        if epoch % 10 ==0:\n",
    "            print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "            print(f\"train_loss {train_loss:>7f} val_loss {val_loss:>7f}\")\n",
    "            print(\"learning rate: \", learning_rate, \", sim: \", sim)\n",
    "\n",
    "        ## Choose Best Model\n",
    "        if val_error_plt[epoch] == np.min(val_error_plt):\n",
    "             best=epoch\n",
    "             torch.save(net.state_dict(), path)\n",
    "\n",
    "        if epoch % 100 ==99:\n",
    "            net.load_state_dict(torch.load(path))\n",
    "            learning_rate = max(learning_rate * 1e-1, 1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f1fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypackages2",
   "language": "python",
   "name": "mypackages2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
