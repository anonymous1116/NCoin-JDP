{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e8cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "from torch.distributions.exponential import Exponential\n",
    "from torch.distributions.beta import Beta\n",
    "from torch.distributions.pareto import Pareto\n",
    "\n",
    "def RMSE(results, true):\n",
    "    # results: tensor with 2 dimensions\n",
    "    # array or list\n",
    "    sim = results.size()[0]\n",
    "    p = results.size()[1]\n",
    "    \n",
    "    tmp = 0\n",
    "    for i in range(p):\n",
    "        tmp += torch.sum(torch.square(results[:,i] - true[i] ))/sim\n",
    "    \n",
    "    return torch.sqrt(tmp).detach().cpu().numpy().tolist()\n",
    "\n",
    "def OU_simul_sample(L_OU, time_OU, y0_OU, mu_OU, theta_OU, sigma_OU):\n",
    "    \"\"\"\n",
    "    This function generates a sample path for OU process\n",
    "    L_OU: number of simulation number\n",
    "    y0: initial value\n",
    "    t: time array including initial point\n",
    "    mu, theta, sigma are parameters of OU process dX_t = theta (mu - X_t)dt + sigma dBt\n",
    "    \"\"\"\n",
    "    z0 = y0_OU\n",
    "    path_OU = torch.zeros(L_OU, time_OU.size)\n",
    "    path_OU[:,0] = y0_OU\n",
    "    for l in range(time_OU.size-1):\n",
    "        del_L = time_OU[l+1] - time_OU[l]\n",
    "        OU_mean = z0 * torch.exp(-mu_OU * del_L) + theta_OU * (1- torch.exp(-mu_OU * del_L))\n",
    "        OU_sd = torch.sqrt( sigma_OU**2/(2*mu_OU) * (1- torch.exp(-2 * mu_OU * del_L)) )\n",
    "        z0 = torch.normal(OU_mean, OU_sd)\n",
    "        path_OU[:,l+1] = z0\n",
    "    return(path_OU)\n",
    "\n",
    "def CIR_simul_sample(obtime, a, b, sigma, y0 = None):\n",
    "    \"\"\"\n",
    "    This function generates a one sample path between an interval for CIR process\n",
    "    y0_CIR: initial value\n",
    "    m : num of slice of each interval\n",
    "    t_CIR: time array including initial point\n",
    "    a, b, sigma are parameters of CIR process dX_t = a (b - X_t)dt + \\sigma sqrt{X_t} dBt\n",
    "    \"\"\"\n",
    "    if y0 is None:\n",
    "        shape = 2 * a * b\n",
    "        shape = shape.numpy()\n",
    "        scale = sigma ** 2 / (2 * a)\n",
    "        scale = scale.numpy()\n",
    "        y0 = np.random.gamma(shape, scale)\n",
    "        y0 = torch.from_numpy(y0)\n",
    "\n",
    "    L = a.size()[0]\n",
    "    z0 = y0\n",
    "    \n",
    "    path = torch.zeros(L, obtime.size)\n",
    "    path[:,0] = y0\n",
    "    \n",
    "    nu0 = 4 * a * b / sigma ** 2\n",
    "    nu0 = nu0.numpy()\n",
    "    \n",
    "    for l in range(obtime.size-1):\n",
    "        del_L = obtime[l+1] - obtime[l]\n",
    "        c0 = 4 * a / sigma ** 2 / (1- torch.exp(-a * del_L))\n",
    "        lambda0 = c0 * z0 * torch.exp(-a * del_L)\n",
    "        lambda0 = lambda0.numpy()\n",
    "        tmp = np.random.noncentral_chisquare(nu0, lambda0)\n",
    "        tmp = torch.from_numpy(tmp)\n",
    "        z0 = tmp/c0\n",
    "        path[:,l+1] = z0\n",
    "    return(path)\n",
    "\n",
    "def Jacobi_sample(del_Jacobi, m_Jacobi, y0_Jacobi, a_Jacobi, b_Jacobi, sigma_Jacobi):\n",
    "    \"\"\"\n",
    "    This function generates a one sample path between an interval for Jacobi process\n",
    "    y0_Jacobi: initial value\n",
    "    m : num of slice of each interval\n",
    "    t_Jacobi: time array including initial point\n",
    "    a, b, sigma are parameters of Jacobi process dX_t = a (b - X_t)dt + \\sigma sqrt{X_t (1- X_t)} dBt\n",
    "    \"\"\"\n",
    "    L_tmp = a_Jacobi.size()[0]\n",
    "    del_tmp = del_Jacobi / m_Jacobi\n",
    "    z0 = y0_Jacobi\n",
    "    for j in range(m_Jacobi):\n",
    "        ran_num = torch.normal(0 * torch.ones(L_tmp),1 * torch.ones(L_tmp))\n",
    "        z0 = z0 + a_Jacobi*(b_Jacobi-z0)*del_tmp + sigma_Jacobi*torch.mul(torch.sqrt(z0),torch.sqrt(torch.ones(L_tmp)-z0))*((del_tmp)**(1/2))*ran_num + (torch.pow(sigma_Jacobi,2) )/4*(torch.ones(L_tmp)-2*z0)*(del_tmp*(torch.pow(ran_num,2)-1)) # Milstein approximation\n",
    "        z0 = torch.max(z0,0 * torch.ones(L_tmp))\n",
    "        z0 = torch.min(z0,1 * torch.ones(L_tmp))\n",
    "    return(z0)\n",
    "\n",
    "def Jacobi_simul_sample(L_Jacobi, time_Jacobi, m_Jacobi, y0_Jacobi, a_Jacobi, b_Jacobi, sigma_Jacobi):\n",
    "    \"\"\"\n",
    "    This function generates a sample path for Jacobi process\n",
    "    L_Jacobi: number of simulation number\n",
    "    y0_Jacobi: initial value\n",
    "    m : num of slice of each interval\n",
    "    t_Jacobi: time array including initial point\n",
    "    a, b, sigma are parameters of Jacobi process dX_t = a (b - X_t)dt + \\sigma sqrt{X_t (1- X_t)} dBt\n",
    "    \"\"\"\n",
    "    tmp = y0_Jacobi\n",
    "    path_Jacobi = torch.zeros(L_Jacobi, time_Jacobi.size)\n",
    "    path_Jacobi[:,0] = y0_Jacobi\n",
    "    for l in range(time_Jacobi.size-1):\n",
    "        del_L = time_Jacobi[l+1] - time_Jacobi[l]\n",
    "        new_path = Jacobi_sample(del_L, m_Jacobi, tmp, a_Jacobi, b_Jacobi, sigma_Jacobi) \n",
    "        path_Jacobi[:,l+1] = new_path\n",
    "        tmp = torch.clone(new_path)\n",
    "    return(path_Jacobi)\n",
    "\n",
    "def TriOU_simul_sample(x01_TriOU, x02_TriOU, x03_TriOU, t_TriOU, m0, kappa_11, kappa_21, kappa_22, kappa_31, kappa_32, kappa_33):\n",
    "    \"\"\"\n",
    "    This function generates a sample path for Triple OU process\n",
    "    \"\"\"\n",
    "    \n",
    "    x01 = x01_TriOU\n",
    "    x02 = x02_TriOU\n",
    "    x03 = x03_TriOU\n",
    "\n",
    "    L_TriOU = x01_TriOU.size()[0]\n",
    "\n",
    "    path_TriOU = torch.zeros(L_TriOU, 3, t_TriOU.size)\n",
    "    \n",
    "    path_TriOU[:,0,0] = x01_TriOU\n",
    "    path_TriOU[:,1,0] = x02_TriOU\n",
    "    path_TriOU[:,2,0] = x03_TriOU\n",
    "    \n",
    "    for l in range(t_TriOU.size-1):\n",
    "        # X, Y generating\n",
    "        del_x = t_TriOU[l+1] - t_TriOU[l]\n",
    "        del_del = del_x / m0\n",
    "\n",
    "        for j in range(m0):\n",
    "            ran_num1 = torch.normal(0 * torch.ones(L_TriOU), 1 * torch.ones(L_TriOU))\n",
    "            ran_num2 = torch.normal(0 * torch.ones(L_TriOU), 1 * torch.ones(L_TriOU))\n",
    "            ran_num3 = torch.normal(0 * torch.ones(L_TriOU), 1 * torch.ones(L_TriOU))\n",
    "            \n",
    "            x01 =  x01 - kappa_11*  x01 * del_del + ((del_del)**(1/2)) * ran_num1\n",
    "            x02 =  x02 + ( - kappa_21*  x01 - kappa_22 * x02)  * del_del + ((del_del)**(1/2)) * ran_num2   # Euler approximation\n",
    "            x03 =  x03 + ( - kappa_31*  x01 - kappa_32 * x02 - kappa_33 * x03 )  * del_del + ((del_del)**(1/2)) * ran_num3   # Euler approximation\n",
    "\n",
    "        path_TriOU[:,0,l+1] = x01\n",
    "        path_TriOU[:,1,l+1] = x02\n",
    "        path_TriOU[:,2,l+1] = x03\n",
    "    return(path_TriOU)\n",
    "\n",
    "def MROUJ_simul_sample(obtime, m, y0, kappa, beta, sigma, lamb, mu):\n",
    "    \"\"\"\n",
    "    This function generates a one sample path between an interval for VNJ process\n",
    "    dX_t = \\kappa(beta-X_t)dt + sigma dB_t + J_t where N_t: Poisson process with lamb, Z_i ~ Exp(mu)\n",
    "    y0_VNJ: initial value\n",
    "    m : num of slice of each interval\n",
    "    \"\"\"\n",
    "    L_tmp = kappa.size()[0]\n",
    "    z0 = y0\n",
    "    path = torch.zeros(L_tmp, obtime.size)\n",
    "    path[:,0] = z0\n",
    "\n",
    "    for l in range(len(obtime)-1):\n",
    "        # X, Y generating\n",
    "        del_x = obtime[l+1] - obtime[l]\n",
    "        del_y = del_x / m\n",
    "\n",
    "        for j in range(m):\n",
    "            ran_num = torch.normal(0 * torch.ones(L_tmp), torch.ones(L_tmp))\n",
    "            ran_num2 = Exponential(mu * torch.ones(L_tmp)).sample() # rate\n",
    "            ran_num3 = torch.poisson(torch.ones(L_tmp) * lamb * del_y)\n",
    "            z0 = z0 + kappa*(beta-z0)*del_y + sigma * ran_num * del_y ** (1/2) + ran_num2 * ran_num3\n",
    "        path[:,l+1] = z0\n",
    "    return(path)\n",
    "\n",
    "\n",
    "def SQRJ_simul_sample(obtime, m, y0, kappa, beta, sigma, lamb, mu):\n",
    "    \"\"\"\n",
    "    This function generates a one sample path between an interval for VNJ process\n",
    "    dX_t = \\kappa(beta-X_t)dt + sigma dB_t + J_t where N_t: Poisson process with lamb, Z_i ~ Exp(mu)\n",
    "    y0_VNJ: initial value\n",
    "    m : num of slice of each interval\n",
    "    \"\"\"\n",
    "    L_tmp = kappa.size()[0]\n",
    "    z0 = y0\n",
    "    path = torch.zeros(L_tmp, obtime.size)\n",
    "    path[:,0] = z0\n",
    "\n",
    "    for l in range(len(obtime)-1):\n",
    "        # X, Y generating\n",
    "        del_x = obtime[l+1] - obtime[l]\n",
    "        del_y = del_x / m\n",
    "\n",
    "        for j in range(m):\n",
    "            ran_num = torch.normal(0 * torch.ones(L_tmp), torch.ones(L_tmp))\n",
    "            ran_num2 = Exponential(mu * torch.ones(L_tmp)).sample() # rate\n",
    "            ran_num3 = torch.poisson(torch.ones(L_tmp) * lamb * del_y)\n",
    "            z0 = z0 + kappa*(beta-z0)*del_y + sigma * torch.sqrt(z0) * ran_num * del_y ** (1/2) + sigma ** 2 /2 *(del_y*(torch.pow(ran_num,2)-1)) + ran_num2 * ran_num3 # Milstein + Jump\n",
    "            z0 = torch.max(z0,1e-10 * torch.ones(L_tmp))\n",
    "        path[:,l+1] = z0\n",
    "    return(path)\n",
    "\n",
    "\n",
    "\n",
    "def BOUJ_simul_sample(obtime, m, x01, x02, kappa_11, kappa_21, kappa_22, theta_1, theta_2, sigma_1, sigma_2, lamb_1, lamb_2, mu_1, mu_2):\n",
    "    \"\"\"\n",
    "    This function generates a sample path for bivariate OU process\n",
    "    \"\"\"\n",
    "    L = kappa_11.size()[0]\n",
    "    z01 = x01\n",
    "    z02 = x02\n",
    "    \n",
    "    path = torch.zeros(2, L, len(obtime))\n",
    "    path[0,:,0] = z01\n",
    "    path[1,:,0] = z02\n",
    "\n",
    "    for l in range(len(obtime)-1):\n",
    "        # X, Y generating\n",
    "        del_x = obtime[l+1] - obtime[l]\n",
    "        del_y = del_x / m\n",
    "\n",
    "        for j in range(m):\n",
    "            ran_num1 = torch.normal(0 * torch.ones(L), 1 * torch.ones(L))\n",
    "            ran_num2 = torch.normal(0 * torch.ones(L), 1 * torch.ones(L))\n",
    "            \n",
    "            ran_num3 = torch.poisson( torch.ones(L) * lamb_1 * del_y)\n",
    "            ran_num4 = torch.poisson( torch.ones(L) * lamb_2 * del_y)\n",
    "            \n",
    "            ran_num5 = Exponential(mu_1 * torch.ones(L)).sample() # rate\n",
    "            ran_num6 = Exponential(mu_2 * torch.ones(L)).sample() # rate\n",
    "            \n",
    "            z01 = z01 + kappa_11* (theta_1 - z01 ) * del_y \n",
    "            z01 = z01 + (del_y**(1/2)) * sigma_1 * ran_num1\n",
    "            z01 = z01 + ran_num3 * ran_num5\n",
    "            \n",
    "            z02 = z02 + (kappa_21* (theta_1-z01)+kappa_22*(theta_2-z02))*del_y \n",
    "            z02 = z02 + (del_y**(1/2)) * sigma_2* ran_num2  \n",
    "            z02 = z02 + ran_num4 * ran_num6\n",
    "            \n",
    "        path[0,:,l+1] = z01\n",
    "        path[1,:,l+1] = z02\n",
    "    return(path)\n",
    "\n",
    "\n",
    "def PBJD_simul_sample(obtime, y0, beta, sigma, lamb_p, lamb_n, eta_p, eta_n):\n",
    "    \"\"\"\n",
    "    This function generates a one sample path between an interval for PBJD process\n",
    "    dX_t = muX_tdt + sigma dB_t + J_1t + J_2t \n",
    "    m : num of slice of each interval\n",
    "    \"\"\"\n",
    "    L_tmp = beta.size()[0]\n",
    "    z0 = y0\n",
    "    path = torch.zeros(L_tmp, obtime.size)\n",
    "    path[:,0] = z0\n",
    "\n",
    "    for l in range(len(obtime)-1):\n",
    "        # X, Y generating\n",
    "        del_x = obtime[l+1] - obtime[l]\n",
    "\n",
    "        ran_num = torch.normal(0 * torch.ones(L_tmp), torch.ones(L_tmp))\n",
    "            \n",
    "        # jump to positive\n",
    "        ran_num2 = torch.zeros(L_tmp)\n",
    "        tmp = torch.poisson( torch.ones(L_tmp) * lamb_p * del_x)\n",
    "        for i in range(int(torch.max(tmp))+1):\n",
    "            if (i > 0) and (tmp == i).sum() > 0:\n",
    "                eta_tmp = eta_p[tmp ==i]\n",
    "                eta_tmp = eta_tmp.repeat(i, 1)\n",
    "                tmp3 = torch.log(Pareto(torch.tensor([1.0]), eta_tmp).sample())\n",
    "                tmp3 = torch.sum(tmp3, 0)\n",
    "                ran_num2[tmp == i] = tmp3\n",
    "        ran_num2 = torch.min(ran_num2, torch.ones(L_tmp) * 1000)\n",
    "            \n",
    "        # jump to negative\n",
    "        ran_num3 = torch.zeros(L_tmp)\n",
    "        tmp = torch.poisson( torch.ones(L_tmp) * lamb_n * del_x)\n",
    "        for i in range(int(torch.max(tmp))+1):\n",
    "            if (i > 0) and (tmp == i).sum() > 0:\n",
    "                eta_tmp = eta_n[tmp ==i]\n",
    "                eta_tmp = eta_tmp.repeat(i, 1)\n",
    "                tmp3 = torch.log(Beta(eta_tmp, torch.tensor([1.0])).sample())\n",
    "                tmp3 = torch.sum(tmp3, 0)\n",
    "                ran_num3[tmp == i] = tmp3\n",
    "        ran_num3 = torch.max(ran_num3, -torch.ones(L_tmp) * 1000)\n",
    "        \n",
    "        z0 = z0 + (beta - sigma ** 2/ 2) * del_x + sigma * ran_num * del_x ** (1/2) + ran_num2 + ran_num3\n",
    "        #z0 = z0 + (beta) * del_x + sigma * ran_num * del_x ** (1/2) + ran_num2 + ran_num3\n",
    "        \n",
    "        path[:,l+1] = z0\n",
    "    return(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138bd354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLE_OU(sim_OU, obtime_OU, delta_OU):\n",
    "    \"\"\"\n",
    "    sim_OU size : sim * n_OU\n",
    "    \"\"\"\n",
    "    sim_num = sim_OU.size()[0]\n",
    "    n_OU = len(obtime_OU)\n",
    "    n0_OU = n_OU -1\n",
    "    vec_xi = sim_OU[:, 1:]\n",
    "    vec_xim1 = sim_OU[:, :n0_OU]\n",
    "    beta1 = (torch.sum(vec_xi * vec_xim1,1) - 1/n0_OU * torch.sum(vec_xi, 1) * torch.sum(vec_xim1, 1) ) / (torch.sum(vec_xim1 ** 2, 1) - 1/n0_OU * (torch.sum(vec_xim1, 1))**2   ) # size : sim\n",
    "    beta2 = 1/n0_OU * (  torch.sum(vec_xi,1) - beta1 * torch.sum(vec_xim1,1) ) / (torch.ones(sim_num)-beta1) # size: sim\n",
    "\n",
    "    tmp1 = beta1.repeat(n_OU-1, 1) # sim *n_OU\n",
    "    tmp1 = torch.transpose(tmp1, 0,1)\n",
    "    tmp2 = beta2 * (torch.ones(sim_num)-beta1)\n",
    "    tmp3 = tmp2.repeat(n_OU-1, 1)\n",
    "    tmp3 = torch.transpose(tmp3, 0,1)\n",
    "    tmp_beta3 = (vec_xi - tmp1 * vec_xim1 - tmp3) # size: sim * n_OU\n",
    "    beta3 = 1/n0_OU * torch.sum(tmp_beta3**2, 1)\n",
    "    mu = -torch.ones(sim_num) * torch.log(beta1) / delta_OU\n",
    "    alpha = beta2\n",
    "    sigma = torch.sqrt(2 * mu * beta3 / (torch.ones(sim_num) - beta1 ** 2 ))\n",
    "\n",
    "    return(torch.stack((mu, alpha,sigma ** 2), 1))\n",
    "\n",
    "def PMLE_CIR(sim_CIR, obtime_CIR, delta_CIR):\n",
    "    sim_num = sim_CIR.size()[0]\n",
    "    n_CIR = len(obtime_CIR)\n",
    "    n0_CIR = n_CIR -1\n",
    "    vec_xi = sim_CIR[:, 1:]\n",
    "    vec_xim1 = sim_CIR[:, :n0_CIR]\n",
    "    beta1 = (- torch.sum(vec_xi / vec_xim1,1) + 1/n0_CIR * torch.sum(vec_xi, 1) * torch.sum(1/vec_xim1, 1) ) / (1/n0_CIR * torch.sum(vec_xim1, 1) * torch.sum((1/vec_xim1), 1) - n0_CIR  ) # size : sim\n",
    "    beta2 = (1/n0_CIR * (  torch.sum(vec_xi / vec_xim1, 1)) - beta1 ) / ((torch.ones(sim_num)-beta1) * 1/n0_CIR * torch.sum(1/vec_xim1, 1) ) # size: sim\n",
    "    \n",
    "    tmp1 = beta1.repeat(n_CIR-1, 1) # sim *n_CIR\n",
    "    tmp1 = torch.transpose(tmp1, 0,1)\n",
    "    tmp2 = beta2 * (torch.ones(sim_num)-beta1)\n",
    "    tmp3 = tmp2.repeat(n_CIR-1, 1)\n",
    "    tmp3 = torch.transpose(tmp3, 0,1)\n",
    "    tmp_beta3 = (vec_xi - tmp1 * vec_xim1 - tmp3) # size: sim * n_CIR\n",
    "    beta3 = 1/n0_CIR * torch.sum(tmp_beta3**2 /vec_xim1, 1)\n",
    "    \n",
    "    mu = -torch.ones(sim_num) * torch.log(beta1) / delta_CIR\n",
    "    alpha = beta2\n",
    "    sigma = torch.sqrt(2 * mu * beta3 / (torch.ones(sim_num) - beta1 ** 2 ))\n",
    "\n",
    "    return(torch.stack((mu, alpha,sigma ** 2), 1))\n",
    "\n",
    "def LSE_TriOU(sim_data, delta_ob):\n",
    "    A = torch.matmul(sim_data[:,:,1:(n+1)], torch.transpose(sim_data[:,:,0:n],1,2 ))\n",
    "    B = torch.linalg.inv(torch.matmul(sim_data[:,:,0:n],torch.transpose(sim_data[:,:,0:n],1,2) ))\n",
    "    Fhat = torch.matmul(A,B)\n",
    "    diag3 = torch.diag(torch.tensor([1,1,1]))\n",
    "    Ahat1 = -(Fhat - diag3) / delta_ob\n",
    "    Ahat2 = -2* torch.matmul((Fhat - diag3), torch.linalg.inv(Fhat + diag3)) / delta_ob\n",
    "\n",
    "    Ahat1 = torch.stack((Ahat1[:,0,0], Ahat1[:,1,0], Ahat1[:,1,1], Ahat1[:,2,0], Ahat1[:,2,1], Ahat1[:,2,2]), 1)\n",
    "    Ahat2 = torch.stack((Ahat2[:,0,0], Ahat2[:,1,0], Ahat2[:,1,1], Ahat2[:,2,0], Ahat2[:,2,1], Ahat2[:,2,2]), 1)\n",
    "\n",
    "    return([Ahat1,Ahat2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08917f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OU_summary(X):\n",
    "    \"\"\"\n",
    "    X: torch size: [L,n]\n",
    "    \"\"\"\n",
    "    L0 = X.size()[0]\n",
    "    n0 = X.size()[1]\n",
    "\n",
    "    sum1 = torch.zeros(L0) # sum x_i x_{i-1}\n",
    "    sum2 = torch.zeros(L0) # sum x_i\n",
    "    sum3 = torch.zeros(L0) # sum x_{i-1}\n",
    "    sum4 = torch.zeros(L0) # sum x_{i-1}^2\n",
    "    sum5 = torch.zeros(L0) # sum x_{i}^2\n",
    "\n",
    "    for l in range(n0-1):\n",
    "      sum1 = sum1 + X[:,l+1] * X[:,l]\n",
    "      sum2 = sum2 + X[:,l+1]\n",
    "      sum3 = sum3 + X[:,l]\n",
    "      sum4 = sum4 + torch.pow(X[:,l],2)\n",
    "      sum5 = sum5 + torch.pow(X[:,l+1],2)\n",
    "    return(torch.stack(( (sum1 - sum2 * sum3/n0 ) /n0, sum2/n0, sum3/n0, sum4/n0 - (sum3/n0)**2, sum5/n0 - (sum2/n0)**2) ,1))\n",
    "\n",
    "def OU_summary2(X):\n",
    "    \"\"\"\n",
    "    X: torch size: [L,n]\n",
    "    \"\"\"\n",
    "    L0 = X.size()[0]\n",
    "    n0 = X.size()[1]\n",
    "\n",
    "    L0 = X.size()[0]\n",
    "    n0 = X.size()[1]\n",
    "    \n",
    "    X0 = X[:,:-1]\n",
    "    X1 = X[:,1:]\n",
    "    \n",
    "    s0 = torch.mean(X0, 1, keepdim=True) # mean of x_{i-1}\n",
    "    s1 = torch.mean(X1, 1, keepdim=True) # mean of x_i\n",
    "    \n",
    "    s2 = torch.mean((X0 - s0) * (X1 - s1),1,keepdim=True)\n",
    "    s3 = torch.mean((X0 - s0)**2,1, keepdim=True)\n",
    "    s4 = torch.mean((X1 - s1)**2,1, keepdim=True)\n",
    "    \n",
    "    s5 = torch.mean((X0 - s0)**2 * (X1 - s1), 1, keepdim=True) /n0\n",
    "    s6 = torch.mean((X0 - s0) * (X1 - s1)**2, 1, keepdim=True) /n0\n",
    "    s7 = torch.mean((X0 - s0)**2 * (X1 - s1)**2, 1, keepdim=True) / (n0 ** 2)\n",
    "    \n",
    "    return(torch.column_stack((s0, s1, s2, s3, s4, s5, s6, s7)) ) \n",
    "\n",
    "\n",
    "def CIR_summary(X):\n",
    "    \"\"\"\n",
    "    X: torch size: [L,n]\n",
    "    \"\"\"\n",
    "    L0 = X.size()[0]\n",
    "    n0 = X.size()[1]\n",
    "    \n",
    "    X0 = X[:,:-1]\n",
    "    X1 = X[:,1:]\n",
    "    \n",
    "    s0 = torch.mean(X0, 1, keepdim=True) # mean of x_{i-1}\n",
    "    s1 = torch.mean(X1, 1, keepdim=True) # mean of x_i\n",
    "    \n",
    "    s2 = torch.mean((X0 - s0) * (X1 - s1),1,keepdim=True)\n",
    "    s3 = torch.mean((X0 - s0)**2,1, keepdim=True)\n",
    "    s4 = torch.mean((X1 - s1)**2,1, keepdim=True)\n",
    "    \n",
    "    s5 = torch.mean(1/ X0, 1, keepdim=True)\n",
    "    s6 = torch.mean(X1/ X0, 1, keepdim=True)\n",
    "    s7 = torch.mean(X1 ** 2/ X0, 1, keepdim=True)\n",
    "    s8 = torch.log(torch.max(X0, 1e-10*torch.ones(1)))\n",
    "    s8 = torch.mean(s8, 1, keepdim=True)\n",
    "    \n",
    "    s9 = torch.mean((X0 - s0)**2 * (X1 - s1), 1, keepdim=True)\n",
    "    s10 = torch.mean((X0 - s0) * (X1 - s1)**2, 1, keepdim=True)\n",
    "    s11 = torch.mean((X0 - s0)**2 * (X1 - s1)**2, 1, keepdim=True)\n",
    "    \n",
    "    \n",
    "    return(torch.column_stack((s0, s1, s2, s3, s4, s5, s6, s7, s8, s9, s10, s11)) ) \n",
    "\n",
    "def CIR_summary2(X):\n",
    "    \"\"\"\n",
    "    X: torch size: [L,n]\n",
    "    \"\"\"\n",
    "    L0 = X.size()[0]\n",
    "    n0 = X.size()[1]\n",
    "    \n",
    "    X0 = X[:,:-1]\n",
    "    X1 = X[:,1:]\n",
    "    \n",
    "    s0 = torch.mean(X0, 1, keepdim=True) # mean of x_{i-1}\n",
    "    s1 = torch.mean(X1, 1, keepdim=True) # mean of x_i\n",
    "    \n",
    "    s2 = torch.mean((X0 - s0) * (X1 - s1),1,keepdim=True)\n",
    "    s3 = torch.mean((X0 - s0)**2,1, keepdim=True)\n",
    "    s4 = torch.mean((X1 - s1)**2,1, keepdim=True)\n",
    "    \n",
    "    s5 = torch.mean(1/ X0, 1, keepdim=True)\n",
    "    s6 = torch.mean(X1/ X0, 1, keepdim=True)\n",
    "    s7 = torch.mean(X1 ** 2/ X0, 1, keepdim=True)\n",
    "    \n",
    "    s8 = torch.mean((X0 - s0)**2 * (X1 - s1), 1, keepdim=True)\n",
    "    s9 = torch.mean((X0 - s0) * (X1 - s1)**2, 1, keepdim=True)\n",
    "    s10 = torch.mean((X0 - s0)**2 * (X1 - s1)**2, 1, keepdim=True)\n",
    "    \n",
    "    return(torch.column_stack((s0, s1, s2, s3, s4, s5, s6, s7, s8, s9, s10)) ) \n",
    "\n",
    "\n",
    "def CIR_summary3(X):\n",
    "    \"\"\"\n",
    "    X: torch size: [L,n]\n",
    "    \"\"\"\n",
    "    L0 = X.size()[0]\n",
    "    n0 = X.size()[1]\n",
    "    \n",
    "    X0 = X[:,:-1]\n",
    "    X1 = X[:,1:]\n",
    "    \n",
    "    s0 = torch.mean(X0, 1, keepdim=True) # mean of x_{i-1}\n",
    "    s1 = torch.mean(X1, 1, keepdim=True) # mean of x_i\n",
    "    \n",
    "    s2 = torch.mean((X0 - s0) * (X1 - s1), 1, keepdim=True)\n",
    "    s3 = torch.mean((X0 - s0)**2, 1, keepdim=True)\n",
    "    s4 = torch.mean((X1 - s1)**2, 1, keepdim=True)\n",
    "    \n",
    "    s5 = torch.mean(1/ X0, 1, keepdim=True)\n",
    "    s6 = torch.mean(X1/ X0, 1, keepdim=True)\n",
    "    s7 = torch.mean(X1 ** 2/ X0, 1, keepdim=True)\n",
    "    \n",
    "    s8 = torch.log(torch.max(X0, 1e-10*torch.ones(1)))\n",
    "    s8 = torch.mean(s8, 1, keepdim=True)\n",
    "    return(torch.column_stack((s0, s1, s2, s3, s4, s5, s6, s7, s8)) ) \n",
    "\n",
    "def Jacobi_summary(X):\n",
    "    \"\"\"\n",
    "    X: torch size: [L,n]\n",
    "    \"\"\"\n",
    "    L0 = X.size()[0]\n",
    "    n0 = X.size()[1]\n",
    "    X1 = X[:,:-1]\n",
    "    X2 = X[:,1:]\n",
    "    \n",
    "    s1 = torch.mean(X[:,:-1], 1, keepdim=True) # mean of x_{i-1}\n",
    "    s2 = torch.mean(X[:,1:], 1, keepdim=True) # mean of x_i\n",
    "    \n",
    "    s3 = torch.mean((X1 - s1) * (X2 - s2),1,keepdim=True)\n",
    "    s4 = torch.mean((X1 - s1)**2,1, keepdim=True)\n",
    "    s5 = torch.mean((X2 - s2)**2,1, keepdim=True)\n",
    "    \n",
    "    s6 = torch.mean((X1 - s1)**2 * (X2 - s2), 1, keepdim=True)\n",
    "    s7 = torch.mean((X1 - s1) * (X2 - s2)**2, 1, keepdim=True)\n",
    "    \n",
    "    s8 = torch.mean((X1 - s1)**2 * (X2 - s2)**2, 1, keepdim=True)\n",
    "      \n",
    "    return(torch.column_stack((s1, s2, s3, s4, s5, s6, s7, s8)) ) \n",
    "\n",
    "def TriOU_summary(ten):\n",
    "    \"\"\"\n",
    "    X: torch size: [L,n]\n",
    "    \"\"\"\n",
    "    L0 = ten.size()[0]\n",
    "    n0 = ten.size()[2]\n",
    "\n",
    "    sum1_1 = torch.zeros(L0) # sum x_{i-1}\n",
    "    sum1_2 = torch.zeros(L0) # sum x_{i-1}^2\n",
    "    sum1_3 = torch.zeros(L0) # sum x_{i}^2\n",
    "    sum1_4 = torch.zeros(L0) # sum x_{i} * x_{i-1}\n",
    "    sum1_5 = torch.zeros(L0) # sum y_{i-1}\n",
    "    \n",
    "    sum2_1 = torch.zeros(L0) # sum y_{i-1}^2\n",
    "    sum2_2 = torch.zeros(L0) # sum y_{i}\n",
    "    sum2_3 = torch.zeros(L0) # sum y_{i}^2\n",
    "    sum2_4 = torch.zeros(L0) # sum y_{i} * y_{i-1}\n",
    "    sum2_5 = torch.zeros(L0) # sum y_{i} * y_{i-1}\n",
    "    \n",
    "    sum3_1 = torch.zeros(L0) # sum z_{i-1}^2\n",
    "    sum3_2 = torch.zeros(L0) # sum z_{i}\n",
    "    sum3_3 = torch.zeros(L0) # sum z_{i}^2\n",
    "    sum3_4 = torch.zeros(L0) # sum z_{i} * z_{i-1}\n",
    "    sum3_5 = torch.zeros(L0) # sum z_{i} * z_{i-1}\n",
    "    \n",
    "    sum12_1 = torch.zeros(L0) # sum_x_{i-1} y_{i-1}\n",
    "    sum12_2 = torch.zeros(L0) # sum_x_{i} y_{i-1}\n",
    "    sum12_3 = torch.zeros(L0) # sum x_{i-1} y_i\n",
    "    sum12_4 = torch.zeros(L0) # sum x_{i} y_{i}\n",
    "    sum12_5 = torch.zeros(L0) # sum x_{i}^2 y_{i}^2\n",
    "    sum12_6 = torch.zeros(L0) # sum x_{i-1}^2 y_{i-1}^2\n",
    "    \n",
    "    sum23_1 = torch.zeros(L0) # sum_y_{i-1} z_{i-1}\n",
    "    sum23_2 = torch.zeros(L0) # sum_y_{i} z_{i-1}\n",
    "    sum23_3 = torch.zeros(L0) # sum y_{i-1} z_i\n",
    "    sum23_4 = torch.zeros(L0) # sum y_{i} z_{i}\n",
    "    sum23_5 = torch.zeros(L0) # sum y_{i}^2 z_{i}^2\n",
    "    sum23_6 = torch.zeros(L0) # sum y_{i-1}^2 z_{i-1}^2\n",
    "    \n",
    "    sum13_1 = torch.zeros(L0) # sum_x_{i-1} z_{i-1}\n",
    "    sum13_2 = torch.zeros(L0) # sum_x_{i} z_{i-1}\n",
    "    sum13_3 = torch.zeros(L0) # sum x_{i-1} z_i\n",
    "    sum13_4 = torch.zeros(L0) # sum x_{i} z_{i}\n",
    "    sum13_5 = torch.zeros(L0) # sum x_{i}^2 z_{i}^2\n",
    "    sum13_6 = torch.zeros(L0) # sum x_{i-1}^2 z_{i-1}^2\n",
    "    \n",
    "    sum123_1 = torch.zeros(L0) # \n",
    "    sum123_2 = torch.zeros(L0) # \n",
    "    sum123_3 = torch.zeros(L0) # \n",
    "    sum123_4 = torch.zeros(L0) # \n",
    "    sum123_5 = torch.zeros(L0) # \n",
    "    sum123_6 = torch.zeros(L0) # \n",
    "    sum123_7 = torch.zeros(L0) # \n",
    "\n",
    "    for l in range(n0-1):\n",
    "      sum1_1 = sum1_1 + ten[:,0,l]\n",
    "      sum1_2 = sum1_2 + torch.pow(ten[:,0,l], 2)\n",
    "      sum1_3 = sum1_3 + ten[:,0,(l+1)]\n",
    "      sum1_4 = sum1_4 + torch.pow(ten[:,0,l+1], 2)\n",
    "      sum1_5 = sum1_5 + ten[:,0,l] * ten[:,0,l+1]\n",
    "      \n",
    "      sum2_1 = sum2_1 + ten[:,1,l]\n",
    "      sum2_2 = sum2_2 + torch.pow(ten[:,1,l], 2)\n",
    "      sum2_3 = sum2_3 + ten[:,1,(l+1)]\n",
    "      sum2_4 = sum2_4 + torch.pow(ten[:,1,l+1], 2)\n",
    "      sum2_5 = sum2_5 + ten[:,1,l] * ten[:,1,l+1]\n",
    "      \n",
    "      sum3_1 = sum2_1 + ten[:,2,l]\n",
    "      sum3_2 = sum2_2 + torch.pow(ten[:,2,l], 2)\n",
    "      sum3_3 = sum2_3 + ten[:,2,(l+1)]\n",
    "      sum3_4 = sum2_4 + torch.pow(ten[:,2,l+1], 2)\n",
    "      sum3_5 = sum2_5 + ten[:,2,l] * ten[:,2,l+1]\n",
    "      \n",
    "      sum12_1 = sum12_1 + ten[:,0,l] * ten[:,1,l]\n",
    "      sum12_2 = sum12_2 + ten[:,0,l+1] * ten[:,1,l]\n",
    "      sum12_3 = sum12_3 + ten[:,0,l] * ten[:,1,l+1]\n",
    "      sum12_4 = sum12_4 + ten[:,0,l+1] * ten[:,1,l+1]\n",
    "      sum12_5 = sum12_5 + torch.pow(ten[:,0,l+1],2) * ten[:,1,l+1]\n",
    "      sum12_6 = sum12_6 + torch.pow(ten[:,0,l+1],2) * torch.pow(ten[:,1,l+1],2)\n",
    "      \n",
    "      sum23_1 = sum23_1 + ten[:,1,l] * ten[:,2,l]\n",
    "      sum23_2 = sum23_2 + ten[:,1,l+1] * ten[:,2,l]\n",
    "      sum23_3 = sum23_3 + ten[:,1,l] * ten[:,2,l+1]\n",
    "      sum23_4 = sum23_4 + ten[:,1,l+1] * ten[:,2,l+1]\n",
    "      sum23_5 = sum23_5 + torch.pow(ten[:,1,l+1],2) * ten[:,2,l+1]\n",
    "      sum23_6 = sum23_6 + torch.pow(ten[:,1,l+1],2) * torch.pow(ten[:,2,l+1],2)\n",
    "      \n",
    "      sum13_1 = sum13_1 + ten[:,0,l] * ten[:,2,l]\n",
    "      sum13_2 = sum13_2 + ten[:,0,l+1] * ten[:,2,l]\n",
    "      sum13_3 = sum13_3 + ten[:,0,l] * ten[:,2,l+1]\n",
    "      sum13_4 = sum13_4 + ten[:,0,l+1] * ten[:,2,l+1]\n",
    "      sum13_5 = sum13_5 + torch.pow(ten[:,0,l+1],2) * ten[:,2,l+1]\n",
    "      sum13_6 = sum13_6 + torch.pow(ten[:,0,l+1],2) * torch.pow(ten[:,2,l+1],2)\n",
    "\n",
    "      sum123_1 = sum123_1 + ten[:,0,l+1] * ten[:,1,l+1] * ten[:,2,l+1]\n",
    "      sum123_2 = sum123_2 + ten[:,0,l] * ten[:,1,l+1] * ten[:,2,l+1]\n",
    "      sum123_3 = sum123_3 + ten[:,0,l+1] * ten[:,1,l] * ten[:,2,l+1]\n",
    "      sum123_4 = sum123_4 + ten[:,0,l+1] * ten[:,1,l+1] * ten[:,2,l]\n",
    "      \n",
    "      sum123_5 = sum123_5 + torch.pow(ten[:,0,l+1],2) * ten[:,1,l+1] * ten[:,2,l+1]\n",
    "      sum123_6 = sum123_6 + ten[:,0,l+1] * torch.pow(ten[:,1,l+1],2) * ten[:,2,l+1]\n",
    "      sum123_7 = sum123_7 + ten[:,0,l+1] * ten[:,1,l+1] * torch.pow(ten[:,2,l+1],2)\n",
    "      \n",
    "    stack_x = torch.stack((sum1_1/n0, sum1_2/n0, sum1_3/n0, sum1_4/n0, sum1_5/n0),1) #5\n",
    "    stack_y = torch.stack((sum2_1/n0, sum2_2/n0, sum2_3/n0, sum2_4/n0, sum2_5/n0),1) #5\n",
    "    stack_z = torch.stack((sum3_1/n0, sum3_2/n0, sum3_3/n0, sum3_4/n0, sum3_5/n0),1) #5\n",
    "    \n",
    "    stack_xy = torch.stack((sum12_1/n0, sum12_2/n0, sum12_3/n0, sum12_4/n0, sum12_5/n0, sum12_6/n0), 1) #6\n",
    "    stack_yz = torch.stack((sum23_1/n0, sum23_2/n0, sum23_3/n0, sum23_4/n0, sum23_5/n0, sum23_6/n0), 1) #6\n",
    "    stack_zx = torch.stack((sum13_1/n0, sum13_2/n0, sum13_3/n0, sum13_4/n0, sum13_5/n0, sum13_6/n0), 1) #6\n",
    "    \n",
    "    stack_xyz = torch.stack((sum123_1/n0, sum123_2/n0, sum123_3/n0, sum123_4/n0, sum123_5/n0, sum123_6/n0, sum123_7/n0 ), 1) # 7\n",
    "     \n",
    "    return(torch.cat([stack_x, stack_y, stack_z,stack_xy, stack_yz, stack_zx, stack_xyz], 1))\n",
    "\n",
    "from torch.distributions.exponential import Exponential\n",
    "def MROUJ_summary(X):\n",
    "    \"\"\"\n",
    "    X: torch size: [L,n]\n",
    "    \"\"\"\n",
    "    L0 = X.size()[0]\n",
    "    n0 = X.size()[1]\n",
    "    \n",
    "    Xi = X[:,range(1,n0)]\n",
    "    Xi1 = X[:,range(0,n0-1)]\n",
    "    \n",
    "    s0 = torch.mean(Xi, 1)\n",
    "    s1 = torch.mean(Xi1, 1)\n",
    "     \n",
    "    Xi = Xi - torch.reshape(s0, (L0, 1))\n",
    "    Xi1 = Xi1 - torch.reshape(s1, (L0, 1))\n",
    "    \n",
    "    s2 = torch.mean(Xi * Xi1, 1) / n0\n",
    "    s3 = torch.mean(Xi **2 , 1) /n0\n",
    "    s4 = torch.mean(Xi1 **2 , 1) /n0\n",
    "    \n",
    "    s5 = torch.mean(torch.abs(Xi - Xi1), 1)\n",
    "    s6 = torch.mean((Xi - Xi1)**2 , 1) / n0 \n",
    "    s7 = torch.mean((Xi - Xi1)**3 , 1) / n0\n",
    "    s8 = torch.mean((Xi - Xi1)**4 , 1) / n0 ** 2\n",
    "    \n",
    "    s9 = torch.mean((Xi - Xi1)**2 * Xi, 1) / n0 \n",
    "    s10 = torch.mean((Xi - Xi1)**2 * Xi ** 2, 1)/ n0 ** 2\n",
    "    \n",
    "    Xi = Xi + torch.reshape(s0, (L0, 1))\n",
    "    Xi1 = Xi1 + torch.reshape(s1, (L0, 1))\n",
    "    \n",
    "    s11 = torch.mean(Xi * Xi1, 1) - s0 * s1\n",
    "    s11 = s11 / ( torch.mean(Xi1 ** 2, 1) - s1 ** 2 )\n",
    "    \n",
    "    s12 = s0 * torch.mean(Xi1 ** 2,1) - s1 * torch.mean(Xi * Xi1, 1)\n",
    "    s12 = s12 / (torch.mean(Xi1 ** 2, 1) - s1 ** 2)\n",
    "    \n",
    "    # Jump intensity\n",
    "    tmp = abs(Xi - Xi1)\n",
    "    \n",
    "    thres = [1e-5 * 3, 1e-5 * 6, 1e-5 * 9, 1e-4 * 3, 1e-4 * 6, 1e-4 * 9, 1e-3 * 3, 1e-3 * 6, 1e-3 * 9,\n",
    "           1e-2 * 3, 1e-2 * 6, 1e-2 * 9, 1e-1 * 3, 1e-1 * 6, 1e-1 * 9,\n",
    "             1.0, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25]\n",
    "    thres_tmp = []\n",
    "    for i in range(len(thres)):\n",
    "        temp = torch.sum( (tmp > thres[i] ), 1) /n0\n",
    "        thres_tmp.append(temp)\n",
    "\n",
    "    j_int = torch.column_stack(thres_tmp)\n",
    "    \n",
    "    # Jump magnitude\n",
    "    tmp = Xi - Xi1\n",
    "    num = 33\n",
    "    q = []\n",
    "    for i in range(num+1):\n",
    "         q.append(i/num)\n",
    "    \n",
    "    q = torch.tensor(q)\n",
    "    mag_q = torch.transpose(torch.quantile(tmp, q, 1), 0, 1)\n",
    "    \n",
    "    return(torch.column_stack((s0, s1, s2, s3, s4, s5, s6, s7, s8, s9, \n",
    "                               s10, s11, s12, j_int, mag_q)) ) \n",
    "\n",
    "def MROUJ_summary2(X):\n",
    "    \"\"\"\n",
    "    X: torch size: [L,n]\n",
    "    \"\"\"\n",
    "    L0 = X.size()[0]\n",
    "    n0 = X.size()[1]\n",
    "    \n",
    "    Xi = X[:,range(1,n0)]\n",
    "    Xi1 = X[:,range(0,n0-1)]\n",
    "    \n",
    "    s0 = torch.mean(Xi, 1)\n",
    "    s1 = torch.mean(Xi1, 1)\n",
    "     \n",
    "    Xi = Xi - torch.reshape(s0, (L0, 1))\n",
    "    Xi1 = Xi1 - torch.reshape(s1, (L0, 1))\n",
    "    \n",
    "    s2 = torch.mean(Xi * Xi1, 1) / n0\n",
    "    s3 = torch.mean(Xi **2 , 1) /n0\n",
    "    s4 = torch.mean(Xi1 **2 , 1) /n0\n",
    "    \n",
    "    s5 = torch.mean(torch.abs(Xi - Xi1), 1)\n",
    "    s6 = torch.mean((Xi - Xi1)**2 , 1) / n0 \n",
    "    s7 = torch.mean((Xi - Xi1)**3 , 1) / n0\n",
    "    s8 = torch.mean((Xi - Xi1)**4 , 1) / n0 ** 2\n",
    "    \n",
    "    s9 = torch.mean((Xi - Xi1)**2 * Xi, 1) / n0 \n",
    "    s10 = torch.mean((Xi - Xi1)**2 * Xi ** 2, 1)/ n0 ** 2\n",
    "    \n",
    "    Xi = Xi + torch.reshape(s0, (L0, 1))\n",
    "    Xi1 = Xi1 + torch.reshape(s1, (L0, 1))\n",
    "    \n",
    "    s11 = torch.mean(Xi * Xi1, 1) - s0 * s1\n",
    "    s11 = s11 / ( torch.mean(Xi1 ** 2, 1) - s1 ** 2 )\n",
    "    \n",
    "    s12 = s0 * torch.mean(Xi1 ** 2,1) - s1 * torch.mean(Xi * Xi1, 1)\n",
    "    s12 = s12 / (torch.mean(Xi1 ** 2, 1) - s1 ** 2)\n",
    "    \n",
    "    # Jump intensity\n",
    "    tmp = abs(Xi - Xi1)\n",
    "    \n",
    "    thres = [1e-5 * 1, 1e-5 * 5, 1e-4 * 1, 1e-4 * 5, 1e-3 * 5, 1e-3 * 1,\n",
    "           1e-2 * 1, 1e-2 * 5, 1e-1 * 1, 1e-1 * 5,\n",
    "             1.0, 1.5, 2, 2.5, 3]\n",
    "    thres_tmp = []\n",
    "    for i in range(len(thres)):\n",
    "        temp = torch.sum( (tmp > thres[i] ), 1) /n0\n",
    "        thres_tmp.append(temp)\n",
    "\n",
    "    j_int = torch.column_stack(thres_tmp)\n",
    "    \n",
    "    # Jump magnitude\n",
    "    tmp = Xi - Xi1\n",
    "    num = 15\n",
    "    q = []\n",
    "    for i in range(num+1):\n",
    "         q.append(i/num)\n",
    "    \n",
    "    q = torch.tensor(q)\n",
    "    mag_q = torch.transpose(torch.quantile(tmp, q, 1), 0, 1)\n",
    "    \n",
    "    return(torch.column_stack((s0, s1, s2, s3, s4, s5, s6, s7, s8, s9, \n",
    "                               s10, s11, s12, j_int, mag_q)) ) \n",
    "\n",
    "\n",
    "def SQRJ_summary(X):\n",
    "    \"\"\"\n",
    "    X: torch size: [L,n]\n",
    "    \"\"\"\n",
    "    \n",
    "    L0 = X.size()[0]\n",
    "    n0 = X.size()[1]\n",
    "    \n",
    "    X0 = X[:,:-1]\n",
    "    X1 = X[:,1:]\n",
    "    \n",
    "    # Pseudo-likelihood\n",
    "    s0 = torch.mean(X0, 1, keepdim=True) # mean of x_{i-1}\n",
    "    s1 = torch.mean(X1, 1, keepdim=True) # mean of x_i\n",
    "    \n",
    "    s2 = torch.mean((X0 - s0) * (X1 - s1),1,keepdim=True)/ n0 ** (1/2)\n",
    "    s3 = torch.mean((X0 - s0)**2,1, keepdim=True)/ n0 ** (1/2)\n",
    "    s4 = torch.mean((X1 - s1)**2,1, keepdim=True)/ n0 ** (1/2)\n",
    "    \n",
    "    s5 = torch.mean(1/ X0, 1, keepdim=True)\n",
    "    s6 = torch.mean(X1/ X0, 1, keepdim=True)\n",
    "    s7 = torch.mean(X1 ** 2/ X0, 1, keepdim=True)/ n0 ** (1/2)\n",
    "    s8 = torch.log(torch.max(X0, 1e-10*torch.ones(1)))\n",
    "    s8 = torch.mean(s8, 1, keepdim=True)\n",
    "    \n",
    "    # GMM\n",
    "    s9 = torch.mean((X0 - s0)**2 * (X1 - s1), 1, keepdim=True)/ n0 \n",
    "    s10 = torch.mean((X0 - s0) * (X1 - s1)**2, 1, keepdim=True)/ n0 \n",
    "    s11 = torch.mean((X0 - s0)**2 * (X1 - s1)**2, 1, keepdim=True)/ n0 ** (3/2)\n",
    "    \n",
    "    \n",
    "    # Jump intensity\n",
    "    tmp = abs(X1 - X0)\n",
    "    thres = [1e-5 * 3, 1e-5 * 6, 1e-5 * 9, 1e-4 * 3, 1e-4 * 6, 1e-4 * 9, 1e-3 * 3, 1e-3 * 6, 1e-3 * 9,\n",
    "           1e-2 * 3, 1e-2 * 6, 1e-2 * 9, 1e-1 * 3, 1e-1 * 6, 1e-1 * 9,\n",
    "             1.0, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25]\n",
    "    thres_tmp = []\n",
    "    for i in range(len(thres)):\n",
    "        temp = torch.sum( (tmp > thres[i] ), 1) /n0\n",
    "        thres_tmp.append(temp)\n",
    "\n",
    "    j_int = torch.column_stack(thres_tmp)\n",
    "    \n",
    "    # Jump magnitude\n",
    "    tmp = X1 - X0\n",
    "    num = 33\n",
    "    q = []\n",
    "    for i in range(num+1):\n",
    "         q.append(i/num)\n",
    "    \n",
    "    q = torch.tensor(q)\n",
    "    mag_q = torch.transpose(torch.quantile(tmp, q, 1), 0, 1)\n",
    "    \n",
    "    return(torch.column_stack((s0, s1, s2, s3, s4, s5, s6, s7, s8, s9, \n",
    "                               s10, s11, j_int, mag_q)) )\n",
    "\n",
    "def PBJD_summary(X, delta):\n",
    "    \"\"\"\n",
    "    X: torch size: [L,n]\n",
    "    \"\"\"\n",
    "    L0 = X.size()[0]\n",
    "    n0 = X.size()[1]\n",
    "    \n",
    "    Xi = X[:,range(1,n0)]\n",
    "    Xi1 = X[:,range(0,n0-1)]\n",
    "    \n",
    "    # mean\n",
    "    s0 = torch.sum((Xi - Xi1), 1) / (delta* (n0-1))\n",
    "    s1 = torch.mean(torch.abs(Xi - Xi1), 1) / n0\n",
    "    s2 = torch.mean((Xi - Xi1)**2 , 1) / n0\n",
    "    s3 = torch.mean((Xi - Xi1)**3 , 1) / n0 \n",
    "    s4 = torch.mean((Xi - Xi1)**4 , 1) / n0 ** 2\n",
    "    \n",
    "    tmp = (Xi - Xi1 - torch.reshape(s0, (L0, 1)) * delta) ** 2/delta\n",
    "    \n",
    "    # sigma\n",
    "    s5 = torch.mean(tmp, 1)/n0\n",
    "    \n",
    "    # Jump intensity\n",
    "    tmp = (Xi - Xi1)\n",
    "    \n",
    "    thres = [1e-5 * 3, 1e-5 * 6, 1e-5 * 9, 1e-4 * 3, 1e-4 * 6, 1e-4 * 9, 1e-3 * 3, 1e-3 * 6, 1e-3 * 9,\n",
    "           1e-2 * 3, 1e-2 * 6, 1e-2 * 9, 1e-1 * 3, 1e-1 * 6, 1e-1 * 9,\n",
    "             1.0, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25]\n",
    "    thres_tmp = []\n",
    "    for i in range(len(thres)):\n",
    "        temp = torch.sum( (tmp > thres[i] ), 1) /n0\n",
    "        thres_tmp.append(temp)\n",
    "    \n",
    "    j_int1 = torch.column_stack(thres_tmp)\n",
    "    \n",
    "    thres_tmp2 = []\n",
    "    for i in range(len(thres)):\n",
    "        temp = torch.sum( (tmp < -thres[i] ), 1) /n0\n",
    "        thres_tmp2.append(temp)\n",
    "    \n",
    "    j_int2 = torch.column_stack(thres_tmp2)\n",
    "    \n",
    "    # Jump magnitude\n",
    "    tmp = Xi - Xi1\n",
    "    num = 33\n",
    "    q = []\n",
    "    for i in range(num+1):\n",
    "         q.append(i/num)\n",
    "    \n",
    "    q = torch.tensor(q)\n",
    "    mag_q = torch.transpose(torch.quantile(tmp, q, 1), 0, 1)\n",
    "    \n",
    "    return(torch.column_stack((s0, s1, s2, s3, s4, s5, \n",
    "                               j_int1, j_int2, mag_q)) ) \n",
    "\n",
    "def PBJD_RDA_summary(X, delta):\n",
    "    \"\"\"\n",
    "    X: torch size: [L,n]\n",
    "    \"\"\"\n",
    "    L0 = X.size()[0]\n",
    "    n0 = X.size()[1]\n",
    "    \n",
    "    Xi = X[:,range(1,n0)]\n",
    "    Xi1 = X[:,range(0,n0-1)]\n",
    "    \n",
    "    # mean\n",
    "    s0 = torch.sum((Xi - Xi1), 1) / (delta* (n0-1))\n",
    "    s1 = torch.mean(torch.abs(Xi - Xi1), 1) / n0\n",
    "    s2 = torch.mean((Xi - Xi1)**2 , 1) / n0\n",
    "    s3 = torch.mean((Xi - Xi1)**3 , 1) / n0 \n",
    "    s4 = torch.mean((Xi - Xi1)**4 , 1) / n0 ** 2\n",
    "    \n",
    "    tmp = (Xi - Xi1 - torch.reshape(s0, (L0, 1)) * delta) ** 2/delta\n",
    "    \n",
    "    # sigma\n",
    "    s5 = torch.mean(tmp, 1)/n0\n",
    "    \n",
    "    # Jump intensity\n",
    "    tmp = (Xi - Xi1)\n",
    "    \n",
    "    thres = [1e-7 * 3, 1e-7 * 6, 1e-7 * 9, \n",
    "             1e-6 * 3, 1e-6 * 6, 1e-6 * 9, \n",
    "             1e-5 * 3, 1e-5 * 6, 1e-5 * 9, \n",
    "             1e-4 * 3, 1e-4 * 6, 1e-4 * 9, \n",
    "             1e-3 * 3, 1e-3 * 6, 1e-3 * 9,\n",
    "             1e-2 * 3, 1e-2 * 6, 1e-2 * 9]\n",
    "    thres_tmp = []\n",
    "    for i in range(len(thres)):\n",
    "        temp = torch.sum( (tmp > thres[i] ), 1) /n0\n",
    "        thres_tmp.append(temp)\n",
    "    \n",
    "    j_int1 = torch.column_stack(thres_tmp)\n",
    "    \n",
    "    thres_tmp2 = []\n",
    "    for i in range(len(thres)):\n",
    "        temp = torch.sum( (tmp < -thres[i] ), 1) /n0\n",
    "        thres_tmp2.append(temp)\n",
    "    \n",
    "    j_int2 = torch.column_stack(thres_tmp2)\n",
    "    \n",
    "    # Jump magnitude\n",
    "    tmp = Xi - Xi1\n",
    "    num = 33\n",
    "    q = []\n",
    "    for i in range(num+1):\n",
    "         q.append(i/num)\n",
    "    \n",
    "    q = torch.tensor(q)\n",
    "    mag_q = torch.transpose(torch.quantile(tmp, q, 1), 0, 1)\n",
    "    \n",
    "    return(torch.column_stack((s0, s1, s2, s3, s4, s5, \n",
    "                               j_int1, j_int2, mag_q)) ) \n",
    "\n",
    "\n",
    "def BOUJ_summary(sim_data):\n",
    "    \"\"\"\n",
    "    sim_data: torch size: [2, L,n]\n",
    "    \"\"\"\n",
    "    L0 = sim_data.size()[1]\n",
    "    n0 = sim_data.size()[2]\n",
    "    \n",
    "    X = sim_data[0]\n",
    "    Y = sim_data[1]\n",
    "    \n",
    "    X0 = X[:,:-1]\n",
    "    X1 = X[:,1:]\n",
    "    \n",
    "    Y0 = Y[:,:-1]\n",
    "    Y1 = Y[:,1:]\n",
    "    \n",
    "    # Pseudo\n",
    "    s0 = torch.mean(X0, 1, keepdim=True) # mean of x_{i-1}\n",
    "    s1 = torch.mean(X1, 1, keepdim=True) # mean of x_i\n",
    "    s2 = torch.mean((X0 - s0) * (X1 - s1), 1, keepdim=True) /n0 ** (1/2)\n",
    "    s3 = torch.mean((X0 - s0)**2, 1, keepdim=True) / n0 ** (1/2)\n",
    "    s4 = torch.mean((X1 - s1)**2, 1, keepdim=True) / n0 ** (1/2)\n",
    "    \n",
    "    s5 = torch.mean(Y0, 1, keepdim=True) # mean of x_{i-1}\n",
    "    s6 = torch.mean(Y1, 1, keepdim=True) # mean of x_i\n",
    "    s7 = torch.mean((Y0 - s5) * (Y1 - s6), 1, keepdim=True)/n0 ** (1/2)\n",
    "    s8 = torch.mean((Y0 - s5)**2, 1, keepdim=True) / n0 ** (1/2)\n",
    "    s9 = torch.mean((Y1 - s6)**2, 1, keepdim=True) / n0 ** (1/2)\n",
    "    \n",
    "    s10 = torch.mean((X0 - s0) * (Y0 - s5), 1 ,keepdim = True) / n0 ** (1/2)\n",
    "    s11 = torch.mean((X1 - s1) * (Y0 - s5), 1 ,keepdim = True) / n0 ** (1/2)\n",
    "    s12 = torch.mean((X0 - s1) * (Y1 - s6), 1 ,keepdim = True) / n0 ** (1/2)\n",
    "    s13 = torch.mean((X1 - s1) * (Y1 - s6), 1 ,keepdim = True) / n0 ** (1/2)\n",
    "    \n",
    "    # GMM\n",
    "    s14 = torch.mean(torch.abs(X1 - X0), 1)\n",
    "    s15 = torch.mean((X1 - X0)**2 , 1) / n0 \n",
    "    s16 = torch.mean((X1 - X0)**3 , 1) / n0\n",
    "    s17 = torch.mean((X1 - X0)**4 , 1) / n0 ** 2\n",
    "    \n",
    "    s18 = torch.mean((X1 - X0)**2 * X0, 1) / n0 \n",
    "    s19 = torch.mean((X1 - X0)**2 * X1 ** 2, 1)/ n0 ** 2\n",
    "    \n",
    "    s20 = torch.mean(torch.abs(Y1 - Y0), 1)\n",
    "    s21 = torch.mean((Y1 - Y0)**2 , 1) / n0 \n",
    "    s22 = torch.mean((Y1 - Y0)**3 , 1) / n0\n",
    "    s23 = torch.mean((Y1 - Y0)**4 , 1) / n0 ** 2\n",
    "    \n",
    "    s24 = torch.mean((Y1 - Y0)**2 * Y0, 1) / n0 \n",
    "    s25 = torch.mean((Y1 - Y0)**2 * Y1 ** 2, 1)/ n0 ** 2\n",
    "    \n",
    "    s26 = torch.mean(X1 - Y1, 1 ,keepdim = True) / n0 ** (1/2)\n",
    "    s27 = torch.mean((X1 - Y1)**2, 1 ,keepdim = True) / n0 \n",
    "    s28 = torch.mean((X1 - Y1)**3, 1 ,keepdim = True) / n0 ** (3/2)\n",
    "    s29 = torch.mean((X1 - Y1)**4, 1 ,keepdim = True) / n0 ** 2\n",
    "    \n",
    "    \n",
    "    # Jump intensity\n",
    "    tmp = torch.abs(X1 - X0)\n",
    "    thres = [1e-5 * 3, 1e-5 * 6, 1e-5 * 9, 1e-4 * 3, 1e-4 * 6, 1e-4 * 9, 1e-3 * 3, 1e-3 * 6, 1e-3 * 9,\n",
    "           1e-2 * 3, 1e-2 * 6, 1e-2 * 9, 1e-1 * 3, 1e-1 * 6, 1e-1 * 9,\n",
    "             1.0, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25]\n",
    "    thres_tmp = []\n",
    "    for i in range(len(thres)):\n",
    "        temp = torch.sum( (tmp > thres[i] ), 1) /n0\n",
    "        thres_tmp.append(temp)\n",
    "    j_int = torch.column_stack(thres_tmp)\n",
    "    \n",
    "    # Jump intensity\n",
    "    tmp = torch.abs(Y1 - Y0)\n",
    "    thres_tmp2 = []\n",
    "    for i in range(len(thres)):\n",
    "        temp = torch.sum( (tmp > thres[i] ), 1) /n0\n",
    "        thres_tmp2.append(temp)\n",
    "    j_int2 = torch.column_stack(thres_tmp2)\n",
    "    \n",
    "    \n",
    "    # Jump magnitude\n",
    "    tmp = torch.abs(X1 - X0)\n",
    "    num = 24\n",
    "    q = []\n",
    "    for i in range(num+1):\n",
    "         q.append(i/num)\n",
    "    \n",
    "    q = torch.tensor(q)\n",
    "    mag_q = torch.transpose(torch.quantile(tmp, q, 1), 0, 1)\n",
    "    \n",
    "    # Jump magnitude\n",
    "    tmp2 = torch.abs(Y1 - Y0)\n",
    "    num = 24\n",
    "    q2 = []\n",
    "    for i in range(num+1):\n",
    "         q2.append(i/num)\n",
    "    \n",
    "    q2 = torch.tensor(q2)\n",
    "    mag_q2 = torch.transpose(torch.quantile(tmp2, q2, 1), 0, 1)\n",
    "    \n",
    "    \n",
    "    return(torch.column_stack((s0, s1, s2, s3, s4, s5, s6, s7, s8, s9, \n",
    "                              s10, s11, s12, s13, s14, s15, s16, s17, s18, s19,\n",
    "                              s20, s21, s22, s23, s24, s25, s26, s27, s28, s29,\n",
    "                               j_int, j_int2, mag_q, mag_q2)) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a178991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_quantile(values, quantiles, sample_weight=None, \n",
    "                      values_sorted=False, old_style=False):\n",
    "    \"\"\" Very close to numpy.percentile, but supports weights.\n",
    "    NOTE: quantiles should be in [0, 1]!\n",
    "    :param values: numpy.array with data\n",
    "    :param quantiles: array-like with many quantiles needed\n",
    "    :param sample_weight: array-like of the same length as `array`\n",
    "    :param values_sorted: bool, if True, then will avoid sorting of\n",
    "        initial array\n",
    "    :param old_style: if True, will correct output to be consistent\n",
    "        with numpy.percentile.\n",
    "    :return: numpy.array with computed quantiles.\n",
    "    \"\"\"\n",
    "    values = np.array(values)\n",
    "    quantiles = np.array(quantiles)\n",
    "    if sample_weight is None:\n",
    "        sample_weight = np.ones(len(values))\n",
    "    sample_weight = np.array(sample_weight)\n",
    "    assert np.all(quantiles >= 0) and np.all(quantiles <= 1), \\\n",
    "        'quantiles should be in [0, 1]'\n",
    "\n",
    "    if not values_sorted:\n",
    "        sorter = np.argsort(values)\n",
    "        values = values[sorter]\n",
    "        sample_weight = sample_weight[sorter]\n",
    "\n",
    "    weighted_quantiles = np.cumsum(sample_weight) - 0.5 * sample_weight\n",
    "    if old_style:\n",
    "        # To be convenient with numpy.percentile\n",
    "        weighted_quantiles -= weighted_quantiles[0]\n",
    "        weighted_quantiles /= weighted_quantiles[-1]\n",
    "    else:\n",
    "        weighted_quantiles /= np.sum(sample_weight)\n",
    "    return np.interp(quantiles, weighted_quantiles, values)\n",
    "\n",
    "def mad_np(sam):\n",
    "    return np.median(np.absolute(sam - np.mean(sam)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f71d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from DNN_module import Net\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def con_mad(X, resid, N_EPOCHS = 250, learning_rate = 1e-5, weight_decay = 1e-5, layer_len = 250):\n",
    "    # X: torch([L,m]) L: nubmer of synthetic data; m: size of input\n",
    "    # resid: torch([L,p]) p: the number of parameter of interest\n",
    "    # x0 : torch([1,m]) \n",
    "    \n",
    "    #output: torch([L,p])\n",
    "    # size\n",
    "    if torch.cuda.is_available(): \n",
    "        dev = \"cuda:0\" \n",
    "    else: \n",
    "        dev = \"cpu\"\n",
    "    device = torch.device(dev) \n",
    "    torch.set_default_device(device)\n",
    "    X = X.to(device)\n",
    "    resid = resid.to(device)\n",
    "    torch.set_default_device('cuda')\n",
    "    \n",
    "    resid = torch.max(torch.abs(resid), torch.ones(1) * 1e-30)\n",
    "    \n",
    "    Y = torch.log(resid)\n",
    "    L = X.size()[0]\n",
    "\n",
    "    L_train = np.floor(L * 0.7).astype(int)\n",
    "    L_val = L - L_train\n",
    "\n",
    "    torch.manual_seed(1000)\n",
    "    indexes = torch.randperm(L_train + L_val)\n",
    "    #Batch size\n",
    "    BATCH_SIZE = 64\n",
    "    \n",
    "    # Divide Data\n",
    "    X_train = X[indexes[0:L_train]]\n",
    "    Y_train = Y[indexes[0:L_train]]\n",
    "\n",
    "    X_val = X[indexes[L_train:(L_train + L_val)]]\n",
    "    Y_val = Y[indexes[L_train:(L_train + L_val)]]\n",
    "\n",
    "    # Use torch.utils.data to create a DataLoader that will take care of creating batches\n",
    "    dataset = TensorDataset(X_train, Y_train)\n",
    "    dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle=True, generator=torch.Generator(device=device))\n",
    "\n",
    "    # Get the dataset size for printing (it is equal to N_SAMPLES)\n",
    "    dataset_size = len(dataloader.dataset)\n",
    "\n",
    "    # Define the input and output dimensions\n",
    "    D_in, D_out = X.size()[1], Y.size()[1]\n",
    "    \n",
    "    # Create an instance of the Net class with specified dimensions\n",
    "    H, H2, H3 = layer_len, layer_len, layer_len\n",
    "    net_var = Net(D_in = D_in, D_out = D_out, H = H, H2 = H2, H3 = H3)\n",
    "    best_model_state = copy.deepcopy(net_var.state_dict())\n",
    "    # Model name\n",
    "    #model_save_name = 'cond_var.pt'\n",
    "    #path = F\"./{model_save_name}\"\n",
    "\n",
    "    def weighted_mse_loss(input, target, weight):\n",
    "        return (weight * (input - target) ** 2).sum()\n",
    "    out_range = [torch.min(Y_train,0).values.detach().cpu().numpy(), torch.max(Y_train,0).values.detach().cpu().numpy()]\n",
    "    weight_1 = torch.tensor(1/(out_range[1] - out_range[0])**2)\n",
    "    \n",
    "    # The nn package also contains definitions of popular loss functions; in this case we will use Mean Squared Error (MSE) as our loss function.\n",
    "    #loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "    optimizer = torch.optim.Adam(net_var.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    train_error_plt = []\n",
    "    val_error_plt = []\n",
    "    \n",
    "    \n",
    "    # Loop over epochs\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        for id_batch, (x_batch, y_batch) in enumerate(dataloader):\n",
    "            y_batch_pred = net_var(x_batch)\n",
    "            #loss = loss_fn(y_batch_pred, y_batch)\n",
    "            loss = weighted_mse_loss(y_batch, y_batch_pred, weight_1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % 50 ==0 and id_batch % 100 == 0:\n",
    "                loss, current = loss.item(), (id_batch + 1)* len(x_batch)\n",
    "                print(f\"train_loss: {loss/BATCH_SIZE:>7f}  [{current:>5d}/{dataset_size:>5d}]\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net_var.eval()\n",
    "            theta_pred_train = net_var(X_train)\n",
    "            # train_loss = loss_fn(theta_pred_train,Y_train) / L_train\n",
    "            train_loss = weighted_mse_loss(Y_train, theta_pred_train, weight_1) / L_train\n",
    "            train_error_plt.append(train_loss.to(\"cpu\"))\n",
    "\n",
    "            theta_pred_val = net_var(X_val)\n",
    "            #val_loss = loss_fn(Y_val, theta_pred_val) / L_val\n",
    "            val_loss = weighted_mse_loss(Y_val, theta_pred_val, weight_1) / L_val\n",
    "            val_error_plt.append(val_loss.to(\"cpu\"))\n",
    "\n",
    "        if epoch % 30 ==0:\n",
    "            print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "            print(f\"train_loss {train_loss:>7f} val_loss {val_loss:>7f}\")\n",
    "\n",
    "        ## Choose Best Model\n",
    "        if val_error_plt[epoch] == np.min(val_error_plt):\n",
    "            best=epoch\n",
    "            best_model_state = copy.deepcopy(net_var.state_dict())\n",
    "\n",
    "        if epoch % 100 == 49:\n",
    "            #net_var.load_state_dict(torch.load(path))\n",
    "            net_var.load_state_dict(best_model_state)\n",
    "            learning_rate = max(learning_rate * 1e-1, 1e-9)\n",
    "            \n",
    "        if val_error_plt[epoch] == math.inf:\n",
    "            if train_error_plt[epoch] == np.min(train_error_plt):\n",
    "                best_model_state = copy.deepcopy(net_var.state_dict())\n",
    "                \n",
    "    # load net\n",
    "    net_var = Net(D_in, D_out, H = H, H2 = H2, H3 = H3)\n",
    "    #net_var.load_state_dict(torch.load(path))\n",
    "    net_var.load_state_dict(best_model_state)\n",
    "    net_var.eval()\n",
    "    print(np.min(val_error_plt))\n",
    "\n",
    "    return net_var, device, np.min(val_error_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674b7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_inf_sd(x0, X, Y, net, tol, h=None, seed = 1001, N_EPOCHS = 250, l_rate = 1e-5, w_rate = 1e-5, layer_len = 250):\n",
    "    # x0: torch([m])    m: number of summary statistics\n",
    "    # X: torch([L,m]) L: nubmer of synthetic data (should be cpu)\n",
    "    # Y: torch([L,p]) L: nubmer of synthetic data (should be cpu)\n",
    "    # net: neural net in this case\n",
    "    # tol: \\in (0,1)\n",
    "    # h: numeric >1\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        dev = \"cuda:0\" \n",
    "    else: \n",
    "        dev = \"cpu\"\n",
    "    \n",
    "    X = X.to(\"cpu\")\n",
    "    Y = Y.to(\"cpu\")\n",
    "    net = net.to(\"cpu\")\n",
    "    x0 = x0.to(\"cpu\")\n",
    "    \n",
    "\n",
    "    # size\n",
    "    L, m = X.size()\n",
    "    p = Y.size()[1]\n",
    "        \n",
    "    # x0 reshaping\n",
    "    x0 = torch.reshape(x0, (1,m))\n",
    "    net.eval()\n",
    "    thetahat = net(x0)\n",
    "    #resid = Y - net(X)\n",
    "    \n",
    "    # Normalizing for stability\n",
    "    \n",
    "    c_tmp = torch.quantile(X, torch.tensor([.001,.999], device = \"cpu\"), 0)\n",
    "    a = torch.reshape(c_tmp[0], (1, c_tmp.size()[1]))\n",
    "    b = torch.reshape(c_tmp[1], (1, c_tmp.size()[1]))\n",
    "    \n",
    "    X_scale = torch.clone((X - a) / (b - a))\n",
    "    x0 = torch.clone((x0 - a) / (b - a))\n",
    "    \n",
    "    # Distance\n",
    "    dist = torch.sum((X_scale - x0)**2, 1)\n",
    "    dist = torch.sqrt(dist)\n",
    "    sort_dist, indicies = torch.sort(dist)\n",
    "    \n",
    "    # new index\n",
    "    nacc = np.floor(L * tol).astype(int)\n",
    "    ds = sort_dist[nacc-1]\n",
    "    wt1 = (dist <= ds)\n",
    "    \n",
    "    # weights\n",
    "    if h is None:\n",
    "        h = 1/ np.log(torch.sum(wt1))\n",
    "    \n",
    "    weights = torch.exp(-dist[wt1]/ds/h)\n",
    "    X_tmp = X_scale[wt1,:]\n",
    "    Y_tmp = Y[wt1,:]\n",
    "    \n",
    "    X_tmp = X_tmp.to(\"cpu\")\n",
    "    net.eval()\n",
    "    resid_tmp = Y_tmp - net(X[wt1,:])\n",
    "    resid_tmp = resid_tmp.detach()\n",
    "    \n",
    "    resid_tmp = resid_tmp.to(\"cpu\")\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    indexes = torch.randperm(X_tmp.size()[0])\n",
    "    indexes = indexes.to(\"cpu\")\n",
    "    \n",
    "    L_var = np.floor(X_tmp.size()[0] * 0.5).astype(int)\n",
    "    L_adj = X_tmp.size()[0] - L_var\n",
    "    \n",
    "    # Divide Data\n",
    "    X_tmp_train = X_tmp[indexes[0:L_var]]\n",
    "    resid_tmp_train = resid_tmp[indexes[0:L_var]]\n",
    "    \n",
    "    X_tmp_val = X_tmp[indexes[L_var:(L_adj + L_var)]]\n",
    "    resid_tmp_val = resid_tmp[indexes[L_var:(L_adj + L_var)]]\n",
    "    weights_val = weights[indexes[L_var:(L_adj + L_var)]]\n",
    "    \n",
    "    net_cond, dev, _ = con_mad(X_tmp_train, resid_tmp_train, N_EPOCHS = N_EPOCHS, layer_len = layer_len)\n",
    "    net_cond.eval()\n",
    "    sd_x0 = torch.exp(net_cond(x0.to(dev)))\n",
    "    sd_X = torch.exp(net_cond(X_tmp_val.to(dev)))\n",
    "    sd_x0 = sd_x0.to(\"cpu\")\n",
    "    sd_X = sd_X.to(\"cpu\")\n",
    "    \n",
    "    adj = thetahat + resid_tmp_val * sd_x0/sd_X\n",
    "    \n",
    "    return weights_val, adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63784a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_inf_sd2(x0, X, Y, net, tol, h=None, ln_num = None, \n",
    "                 N_EPOCHS = 100, l_rate = None, w_rate = None, seed = None):\n",
    "    # x0: torch([m])    m: number of summary statistics\n",
    "    # X: torch([L,m]) L: nubmer of synthetic data (should be cpu objects)\n",
    "    # Y: torch([L,p]) L: nubmer of synthetic data (should be cpu objects)\n",
    "    # net: neural net in this case\n",
    "    # tol: \\in (0,1)\n",
    "    # h: numeric >1\n",
    "    if torch.cuda.is_available(): \n",
    "        dev = \"cuda:0\" \n",
    "    else: \n",
    "        dev = \"cpu\"\n",
    "    \n",
    "    X = X.to(\"cpu\")\n",
    "    Y = Y.to(\"cpu\")\n",
    "    net = net.to(\"cpu\")\n",
    "    x0 = x0.to(\"cpu\")\n",
    "    \n",
    "\n",
    "    # size\n",
    "    L, m = X.size()\n",
    "    p = Y.size()[1]\n",
    "        \n",
    "    # x0 reshaping\n",
    "    x0 = torch.reshape(x0, (1,m))\n",
    "    net.eval()\n",
    "    thetahat = net(x0)\n",
    "    #resid = Y - net(X)\n",
    "    \n",
    "    # Normalizing for stability\n",
    "    \n",
    "    c_tmp = torch.quantile(X, torch.tensor([.001,.999], device = \"cpu\"), 0)\n",
    "    a = torch.reshape(c_tmp[0], (1, c_tmp.size()[1]))\n",
    "    b = torch.reshape(c_tmp[1], (1, c_tmp.size()[1]))\n",
    "    \n",
    "    X_scale = torch.clone((X - a) / (b - a))\n",
    "    x0 = torch.clone((x0 - a) / (b - a))\n",
    "    \n",
    "    # Distance\n",
    "    dist = torch.sum((X_scale - x0)**2, 1)\n",
    "    dist = torch.sqrt(dist)\n",
    "    sort_dist, indicies = torch.sort(dist)\n",
    "    \n",
    "    # new index\n",
    "    nacc = np.floor(L * tol).astype(int)\n",
    "    ds = sort_dist[nacc-1]\n",
    "    wt1 = (dist <= ds)\n",
    "    \n",
    "    # weights\n",
    "    if h is None:\n",
    "        h = 1/ np.log(torch.sum(wt1))\n",
    "        \n",
    "    if ln_num is None:\n",
    "        ln_num = 10\n",
    "    \n",
    "    if l_rate is None:\n",
    "        l_rate = 1e-5\n",
    "    \n",
    "    if w_rate is None:\n",
    "        w_rate = 1e-5\n",
    "    \n",
    "    if seed is None:\n",
    "        seed = 1001\n",
    "    \n",
    "    weights = torch.exp(-dist[wt1]/ds/h)\n",
    "    X_tmp = X_scale[wt1,:]\n",
    "    Y_tmp = Y[wt1,:]\n",
    "    \n",
    "    X_tmp = X_tmp.to(\"cpu\")\n",
    "    resid_tmp = Y_tmp - net(X[wt1,:])\n",
    "    resid_tmp = resid_tmp.detach()\n",
    "    \n",
    "    resid_tmp = resid_tmp.to(\"cpu\")\n",
    "    \n",
    "    \n",
    "    l_rate_list = [l_rate, l_rate * 1e-1, l_rate * 10]\n",
    "    w_rate_list = [w_rate, w_rate * 1e-1, w_rate * 10]\n",
    "    random.seed(10)\n",
    "    l_rate_list = random.choices(l_rate_list, k=ln_num)\n",
    "    w_rate_list = random.choices(w_rate_list, k=ln_num)\n",
    "    \n",
    "    # Create an instance of the Net class with specified dimensions\n",
    "    H, H2, H3 = 256, 256, 256\n",
    "    D_in, D_out = X_tmp.size()[1], resid_tmp.size()[1]\n",
    "    net_cond_best = Net(D_in = D_in, D_out = D_out, H = H, H2 = H2, H3 = H3)\n",
    "\n",
    "    val_min_0 = float('inf')\n",
    "    for k in range(ln_num):\n",
    "        torch.manual_seed(seed+ln_num)\n",
    "        indexes = torch.randperm(X_tmp.size()[0])\n",
    "        indexes = indexes.to(\"cpu\")\n",
    "    \n",
    "        L_var = np.floor(X_tmp.size()[0] * 0.5).astype(int)\n",
    "        L_adj = X_tmp.size()[0] - L_var\n",
    "    \n",
    "        # Divide Data\n",
    "        X_tmp_train = X_tmp[indexes[0:L_var]]\n",
    "        resid_tmp_train = resid_tmp[indexes[0:L_var]]\n",
    "    \n",
    "        X_tmp_val = X_tmp[indexes[L_var:(L_adj + L_var)]]\n",
    "        resid_tmp_val = resid_tmp[indexes[L_var:(L_adj + L_var)]]\n",
    "        weights_val = weights[indexes[L_var:(L_adj + L_var)]]\n",
    "    \n",
    "        l_rate = l_rate_list[k]\n",
    "        w_rate = w_rate_list[k]\n",
    "        \n",
    "        net_cond, dev, val_min = con_mad(X_tmp_train, resid_tmp_train, N_EPOCHS = N_EPOCHS, \n",
    "                                         learning_rate = l_rate, weight_decay = w_rate)\n",
    "        if val_min <= val_min_0:\n",
    "            best_model_state = copy.deepcopy(net_cond.state_dict())\n",
    "            val_min_0 = val_min\n",
    "        print(\"iter: \", k, \"Val= \", val_min_0)\n",
    "        \n",
    "    net_cond_best.load_state_dict(best_model_state)\n",
    "    net_cond_best = net_cond_best.to(\"cpu\")\n",
    "    net_cond_best.eval()\n",
    "    sd_x0 = torch.exp(net_cond_best(x0.to(\"cpu\")))\n",
    "    sd_X = torch.exp(net_cond_best(X_tmp_val.to(\"cpu\")))\n",
    "    sd_x0 = sd_x0.to(\"cpu\")\n",
    "    sd_X = sd_X.to(\"cpu\")\n",
    "    \n",
    "    adj = thetahat + resid_tmp_val * sd_x0/sd_X\n",
    "    \n",
    "    return weights_val, adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ebecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import scipy.stats.kde as kde\n",
    "\n",
    "def hpd_grid(sample, alpha=0.05, roundto=2):\n",
    "    \"\"\"Calculate highest posterior density (HPD) of array for given alpha. \n",
    "    The HPD is the minimum width Bayesian credible interval (BCI). \n",
    "    The function works for multimodal distributions, returning more than one mode\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    sample : Numpy array or python list\n",
    "        An array containing MCMC samples\n",
    "    alpha : float\n",
    "        Desired probability of type I error (defaults to 0.05)\n",
    "    roundto: integer\n",
    "        Number of digits after the decimal point for the results\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    hpd: array with the lower \n",
    "          \n",
    "    \"\"\"\n",
    "    sample = np.asarray(sample)\n",
    "    sample = sample[~np.isnan(sample)]\n",
    "    # get upper and lower bounds\n",
    "    l = np.min(sample)\n",
    "    u = np.max(sample)\n",
    "    density = kde.gaussian_kde(sample)\n",
    "    x = np.linspace(l, u, 2000)\n",
    "    y = density.evaluate(x)\n",
    "    #y = density.evaluate(x, l, u) waitting for PR to be accepted\n",
    "    xy_zipped = zip(x, y/np.sum(y))\n",
    "    xy = sorted(xy_zipped, key=lambda x: x[1], reverse=True)\n",
    "    xy_cum_sum = 0\n",
    "    hdv = []\n",
    "    for val in xy:\n",
    "        xy_cum_sum += val[1]\n",
    "        hdv.append(val[0])\n",
    "        if xy_cum_sum >= (1-alpha):\n",
    "            break\n",
    "    hdv.sort()\n",
    "    diff = (u-l)/20  # differences of 5%\n",
    "    hpd = []\n",
    "    hpd.append(round(min(hdv), roundto))\n",
    "    for i in range(1, len(hdv)):\n",
    "        if hdv[i]-hdv[i-1] >= diff:\n",
    "            hpd.append(round(hdv[i-1], roundto))\n",
    "            hpd.append(round(hdv[i], roundto))\n",
    "    hpd.append(round(max(hdv), roundto))\n",
    "    ite = iter(hpd)\n",
    "    hpd = list(zip(ite, ite))\n",
    "    modes = []\n",
    "    for value in hpd:\n",
    "         x_hpd = x[(x > value[0]) & (x < value[1])]\n",
    "         y_hpd = y[(x > value[0]) & (x < value[1])]\n",
    "         modes.append(round(x_hpd[np.argmax(y_hpd)], roundto))\n",
    "    return hpd, x, y, modes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (My sbi_pack Kernel)",
   "language": "python",
   "name": "sbi_pack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
